{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Up to this point you've been using data to make real-valued predictions such as home prices. This type of modeling is called **regression**, hence the \"Regressor\" part of `RandomForestRegressor`. In general, regression means you are trying to predict real numbers like prices, failure rates, energy consumption, etc.\n",
    "\n",
    "Another common problem you'll see is making a choice between mutually exclusive outcomes. For example, spam detection is predicting if an email is \"spam\" or \"not spam\" based on the body text. Another common problem is identifying handwritten digits from images, choosing one of ten digits for any given image. This type of modeling is called **classification** because we are trying to choose one option from some set of classes.\n",
    "\n",
    "Classification is typically broken down further into binary and multiclass classification. Binary classification means there are two classes or conditions (\"spam\" or \"not spam\") while multiclass has more than two classes (ten digits). In general there are different approaches to the two types of classification, but most multiclass models will also work for binary problems.\n",
    "\n",
    "It's straightforward to build classification models using what you already know about scikit-learn. Instead of `RandomForestRegressor` for regression, we can use `RandomForestClassifier` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn-ensemble-randomforestclassifier)). \n",
    "\n",
    "As an example of classification with `RandomForestClassifier`, I'll use [this dataset](https://www.kaggle.com/iabhishekofficial/mobile-price-classification#train.csv) for predicting price ranges for phones. The targets in the data have values:\n",
    "\n",
    " * 0 (low cost)\n",
    " * 1 (medium cost)\n",
    " * 2 (high cost)\n",
    " * 3 (very high cost)\n",
    " \n",
    "For features, we have things like\n",
    "\n",
    "* battery_power: Total energy a battery can store in one time measured in mAh\n",
    "* blue: Has bluetooth or not\n",
    "* clock_speed: speed at which microprocessor executes instructions\n",
    "* dual_sim: Has dual sim support or not\n",
    "* fc: Front Camera mega pixels\n",
    "* four_g: Has 4G or not\n",
    "* ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change this to the appropriate path for the kernel\n",
    "data = pd.read_csv('/Users/mat/Projects/Kaggle/classification/mobile-price-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>756</td>\n",
       "      <td>2549</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.7</td>\n",
       "      <td>136</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>905</td>\n",
       "      <td>1988</td>\n",
       "      <td>2631</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>563</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0.9</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1263</td>\n",
       "      <td>1716</td>\n",
       "      <td>2603</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>615</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1216</td>\n",
       "      <td>1786</td>\n",
       "      <td>2769</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1821</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0.6</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1208</td>\n",
       "      <td>1212</td>\n",
       "      <td>1411</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  m_dep  \\\n",
       "0            842     0          2.2         0   1       0           7    0.6   \n",
       "1           1021     1          0.5         1   0       1          53    0.7   \n",
       "2            563     1          0.5         1   2       1          41    0.9   \n",
       "3            615     1          2.5         0   0       0          10    0.8   \n",
       "4           1821     1          1.2         0  13       1          44    0.6   \n",
       "\n",
       "   mobile_wt  n_cores     ...       px_height  px_width   ram  sc_h  sc_w  \\\n",
       "0        188        2     ...              20       756  2549     9     7   \n",
       "1        136        3     ...             905      1988  2631    17     3   \n",
       "2        145        5     ...            1263      1716  2603    11     2   \n",
       "3        131        6     ...            1216      1786  2769    16     8   \n",
       "4        141        2     ...            1208      1212  1411     8     2   \n",
       "\n",
       "   talk_time  three_g  touch_screen  wifi  price_range  \n",
       "0         19        0             0     1            1  \n",
       "1          7        1             1     0            2  \n",
       "2          9        1             1     0            2  \n",
       "3         11        1             0     0            2  \n",
       "4         15        1             1     0            1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['battery_power', 'blue', 'clock_speed', 'dual_sim', 'fc', 'four_g',\n",
       "       'int_memory', 'm_dep', 'mobile_wt', 'n_cores', 'pc', 'px_height',\n",
       "       'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time', 'three_g',\n",
       "       'touch_screen', 'wifi', 'price_range'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create our feature and targets the same as before using `train_test_split`. Creating and fitting the model is the same as well, except we're using `RandomForestClassifier` instead of `RandomForestRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for the targets and features\n",
    "y = data['price_range']\n",
    "X = data.drop('price_range', axis=1)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=7, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the classifier and fit it to our training data\n",
    "model = RandomForestClassifier(random_state=7, n_estimators=100)\n",
    "model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest metric for classification models is the **accuracy**, the number of correct predictions out of all predictions made. Scikit-learn provides `metrics.accuracy_score` to calculate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "# Predict classes given the validation features\n",
    "pred_y = model.predict(val_X)\n",
    "\n",
    "# Calculate the accuracy as our performance metric\n",
    "accuracy = metrics.accuracy_score(val_y, pred_y)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Our model did pretty well, correctly predicting around 86% of the price ranges in the validation data. It's often useful to look at where the model is failing with a **confusion matrix** which shows us how our model classified the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[130   6   0   0]\n",
      " [  4  91  15   0]\n",
      " [  0  21  98  12]\n",
      " [  0   0  10 113]]\n",
      "\n",
      "Normalized confusion matrix:\n",
      "[[0.95588235 0.04411765 0.         0.        ]\n",
      " [0.03636364 0.82727273 0.13636364 0.        ]\n",
      " [0.         0.16030534 0.7480916  0.09160305]\n",
      " [0.         0.         0.08130081 0.91869919]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix itself\n",
    "confusion = metrics.confusion_matrix(val_y, pred_y)\n",
    "print(f\"Confusion matrix:\\n{confusion}\")\n",
    "\n",
    "# Normalizing by the true label counts to get rates\n",
    "norm_confusion = confusion.astype('float') / confusion.sum(axis=1)[:, None]\n",
    "print(f\"\\nNormalized confusion matrix:\\n{norm_confusion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Include image of the confusion matrix here\n",
    "\n",
    "The rows of the confusion matrix are the true class and the columns are the predicted class. The diagonal tells us how many of each class the model predicted correctly. The off-diagonals show where the model is making wrong predictions, where it is \"confused.\" For example, looking at the first column and second row, we classified four phones that were actually low cost as medium cost. We see for classes 0 and 3, the low cost and highest cost phones, our model works really well, above 90% accurate. However, our model is weaker for medium and high cost phones. Note that incorrect predictions are only between adjacent classes. The model doesn't confuse low cost and very high cost phones.\n",
    "\n",
    "The diagonal of the normalized confusion matrix gives us the **true positive rate** for each of the classes. This is the fraction of positive cases in the validation data the model predicted to be positive. This value is important because the accuracy metric can sometimes hide information you care about. Occasionally you'll have unbalanced classes where you have many more examples of one class compared to another. For example, it's typical that when you're trying to diagnose a disease with a machine learning model, most examples in your data won't have that disease. Your model could be very good at identifying when people don't have the disease (negative cases), but poor at identifying positive cases. \n",
    "\n",
    "To illustrate this, assume negative cases make up 90% of your data and the classifier identifies negative cases at 95% accuracy.  Positive cases make up the other 10% of the data but your classifier only has a 25% accuracy for these cases. The overall accuracy would then be $90\\% * 95\\% + 25\\% * 5\\% = 88\\%$. The accuracy looks high and if that was the only metric you looked at you might think your classifier is doing pretty well. However, the goal is to identify when people have this disease, so 25% accuracy there is clearly not sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll often see the true positive rate called the **recall** which you can calculate using `metrics.recall_score`. For binary classification you'll get one value while for multiclass classification, you'll get values for each of the classes. For more information about recall and associated metrics check out [the Wikipedia page](https://en.wikipedia.org/wiki/Precision_and_recall) and [the scikit-learn tutorial](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class probabilities \n",
    "\n",
    "The output from `model.predict` is a single class per input. However, classification models actually calculate a *probability distribution* over the classes. Using `model.predict` simply returns the class with the highest probability. This might not be ideal based on how the decision affects your metrics or downstream measures. To get the probabilities themselves, use the `.predict_proba` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02 0.09 0.44 0.45]\n",
      " [0.02 0.06 0.22 0.7 ]\n",
      " [0.   0.17 0.61 0.22]\n",
      " ...\n",
      " [0.05 0.17 0.42 0.36]\n",
      " [0.45 0.34 0.13 0.08]\n",
      " [0.25 0.53 0.18 0.04]]\n"
     ]
    }
   ],
   "source": [
    "probs = model.predict_proba(val_X)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the probability the model assigns to each class. Often in business problems, decisions you make lead to different monetary returns. The expected return for a decision based on your classifier is the probability times the monetary return of that decision.\n",
    "\n",
    "Consider probabilities `[0.05 0.17 0.42 0.36]`. Assume the third option would result in \\\\$100 of profit while the fourth option would return \\\\$150 in profit. Then the expected monetary values are $0.42* \\$100 = \\$42$ and $0.36*\\$150 = \\$54$. Even though the third option has the highest probability, on average it would be better from a business perspective to choose the fourth option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, you'll get a chance to build your own classification model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
