{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "you've learned how to define a NN. it comes with entirely random weights. needs to be trained // needs to be exposed to the data so it can discover patterns\n",
    "\n",
    "in this lesson, you'll learn big picture about how this works.  then, in the next lesson, you'll learn how to apply these concepts to train a neural network.\n",
    "\n",
    "# Loss functions\n",
    "\n",
    "how can we tell how good our NN is? one way is to take the input, pass it to the neural netwoork, and then see how close the value that the network returns is to the true value.  the close it is, the better the network did.\n",
    "\n",
    "we can formalize this idea with a loss function.\n",
    "\n",
    "talk about loss function for multi-class classification only. \n",
    "\n",
    "there are many different loss functions. need to use something else for regression.\n",
    "\n",
    "# Stochastic gradient descent\n",
    "\n",
    "how can we minimize the loss? \n",
    "\n",
    "idea of loss as a surface.  each different set of parameters is different location on the surface.  want to find parameters that get you to the lowest valley.\n",
    "\n",
    "how do you do this? start with one set of parameters. get the loss. find the path of steepest descent. take a step. repeat.\n",
    "\n",
    "will actually do this in the next lesson.  keras takes care of all of this for you"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
