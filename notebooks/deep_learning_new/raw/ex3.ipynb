{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>\n",
    "- [ ] Introduction\n",
    "- [ ] Exercise 1\n",
    "  - [x] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 2\n",
    "  - [x] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 3\n",
    "  - [x] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Conclusion\n",
    "</mark>\n",
    "\n",
    "# Introduction #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Set Matplotlib defaults\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "\n",
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning_new.ex3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for a Neural Network #\n",
    "\n",
    "The data we'll use in this course will be *structured* data, or more specifically, *tabular* data, the kind you'd find in CSV files and Pandas DataFrames. Neural nets usually won't be able to work with the raw data, so you'll need to prepare the data before using it for training.\n",
    "\n",
    "Neural nets need numeric inputs and produce numeric outputs and generally perform best when all the features are all on a common scale near 0. This means you'll need to encode any non-numeric features and scale any numeric features. For numerics, [standardization](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) and [min-max scaling](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) to $[0, 1]$ can both be good choices. For categorical features with a moderate number of categories, [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) is a good choice. The [preprocessing module](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) in scikit-learn has almost everything you might need for preparing tabular data for neural networks.\n",
    "\n",
    "<mark><strong>TODO - add resources on Kaggle</strong>\n",
    "[Data Cleaning](https://www.kaggle.com/learn/data-cleaning)\n",
    "[Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning)\n",
    "</mark>\n",
    "\n",
    "# 1) Preparing the Fuel Economy Dataset\n",
    "\n",
    "In the *Fuel Economy* dataset your task is to predict the fuel economy of an automobile given features like its type of engine or the year it was made. \n",
    "\n",
    "First let's load the *Fuel Economy* dataset. Our target is the `FE` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fuel = pd.read_csv('../input/dl-course-data/fuel.csv')\n",
    "display(fuel.head())\n",
    "display(fuel.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features with `object` type are categorical; we will one-hot encode these. The numeric features we'll standardize. It's not as essential that the target be transformed, though doing so can significantly speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = fuel.copy()\n",
    "# Remove target\n",
    "y = X.pop('FE')\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(),\n",
    "     make_column_selector(dtype_include=np.number)),\n",
    "    (OneHotEncoder(sparse=False),\n",
    "     make_column_selector(dtype_include=object)),\n",
    ")\n",
    "\n",
    "# Split before applying any data-dependent transformations\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X, y, train_size=0.75)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "y_train = np.log(y_train) # log transform target instead of standardizing\n",
    "y_valid = np.log(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now our data is ready for the network! Run the next cell to get credit for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for credit!\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Input Shape\n",
    "\n",
    "What should be the value of `input_shape` in the first layer of the network? (Consider looking at the `shape` attribute of the appropriate dataset.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "input_shape = ____\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "input_shape = [13] # and check 14\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "input_shape = 50\n",
    "q_2.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "input_shape = [50]\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now our data is ready for a neural network!\n",
    "\n",
    "# 3) Define Neural Network Model\n",
    "\n",
    "Define a regression model with three hidden dense layers, each having 64 units and a ReLU activation. (Be sure to include the output layer, too!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model = ____\n",
    "\n",
    "# Check your answer\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "q_3.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "q_3.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "q_3.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])\n",
    "q_3.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Add Loss and Optimizer\n",
    "\n",
    "Now, using the `compile` method, add the Adam optimizer and MAE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "____\n",
    "\n",
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# missing loss or optimizer\n",
    "model.compile(\n",
    "    loss='mae'\n",
    ")\n",
    "q_4.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# wrong loss or optimizer\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='mse'\n",
    ")\n",
    "q_4.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae'\n",
    ")\n",
    "q_4.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Train Model\n",
    "\n",
    "Now train the network for 100 epochs with a batch size of 128. The input data is `X_train` with target `y_train`; the validation data is `X_valid` and `y_valid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "history = ____\n",
    "\n",
    "# Check your answer\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Wrong arguments\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=8,\n",
    "    epochs=4,\n",
    ")\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Missing validation data\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    ")\n",
    "q_5.assert_check_failed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "\n",
    "q_5.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_5.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_5.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Evaluate Training\n",
    "\n",
    "Finally, run the cell below to get a plot of the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 10. You can change this to get a different view.\n",
    "history_df.loc[10:, ['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you trained the model longer, would you expect the loss to decrease further?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_6.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate and Batch Size #\n",
    "\n",
    "Let's see how the learning rate and batch size affect how the training proceeds.\n",
    "\n",
    "# 7) Observe changes in the loss curve\n",
    "\n",
    "Change the values for `learning_rate` and `batch_size` and then run the cell. Pay attention to how the loss curve changes. Try the following combinations, or try some of your own:\n",
    "\n",
    "| `learning_rate` | `batch_size` |\n",
    "|-----------------|--------------|\n",
    "| 0.01            | 128          |\n",
    "| 0.0001          | 128          |\n",
    "| 1.0             | 128          |\n",
    "| 0.01            | 8            |\n",
    "| 0.01            | 1024         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Experiment with different values for the learning rate and batch size\n",
    "learning_rate = 0.01\n",
    "batch_size = 2048\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------#\n",
    "bias_init = keras.initializers.constant(y_train.median()) # you can ignore!\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=input_shape),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),    \n",
    "    layers.Dense(1, bias_initializer=bias_init)\n",
    "                 \n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mae'\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=100,\n",
    "    verbose=0, # turn off output\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[0:, 'loss'].plot()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What effect did changing the learning rate have? What effect does changing the batch size have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_7.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "py,md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
