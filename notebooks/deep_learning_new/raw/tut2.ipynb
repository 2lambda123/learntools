{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "# Framework\n",
    "\n",
    "prepare the data, then ...\n",
    "define, compile, fit (mae covered in intro to ml) and evaluate, predict\n",
    " \n",
    "how can we tell how good our NN is? one way is to take the input, pass it to the neural netwoork, and then see how close the value that the network returns is to the true value.  the close it is, the better the network did.\n",
    "\n",
    "we can formalize this idea with a loss function.\n",
    "\n",
    "there are many different loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "\n",
    "### Step 1: Prepare the data\n",
    "\n",
    "The first step is to prepare the data.\n",
    "- remove missing values\n",
    "- give categorical variables a one-hot encoding\n",
    "- split the data into training and test sets\n",
    "\n",
    "- deal with missing values\n",
    "- one-hot encode categorical features (in exercise: why not label encoding?)\n",
    "- normalize the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be entirely hidden (data prep)\n",
    "# need to mention removing missing values and also ohe-hot encoding categorical features\n",
    "# another example: https://www.tensorflow.org/tutorials/keras/regression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../input/auto_mpg.csv') \n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "numeric_features = ['cylinders', 'displacement', 'horsepower', \n",
    "                    'weight', 'acceleration', 'model year']\n",
    "df_numeric = df[numeric_features]\n",
    "df_origin = pd.get_dummies(df.origin, prefix='origin')\n",
    "X = pd.concat([df_numeric, df_origin], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "y = df.mpg\n",
    "\n",
    "# Split into training and test dataset\n",
    "#train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "#test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Initialize a neural network\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(64, activation='relu', input_shape=(9,)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compile the model\n",
    "\n",
    "Next, we compile the model.  We set tthe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=1000, verbose=0, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to use test data\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(predictions[:5].flatten()))\n",
    "print(list(y.head()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
