{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Welcome to Deep Learning! #\n",
    "\n",
    "- do deep learning for **regression** and **classification**\n",
    "- design **neural network architectures**\n",
    "- navigate the **loss landscape**\n",
    "- master **stochastic gradient descent**\n",
    "- solve real world problems\n",
    "\n",
    "You'll be prepared for deep learning if you've taken our *Introduction to Machine Learning* course.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "# The Linear Unit #\n",
    "\n",
    "A single neuron with one input looks like:\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/xxS8rzf.png\" width=\"250\" alt=\"Diagram of a linear unit.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>The Linear Unit\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "When reading this diagram think about the computation as flowing from left to right. The numbers on the connections we call **weights** and the values that flow from input to output we call **activations**. Notice that this neuron has a constant input of 1 attached; its connection has a special weight called the **bias**. This neuron has two weights, `w` and `b`.\n",
    "\n",
    "The rule is that whenever an activation flows through a connection, you multiply it by the weight, and to get the output of the unit you just sum up all of the inputs. So, this unit computes a function like $y = w x + b$, or in Python `output = w * input + b`.\n",
    "\n",
    "# Example #\n",
    "\n",
    "Say the weights on our neuron happened to be `w=3` and `b=2`. What would we get if we plug in `x=-4`?\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/.png\" width=\"300\" alt=\"Diagram of neural computation.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>Computing with the linear unit.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Which checks with our formula: $y = 3(-4) + 2 = -10$.\n",
    "\n",
    "(By the way, running all of your training data through a network like this is sometimes called doing the *forward pass*.)\n",
    "\n",
    "# A Linear Unit Fits a Line #\n",
    "\n",
    "Most of the problems we'll work in this course will be *curve-fitting* problems. Given some data-points, we want to draw a curve that runs through the points as close as possible. (These are also called *regression* problems.)\n",
    "\n",
    "What kind of curve does a linear unit fit? Does the formula $y=w x + b$ look familiar? It's an equation of a line! It's the slope-intercept equation, where $w$ is the slope and $b$ is the y-intercept. That's why we call it the <em>linear</em> unit.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/.png\" width=\"300\" alt=\"Three input connections: x0, x1, and x2, along with the bias.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center><strong>Left: </strong>The untrained linear unit. <strong>Right: </strong>The trained linear unit.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "When first created, a neuron has its weights set randomly. The goal of training is to find values for the weights that fit the curve. For our linear unit, we're trying to find the best slope ($w$) and y-intercept ($b$).\n",
    "\n",
    "# Multiple Inputs #\n",
    "\n",
    "What if we wanted to fit a curve to more than one input? That's easy enough. We can just add more input connections to the neuron. To find the output, multiply each input to its connection weight and then add them all together.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/.png\" width=\"300\" alt=\"Three input connections: x0, x1, and x2, along with the bias.\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>A linear unit with three inputs.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "The formula for this neuron would be $y = w_0 x_0 + w_1 x_1 + b$. A linear unit with two inputs will fit a plane. (And one more more inputs than that will fit a *hyperplane*!)\n",
    "\n",
    "# Example - Red Wine Quality #\n",
    "\n",
    "Now let's see this in action! Our goal in this example will be to predict the perceived quality of a wine (on a scale of 3-8) given its *residual sugar* content, which is the amount of grape sugar remaining after fermentation. High levels of residual sugar make a wine *sweet* while low levels make it *dry*. The data is from the *Red Wine Quality* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE$\n",
    "import pandas as pd\n",
    "\n",
    "red_wine = pd.read_csv('../input/dl-course-data/dl-course-data/red-wine.csv')\n",
    "\n",
    "# Create training and validation splits\n",
    "df_train = red_wine.sample(frac=0.7, random_state=0)\n",
    "\n",
    "# Neural networks perform best when the data is in on a common scale.\n",
    "# We will rescale each feature into the interval $[0, 1]$.\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "\n",
    "# Split feature and target\n",
    "x_train = df_train['residual sugar']\n",
    "y_train = df_train['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Keras, you can create a model with a single linear unit using what's called a `Dense` layer. Most neural networks are built by stacking layers of neurons that connect in a particular way, which we'll learn about in Lesson 2. (Stacking layers is what `Sequential` does.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Create a network with 1 linear unit\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When first created, a model has its weights initialized randomly. We'll need to fit it to the training data before we make predictions, which is what this next hidden cell will do. Take a look now if you like, but we'll go over the training process fully in Lesson 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$HIDE$\n",
    "# Add the optimizer and loss function\n",
    "model.compile(\n",
    "    optimizer='sgd',\n",
    "    loss='mse',\n",
    ")\n",
    "\n",
    "# Fit the network to the training data\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=256,\n",
    "    epochs=50,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote style=\"margin-right:auto; margin-left:auto; background-color: #ebf9ff; padding: 1em; margin:24px;\">\n",
    "    <strong>Why Not Just Use Scikit-Learn?</strong><br>\n",
    "If you've studied machine learning much, you've probably come across linear regression. A single `Dense(units=1)` layer, in fact, creates a linear regression model equivalent to those in scikit-learn. So why go to all the trouble?\n",
    "\n",
    "It's always good to start your model development with the simplest model possible. For one, this can help you check that there aren't any bugs in the rest of your code. Secondly, it gives you a solid baseline to start from. You know how well linear regression does -- can deep learning do better?\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
