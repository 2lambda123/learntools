{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "integral-fifteen",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "Run this cell to set everything up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.time_series.ex4 import *\n",
    "\n",
    "# Setup notebook\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n",
    "from statsmodels.tsa.tsatools import lagmat\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\n",
    "    \"figure\",\n",
    "    autolayout=True,\n",
    "    figsize=(11, 4),\n",
    "    titlesize=18,\n",
    "    titleweight='bold',\n",
    ")\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=16,\n",
    "    titlepad=10,\n",
    ")\n",
    "plot_params = dict(\n",
    "    color=\"0.75\",\n",
    "    style=\".-\",\n",
    "    markeredgecolor=\"0.25\",\n",
    "    markerfacecolor=\"0.25\",\n",
    "    legend=False,\n",
    ")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "def lagplot(x, y=None, lag=1, standardize=False, ax=None, **kwargs):\n",
    "    from matplotlib.offsetbox import AnchoredText\n",
    "    x_ = x.shift(lag)\n",
    "    if standardize:\n",
    "        x_ = (x_ - x_.mean()) / x_.std()\n",
    "    if y is not None:\n",
    "        y_ = (y - y.mean()) / y.std() if standardize else y\n",
    "    else:\n",
    "        y_ = x\n",
    "    corr = y_.corr(x_)\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    scatter_kws = dict(\n",
    "        alpha=0.75,\n",
    "        s=3,\n",
    "    )\n",
    "    line_kws = dict(color='C3', )\n",
    "    ax = sns.regplot(x=x_,\n",
    "                     y=y_,\n",
    "                     scatter_kws=scatter_kws,\n",
    "                     line_kws=line_kws,\n",
    "                     lowess=True,\n",
    "                     ax=ax,\n",
    "                     **kwargs)\n",
    "    at = AnchoredText(\n",
    "        f\"{corr:.2f}\",\n",
    "        prop=dict(size=\"large\"),\n",
    "        frameon=True,\n",
    "        loc=\"upper left\",\n",
    "    )\n",
    "    at.patch.set_boxstyle(\"square, pad=0.0\")\n",
    "    ax.add_artist(at)\n",
    "    ax.set(title=f\"Lag {lag}\", xlabel=x_.name, ylabel=y_.name)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_lags(x, y=None, lags=6, nrows=1, lagplot_kwargs={}, **kwargs):\n",
    "    import math\n",
    "    kwargs.setdefault('nrows', nrows)\n",
    "    kwargs.setdefault('ncols', math.ceil(lags / nrows))\n",
    "    kwargs.setdefault('figsize', (kwargs['ncols'] * 2, nrows * 2 + 0.5))\n",
    "    fig, axs = plt.subplots(sharex=True, sharey=True, squeeze=False, **kwargs)\n",
    "    for ax, k in zip(fig.get_axes(), range(kwargs['nrows'] * kwargs['ncols'])):\n",
    "        if k + 1 <= lags:\n",
    "            ax = lagplot(x, y, lag=k + 1, ax=ax, **lagplot_kwargs)\n",
    "            ax.set_title(f\"Lag {k + 1}\", fontdict=dict(fontsize=14))\n",
    "            ax.set(xlabel=\"\", ylabel=\"\")\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    plt.setp(axs[-1, :], xlabel=x.name)\n",
    "    plt.setp(axs[:, 0], ylabel=y.name if y is not None else x.name)\n",
    "    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def make_lag_features(y, lags):\n",
    "    name = 'lag' if lags > 0 else 'lead'\n",
    "    steps = range(1, lags+1) if lags > 0 else range(-1, lags-1, -1)\n",
    "    return pd.concat(\n",
    "        [y.shift(i, freq='infer') for i in steps],\n",
    "        axis=1,\n",
    "        join='outer',\n",
    "        keys=[f'{y.name}_{name}_{i if lags > 0 else -i}' for i in steps],\n",
    "    )\n",
    "\n",
    "\n",
    "comp_dir = Path('../input/store-sales-time-series-forecasting')\n",
    "\n",
    "store_sales = pd.read_csv(\n",
    "    comp_dir / 'train.csv',\n",
    "    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'sales': 'float32',\n",
    "        'onpromotion': 'float32',\n",
    "    },\n",
    "    parse_dates=['date'],\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "store_sales['date'] = store_sales.date.dt.to_period('D')\n",
    "store_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n",
    "average_sales = store_sales.groupby('date').mean().squeeze().loc['2017']\n",
    "\n",
    "oil = pd.read_csv(\n",
    "    comp_dir / \"oil.csv\",\n",
    "    dtype='float32',\n",
    "    parse_dates=[\"date\"],\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "oil = oil.set_index('date').to_period('D').squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-directive",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 250\n",
    "time = np.linspace(0, 100, num=N)\n",
    "error_1 = np.random.normal(size=N, scale=10.0)\n",
    "error_2 = np.random.normal(size=N, scale=2.0)\n",
    "\n",
    "trending = pd.Series(time + error_1)\n",
    "seasonal = pd.Series(10 * np.sin(20*2*np.pi*time/100) + error_2)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(11, 6))\n",
    "ax1 = trending.plot(ax=ax1)\n",
    "ax1.set_title(\"Trending\")\n",
    "ax2 = seasonal.plot(ax=ax2)\n",
    "ax2.set_title(\"Seasonal\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_lags(trending, lags=8, nrows=2)\n",
    "fig.suptitle('Trending', fontweight='bold', fontsize=16);\n",
    "\n",
    "fig = plot_lags(seasonal, lags=8, nrows=2)\n",
    "fig.suptitle('Seasonal', fontweight='bold', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-grass",
   "metadata": {},
   "source": [
    "# 1) Examine the relationship between time and serial dependence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-monthly",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-engineering",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Since we're interested in what *new* information we can capture through lag features, let's remove from *Store Sales* the parts we've already captured: the trend and the seasons. Removing from a series its trend or seasons is called **detrending** or **deseasonalizing** the series.\n",
    "\n",
    "Use the code in the next cell to deseasonalize *Average Store Sales*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = average_sales.loc[:, 'sales']\n",
    "\n",
    "fourier = CalendarFourier(freq='M', order=4)\n",
    "dp = DeterministicProcess(\n",
    "    constant=True,\n",
    "    index=y.index,\n",
    "    order=1,\n",
    "    seasonal=True,\n",
    "    drop=True,\n",
    "    additional_terms=[fourier],\n",
    ")\n",
    "X_time = dp.in_sample()\n",
    "X_time['NewYearsDay'] = (X_time.index.dayofyear == 1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_time, y)\n",
    "sales_deseasoned = y - model.predict(X_time)\n",
    "sales_deseasoned.name = 'sales_deseasoned'\n",
    "\n",
    "ax = sales_deseasoned.plot()\n",
    "ax.set_title(\"Average Store Sales (deseasonalized)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-first",
   "metadata": {},
   "source": [
    "Now let's examine our deseasonalized series for serial dependence.\n",
    "\n",
    "First take a look at the partial autocorrelation correlogram. Do any of the lags seem significant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(sales_deseasoned, lags=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-cream",
   "metadata": {},
   "source": [
    "Now look at the lag plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lags(sales_deseasoned, lags=8, nrows=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-offering",
   "metadata": {},
   "source": [
    "Do you notice any potentially useful relationships that weren't apparent from the correlogram?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-census",
   "metadata": {},
   "source": [
    "# 2) Examine serial dependence in *Store Sales*\n",
    "\n",
    "After you've thought about your answer, run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the solution (Run this cell to receive credit!)\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-british",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "Recall from the tutorial that a *leading indicator* is a series that can be used to predict the target at a future time -- a leading indicator provides \"advance notice\" of changes in the target.\n",
    "\n",
    "The competition dataset includes two time series that could potentially be useful as leading indicators: \n",
    "- `onpromotion`: number of items on a special promotion that day, and\n",
    "- `oil`: daily oil price.\n",
    "\n",
    "We have values for both of these series throughout the training and test periods.\n",
    "\n",
    "Use the next cell to examine lags for `onpromotion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "onpromotion = average_sales.loc[:, 'onpromotion']\n",
    "\n",
    "plot_lags(onpromotion['2017-01-02' :], y['2017-01-02' :], lags=8, nrows=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-preservation",
   "metadata": {},
   "source": [
    "And use this cell to examine lags for `oil`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oil, oil = y.align(oil, join='inner')\n",
    "\n",
    "plot_lags(oil, y_oil, lags=8, nrows=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-essence",
   "metadata": {},
   "source": [
    "# 3) Examine time series features\n",
    "\n",
    "Which of these series do the plots suggest might be useful to include as features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-fifty",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "# 4) Create time series features\n",
    "\n",
    "Create the features indicated in the solution to Question 3. If no features from that series would be useful, use an empty dataframe `pd.DataFrame()` as your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_lags = ____\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X_promo = ____\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X_oil = ____\n",
    "\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#X = pd.concat([X_lags, X_promo, X_oil], axis=1)\n",
    "\n",
    "# Check your answer\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "X_lags = make_lag_features(y_deseason, lags=1)\n",
    "\n",
    "X_promo = pd.concat([\n",
    "    make_lag_features(onpromotion, lags=1),\n",
    "    onpromotion,\n",
    "    make_lag_features(onpromotion, lags=-1),\n",
    "], axis=1)\n",
    "\n",
    "X_oil = pd.DataFrame()\n",
    "\n",
    "X = pd.concat([X_time, X_lags, X_promo, X_oil], axis=1).dropna()\n",
    "y, X = y.align(X, join='inner')\n",
    "\n",
    "q_4.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-representative",
   "metadata": {},
   "source": [
    "Use the code in the next cell if you'd like to see predictions from the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=30, shuffle=False)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "y_fit = pd.Series(model.predict(X_train), index=X_train.index).clip(0.0)\n",
    "y_pred = pd.Series(model.predict(X_valid), index=X_valid.index).clip(0.0)\n",
    "\n",
    "rmsle_train = mean_squared_log_error(y_train, y_fit) ** 0.5\n",
    "rmsle_valid = mean_squared_log_error(y_valid, y_pred) ** 0.5\n",
    "print(f'Training RMSLE: {rmsle_train:.5f}')\n",
    "print(f'Validation RMSLE: {rmsle_valid:.5f}')\n",
    "\n",
    "ax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\n",
    "ax = y_fit.plot(ax=ax, label=\"Fitted\", color='C0')\n",
    "ax = y_pred.plot(ax=ax, label=\"Forecast\", color='C3')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-gentleman",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "\n",
    "# 5) Create statistical features\n",
    "\n",
    "Winners of Kaggle forecasting competitions have often included moving averages and other rolling statistics in their feature sets. Such features seem to be especially useful when used with GBDT algorithms like XGBoost.\n",
    "\n",
    "In Lesson 2 you learned how to compute moving averages to estimate trends. Computing rolling statistics to be used as features is similar except we need to take care to avoid lookahead leakage. First, the result should be set at the right end of the window instead of the center -- that is, we should use `center=False` (the default) in the `rolling` method. Second, the target should be lagged a step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-undergraduate",
   "metadata": {},
   "source": [
    "Edit the code in the next cell to create the following features:\n",
    "- 14-day rolling median (`median`) of lagged target\n",
    "- 7-day rolling standard deviation (`std`) of lagged target\n",
    "- 7-day sum (`sum`) of items \"on promotion\", with centered window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lag = average_sales.loc[:, 'sales'].shift(1)  # lagged target\n",
    "onpromo = average_sales.loc[:, 'onpromotion']  # items on promotion\n",
    "\n",
    "# Statistical features\n",
    "X_stats = pd.concat({\n",
    "    # 28-day mean of lagged target\n",
    "    'mean_7': y_lag.rolling(7).mean(),\n",
    "    # YOUR CODE HERE: Edit to create the rolling statistic\n",
    "    # 14-day median of lagged target\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#    'median_14': ____,\n",
    "    # 7-day rolling standard deviation of lagged target\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#    'std_7': ____,\n",
    "    # 7-day sum of promotions with centered window\n",
    "#_UNCOMMENT_IF(PROD)_\n",
    "#    'promo_7': ____,\n",
    "}, axis=1).dropna()\n",
    "\n",
    "\n",
    "# Check your answer\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_5.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_5.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "y_lag = average_sales.loc[:, 'sales'].shift(1)\n",
    "onpromo = average_sales.loc[:, 'onpromotion']\n",
    "\n",
    "X_stats = pd.concat({\n",
    "    'mean_7': y_lag.rolling(7).mean(),\n",
    "    'median_14': y_lag.rolling(14).median(),\n",
    "    'std_7': y_lag.rolling(7).std(),\n",
    "    'promo_7': onpromo.rolling(7, center=True).sum(),\n",
    "}, axis=1).dropna()\n",
    "\n",
    "\n",
    "q_5.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-concentration",
   "metadata": {},
   "source": [
    "Check out the Pandas [`Window` documentation](https://pandas.pydata.org/pandas-docs/stable/reference/window.html) for more statistics you can compute. Also try \"exponential weighted\" windows by using `ewm` in place of `rolling`; exponential decay is often a more realistic representation of how effects propagate over time.\n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "\n",
    "# (Optional) Explore non-linear dynamics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-sharing",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regional-poster",
   "metadata": {},
   "source": [
    "# Keep Going #"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
