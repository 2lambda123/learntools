{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "Deep learning has revolutionized computer vision, and it’s the core technology behind capabilities like self-driving cars.\n",
    "\n",
    "<center><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Google_driverless_car_at_intersection.gk.jpg/640px-Google_driverless_car_at_intersection.gk.jpg alt='Google self driving car'></center>\n",
    "\n",
    "This series will quickly get you up-to-speed in deep learning. We’ll cover topics in a different order than most academic sources.  Other courses start with technical or theoretical details and eventually build up to something you can apply. In this series, you’ll start running powerful models soon to get hands-on experience using deep learning. Then we’ll come back to the technical details you need for fine-tuning your models and addressing novel applications.\n",
    "\n",
    "In this lesson, you will learn about convolutions, the basic building block for deep learning models in computer vision (and many other applications). After that, we'll quickly progress to using world-class deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow and Keras\n",
    "\n",
    "We’ll use TensorFlow 2.0 for this course. Over the last few years, TensorFlow has been the most popular tool for deep learning. This year, TensorFlow is taking a huge step forward in useability by incorporating the Keras API into the framework. This new version promises to help beginners be productive as fast as possible while being flexible enough for experts to implement novel models.\n",
    "\n",
    "<img src=https://i.imgur.com/VB1Bkp4.png alt=\"TensorFlow and Keras logos\" width=500px>\n",
    "\n",
    "The standalone Keras library still exists. Keras isn't so much a framework, but an API specification that works with multiple deep learning frameworks as backends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Computer Vision\n",
    "\n",
    "Your machine learning experience so far has probably focused on tabular data, like you’d work with in Pandas. We’ll be doing deep learning with images, so we’ll start with an overview of how images are stored for machine learning.\n",
    "\n",
    "Here I have the image of a handwritten digit, the number two. It is composed of pixels. Some pixels are completely black, some are completely white, and some are varying shades of grey.  The pixels are arranged in rows and columns, so it is a natural way to store them in a matrix. The matrix would have might look roughly this this. Each value represents the darkness of a pixel in the image. \n",
    "\n",
    "<img src=https://i.imgur.com/CsDt0Fi.png width=400px alt='An image of the number 2 represented as a matrix of numbers'>\n",
    "\n",
    "The number in the upper left of the matrix indicates how dark the upper-left pixel in the image is.  Go down a row in the matrix, and we get the intensity of the pixel one row down in the image.  I made this small matrix to fit on your screen. So the real matrix would be larger than what you see here, but have the same format.\n",
    "\n",
    "Color images have an extra dimension. For each pixel, we store how red that pixel is, how green it is, and how blue it is.  It’s like a stack of three matrices. Tensor is the word for something that is like a matrix, but which can have any number of dimensions. So we’ll call them tensors moving forward.\n",
    "\n",
    "<img src=https://i.imgur.com/8xgVrMJ.png width=400px alt='A color image of a dog represented as a tensor with red, blue, and green channels'>\n",
    "\n",
    "For now, let’s go back to the greyscale image, which has a 2D tensor representing the darkness of each pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "\n",
    "Today’s deep learning models apply something called convolutions to this type of tensor. A convolution is a small tensor that can be multiplied over little sections of the main image.  \n",
    "\n",
    "Here is an example of a convolution.  Convolutions are also called filters, because depending on the values in that convolutional array, it can pick out specific patterns in from the image.\n",
    "\n",
    "$$\n",
    "\\begin{array}{ | r | r | }\n",
    "\\hline\n",
    "  1.5 & 1.5 \\\\ \\hline\n",
    "  -1.5 & -1.5 \\\\ \\hline\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "I propose that the convolution you see here is a horizontal line detector.  If you multiply it on a part of the image that has a horizontal line, you get a large value. If you multiply it on a part of the image without a horizontal line, it gives a value close to 0. Let’s see a simple example.\n",
    "\n",
    "Here we have a part of the image where all the pixels are the same intensity.  We do array-style multiplication, multiplying the upper left values in each tensor, then the upper right values in each tensor, and so on. Then we sum the results.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "       \\begin{array}{ | r | r | }\n",
    "        \\hline\n",
    "        1.5 & 1.5 \\\\ \\hline\n",
    "        -1.5 & -1.5 \\\\ \\hline\n",
    "       \\end{array} \n",
    "  \\odot \\begin{array}{ | l | l | l | l |}\n",
    "        \\hline\n",
    "        200 & 200 & \\dots & \\dots \\\\ \\hline\n",
    "        200 & 200 & \\dots & \\dots \\\\ \\hline\n",
    "        \\dots & \\dots & \\dots & \\dots \\\\ \\hline\n",
    "        \\dots & \\dots & \\dots & \\dots \\\\ \\hline\n",
    "       \\end{array}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "1.5*200 + 1.5*200 + -1.5*200 + -1.5*200 = 0\n",
    "$$\n",
    "\n",
    "For this particular convolution and this set of pixel values, we get a result of 0. Doing the same thing for a completely white area, we'd get 1.5 times zero in each cell. So we get 0 again.\n",
    "\n",
    "Let’s use the same convolution where we have dark pixels above some light pixels.  In other words, over a horizontal line. This time we get a bit value. So, this convolution really does work at detecting horizontal lines.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "       \\begin{array}{ | r | r | }\n",
    "        \\hline\n",
    "        1.5 & 1.5 \\\\ \\hline\n",
    "        -1.5 & -1.5 \\\\ \\hline\n",
    "       \\end{array} \n",
    "  \\odot \\begin{array}{ | l | l | l | l |}\n",
    "        \\hline\n",
    "        200 & 200 & \\dots & \\dots \\\\ \\hline\n",
    "        0 & 0 & \\dots & \\dots \\\\ \\hline\n",
    "        \\dots & \\dots & \\dots & \\dots \\\\ \\hline\n",
    "        \\dots & \\dots & \\dots & \\dots \\\\ \\hline\n",
    "       \\end{array}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "1.5*200 + 1.5*200 + -1.5*0 + -1.5*0 = 600\n",
    "$$\n",
    "\n",
    "This particular convolution was two rows by two columns. We could use other size convolutions, like three by three. The numeric values in the convolution determine what pattern it detects.  In practice, you won’t choose those numbers when using deep learning models. We’ll come back to show how you get those numbers. \n",
    "\n",
    "But we’ll start with a short exercise to see convolutions in action. Once you’ve done that exercise and you have a good grasp of a single convolution, you’ll learn how combining many convolutions can create a powerful models. Read on below to get started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn\n",
    "After the video, **[test your understanding of convolutions](#$EXERCISE_FORKING_URL$)**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
