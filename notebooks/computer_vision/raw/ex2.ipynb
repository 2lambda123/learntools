{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status #\n",
    "\n",
    "- [x] Outline\n",
    "- [ ] Introduction\n",
    "- [ ] Exercise 1\n",
    "  - [x] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 2\n",
    "  - [x] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 3\n",
    "  - [x] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 4\n",
    "  - [ ] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Conclusion\n",
    "\n",
    "# Introduction #\n",
    "\n",
    "In these exercises, you'll explore the feature extraction operations on your own.\n",
    "\n",
    "Run the cell below to get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.computer_vision.ex2 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Transformations #\n",
    "\n",
    "Run the following cell to load an image we'll use for the next few exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "image_path = './images/car_feature.jpg'\n",
    "image = np.array(Image.open(image_path)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define Kernel\n",
    "\n",
    "First define a kernel. You have your choice of what kind of kernel to apply. There are a couple cells below that can run to get some ideas. Once you've found one you like, just type in values here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Define this just like you would a numpy array.\n",
    "kernel = tf.constant(\n",
    "    ____\n",
    ")\n",
    "\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# The emboss kernel\n",
    "kernel = tf.constant([\n",
    "    [-2, -1, 0],\n",
    "    [-1, 1, 1],\n",
    "    [0, 1, 2],\n",
    "])\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to see some standard kernels used in image processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visiontools import edge, bottom_sobel, emboss_se, sharpen\n",
    "\n",
    "kernels = [edge, bottom_sobel, emboss, sharpen]\n",
    "names = [\"Edge Detect\", \"Bottom Sobel\", \"Emboss\", \"Sharpen\"]\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i, (kernel, name) in enumerate(zip(kernels, names)):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    visiontools.show_kernel(kernel)\n",
    "    plt.title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, run this cell to see a random kernel from the pretrained VGG16 model we saw in Lesson 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# choose a random convolutional layer\n",
    "layer = random.choice(\n",
    "    [layer.name for layer in vgg.layers\n",
    "     if layer.__class__.__name__ is 'Conv2D']\n",
    ")\n",
    "# and get its filters\n",
    "filters = layer.get_filters()[0]\n",
    "# choose an input channel\n",
    "input_index = np.random.randint(0, filters.shape[2])\n",
    "# choose a filter\n",
    "filter_index = np.random.randint(0, filters.shape[3])\n",
    "\n",
    "# get kernel and normalize\n",
    "krn = filters[:, :, input_index, filter_index]\n",
    "krn -= krn.mean()\n",
    "krn /= (krn.std() + 1e-5)\n",
    "krn = krn.round(decimals=1)\n",
    "\n",
    "print(\"Layer: {}  Input Channel: {}  Filter: {}\"\n",
    "      .format(layer.name, input_index, filter_index))\n",
    "visiontools.show_kernel(krn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Apply Convolution\n",
    "\n",
    "First run this cell to do some reformatting for TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat for batch compatibility.\n",
    "image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "kernel = tf.reshape(krn, [*krn.shape, 1, 1])\n",
    "kernel = tf.cast(kernel, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now filter the image with your kernel using the convolution function in `tf.nn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Apply convolution to image\n",
    "image_filter = ____\n",
    "\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "image_filter = tf.nn.conv2d(\n",
    "    input=image,\n",
    "    filters=kernel,\n",
    "    strides=1,\n",
    "    padding='SAME',\n",
    ")\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to see the result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    # Reformat for plotting\n",
    "    tf.squeeze(image_filter)\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Apply ReLU\n",
    "\n",
    "Now detect the feature with `tf.nn.relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "image_detect = ___\n",
    "\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "image_detect = tf.nn.relu(image_filter)\n",
    "q_3.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to see the effect of the ReLU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    # Reformat for plotting\n",
    "    tf.squeeze(image_detect)\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore some Kernels #\n",
    "\n",
    "### 4) View Kernels in VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n",
    "\n",
    "Here is a fun website where you can interactively explore some common kernels: [Image Kernels Explained Visually](https://setosa.io/ev/image-kernels/).\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
