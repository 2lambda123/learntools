{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In the last lesson we saw that a convnet performs feature extraction through a sequence of three operations -- filter, detect, condense. In this lesson, we'll describe these operations in terms of **activations** and **weights** as you learned about in *Introduction to Deep Learning*. This will also be an introduction to **convolution**, **ReLU**, and **pooling**, which we will continue in Lesson 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter #\n",
    "\n",
    "Recall that a **convolutional layer** will typically carry out the filtering step. The **weights** a network learns during training are primarily contained in its convolutional layers. We can represent them as small arrays called **kernels**\n",
    "\n",
    "<!--TODO: a kernel-->\n",
    "\n",
    "A convolutional layer will usually contain many kernels. They are what determine the kind of filtering that occurs.\n",
    "\n",
    "The pattern of numbers in the array defines the effect of a kernel. You can think about a kernel as a kind of polarized lens, letting through only a certain pattern of information. The kernel above will filter for vertical lines.\n",
    "\n",
    "The **activations** in the network we call **feature maps**. They are what result when we apply a filter to an image; they are the visual features the network extracts.\n",
    "\n",
    "The first feature maps are the color channels of the image. A grayscale image has one channel.\n",
    "\n",
    "<!--TODO: grayscale channel-->\n",
    "\n",
    "A color image will have three channels.\n",
    "\n",
    "<!--TODO: color channel -->\n",
    "\n",
    "As more extraction operations are applied, the feature maps become increasingly refined.\n",
    "\n",
    "<!--TODO: feature maps simple to complex-->\n",
    "\n",
    "Here are some examples of kernels applied to feature maps:\n",
    "\n",
    "<!--TODO: kernels applied to feature maps-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels: The Depth Dimension ##\n",
    "\n",
    "*(This section makes some terminology we'll be using a bit more precise. It's not essential to anything that follows, so feel free to skip it if you want. The important thing is just to understand that a convolutional layer contains many kernels.)*\n",
    "\n",
    "When an image first enters a network, it exists as a set of channels. We usually think about the channels as being the *depth* dimension, with the width and height as the two spatial dimensions. In the language of TensorFlow, an image is a tensor with shape `[height, width, channels]`.\n",
    "\n",
    "<!--TODO: shape of an image-->\n",
    "\n",
    "A convolutional layer will apply a kernel to each channel in the input, and the collection of these kernels is what we call a **filter**. One filter produces one feature map.\n",
    "\n",
    "<!--TODO: filter to feature map-->\n",
    "\n",
    "A convolutional layer may produce many feature maps. So, if a convolutional layer producing 16 feature maps is applied to an image with 3 channels, it will contain 16*3=48 kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect #\n",
    "\n",
    "After filtering, the feature maps pass through the activation function. The **ReLU activation** has a graph like this:\n",
    "\n",
    "<!--TODO: ReLU -->\n",
    "\n",
    "(*ReLU* stands for *Rectified Linear Unit*.)\n",
    "\n",
    "You could think about the activation function as normalizing the pixel values according to some measure of importance. The ReLU function says that negative values are not important and so sets them to 0. (\"Everything unimportant is equally unimportant.\")\n",
    "\n",
    "Like other activation functions used in neural networks, the ReLU function is *nonlinear*. Essentially this means that the total effect of all the layers in the network is different than what we would get by just adding the effects together, becoming, in effect, a network with one layer only.\n",
    "\n",
    "The ReLU function ensures that only pixels with positive activation remain in the feature map. This is desireable because we don't want any negative activations destroying the features we detect deeper in the network, which is what would happen if we simply added them together.\n",
    "\n",
    "Here is ReLU applied to some feature maps. Notice how it succeeds at isolating the feature of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condense #\n",
    "\n",
    "Notice that after applying the ReLU function the feature map ends up with a lot of \"dead space,\" that is, large areas containing only 0's.\n",
    "\n",
    "<!--TODO: feature map with 0s-->\n",
    "\n",
    "Carrying these 0 activations through the entire network would be very wasteful of memory resources. Instead, we would like to **condense** the feature map to retain only the actual feature.\n",
    "\n",
    "This is what the pooling operation does, in particular, the **maximum pooling** operation. Max pooling will take a block of activations in the original feature map and replace them with the maximum activation in that block.\n",
    "\n",
    "<!--TODO: max pooling-->\n",
    "\n",
    "Altogether, the extraction operation looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - Apply Operations #\n",
    "\n",
    "Let's apply these operations to an image to get a feel for what they do.\n",
    "\n",
    "Here is the image we'll use for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by importing the extraction operations from the Keras backend. These are the primitive functions the layers of the network apply to their inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import conv2d, relu, pool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the filtering step, we'll define a kernel and then apply it to the image by convolution. The kernel in this case is an \"edge detection\" kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "kernel = tf.constant([[-1, -1, -1],\n",
    "                      [-1,  8, -1],\n",
    "                      [-1, -1, -1]])\n",
    "\n",
    "img = conv2d(img, kernel=kernel)\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the detection step with the ReLU function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = relu(img)\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last is condensing with maximum pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pool2d(img, pool_mode='max')\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - Visualize Activations #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be instructive to look at the activations an image produces in a network throughout its layers. We've included a function in a utility script that will plot them for you. Let's look at some activations in the network from Lesson 2 (using the same image as before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visiontools import plot_activations\n",
    "\n",
    "plot_activations(img, model=convolutional_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the features extracted become more and more refined as the activations flow deeper into the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
