{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status #\n",
    "\n",
    "- [x] Outline\n",
    "- [ ] Introduction\n",
    "- [ ] Exercise 1\n",
    "  - [ ] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 2\n",
    "  - [x] Code\n",
    "  - [x] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 3\n",
    "  - [x] Code\n",
    "  - [x] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 4\n",
    "  - [ ] Code\n",
    "  - [x] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Conclusion\n",
    "\n",
    "# Introduction #\n",
    "\n",
    "Run the cell below to set everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.computer_vision.ex3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Apply Pooling to Condense\n",
    "\n",
    "Run this cell to get back to where you left off in the previous lesson. There is a kernel predefined for you, but feel free to change it to the one you were using before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the last step in the sequence. Apply maximum pooling with `tf.nn.pool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "image_condense = ____\n",
    "\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "image_condense = tf.nn.pool(\n",
    "    input=image_detect, # image in the Detect step above\n",
    "    window_shape=(2, 2),\n",
    "    pooling_type='MAX',\n",
    "    # we'll see what these do in the next lesson!\n",
    "    strides=(2, 2),\n",
    "    padding='SAME',\n",
    ")\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to see what maximum pooling did to the feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(\n",
    "    # Reformat for plotting\n",
    "    tf.squeeze(image_detect)\n",
    ")\n",
    "plt.axis('off')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explore Invariance\n",
    "\n",
    "This next code cell will randomly apply a small shift to the circle and then condense the image several times with maximum pooling. Run this cell a few times and make note of the feature produced at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEATS = 4\n",
    "SIZE = [64, 64]\n",
    "\n",
    "# Create a randomly shifted circle\n",
    "image = visiontools.circle(SIZE, r_shrink=4, val=1)\n",
    "image = tf.expand_dims(image, axis=-1)\n",
    "image = visiontools.random_transform(image, jitter=3, fill_method='replicate')\n",
    "image = tf.squeeze(image)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, REPEATS+1, 1)\n",
    "plt.imshow(image, vmin=0, vmax=1)\n",
    "plt.title(\"Original\\nShape: {}x{}\".format(image.shape[0], image.shape[1]))\n",
    "plt.axis('off')\n",
    "\n",
    "# Now condense with maximum pooling several times\n",
    "for i in range(REPEATS):\n",
    "    ax = plt.subplot(1, REPEATS+1, i+2)\n",
    "    image = tf.reshape(image, [1, *image.shape, 1])\n",
    "    image = tf.nn.pool(image, window_shape=(2,2), strides=(2, 2), padding='SAME', pooling_type='MAX')\n",
    "    image = tf.squeeze(image)\n",
    "    plt.imshow(image, vmin=0, vmax=1)\n",
    "    plt.title(\"MaxPool {}\\nShape: {}x{}\".format(i+1, image.shape[0], image.shape[1]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you were wanting to teach a convolutional classifier to recognize circles, would it be helpful to include all of these \"shifted\" circles in your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lesson 6, we'll explore this idea of invariance more when we learn about **Data Augmentation**.\n",
    "\n",
    "### 3) What about Average Pooling?\n",
    "\n",
    "In this exercise, we'll look at an alternative to maximum pooling that was once very popular: **average pooling**. An `AvgPool2D` layer operates the same way as `MaxPool2D`, but replaces a patch of pixels by their average instead of their maximum value.\n",
    "\n",
    "Run the following cell to see the effect of average pooling to a feature over several iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPEATS = 4\n",
    "\n",
    "SIZE = [32, 32]\n",
    "image = visiontools.circle(SIZE)\n",
    "image = tf.reshape(image, [1, *image.shape, 1])\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, REPEATS+1, 1)\n",
    "plt.imshow(tf.squeeze(image), vmin=0, vmax=1)\n",
    "plt.title(\"Original\\nShape: {}x{}\".format(image.shape[0], image.shape[1]))\n",
    "plt.axis('off')\n",
    "for i in range(REPEATS):\n",
    "    ax = plt.subplot(1, REPEATS+1, i+2)\n",
    "    image = tf.nn.avg_pool(image, ksize=2, strides=2, padding='SAME'),\n",
    "    plt.imshow(tf.squeeze(image), vmin=0, vmax=1)\n",
    "    plt.title(\"MaxPool {}\\nShape: {}x{}\".format(i+1, image.shape[1], image.shape[2]))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? All else equal, what do you think would happen if you replaced maximum pooling with average pooling in a convolutional classifier? Would you expect its performance to improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 4) What about Global Average Pooling?\n",
    "\n",
    "We mentioned in the previous exercise that average pooling has largely been superceeded by maximum pooling within the convolutional base. There is, however, a kind of average pooling that is still widely used in the *head* of a convnet. This is **global average pooling**. A `GlobalAvgPool2D` layer is often used as an alternative to some or all of the hidden `Dense` layers in the head of the network, like so:\n",
    "\n",
    "<!--md-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.GlobalAvgPool2D(),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--end_md-->\n",
    "\n",
    "What is this layer doing? Notice that we no longer have the `Flatten` layer that usually comes after the base to transform the 2D feature data to 1D data needed by the classifier. Now the `GlobalAvgPool2D` layer is serving this function. But, instead of \"unstacking\" the feature (like `Flatten`), it simply replaces the entire feature with its average value. Though very destructive, it can work quite well, and has the advantage of reducing the number of parameters in the model.\n",
    "\n",
    "First run the following cell to see what `GlobalAvgPool2D` does to a stack of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q_4a.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rewrite this model to use a `GlobalAvgPool2D` layer instead of the `Flatten` and `Dense` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "model = ____\n",
    "\n",
    "q_4b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.GlobalAvgPool2D(),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "q_4b.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's train the model. Run the following cell for credit on this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
