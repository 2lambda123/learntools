{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets #\n",
    "## ImageConverter Method ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade tensorflow-datasets > /dev/null\n",
    "\n",
    "import io, os, csv\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to convert an image dataset to TFRecords using the [DatasetBuilder](https://www.tensorflow.org/datasets/api_docs/python/tfds/core/DatasetBuilder) utility in [TensorFlow Datasets](https://www.tensorflow.org/datasets) (`tfds`). TFDS is a high-level wrapper around `tf.data`.\n",
    "\n",
    "First we'll fetch some extensions to TFDS. For more info, see [this Colab notebook](https://github.com/tensorflow/tpu/blob/master/tools/colab/image_classification_converter.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/kaggle/working/')\n",
    "! git clone -b image_classification_converter https://github.com/tensorflow/tpu.git\n",
    "# os.chdir('/home/jovyan/work/kaggle/image_converter/tools/data_converter')\n",
    "os.chdir('/kaggle/working/tpu/tools/data_converter/')\n",
    "from image_classification.image_classification_data import ImageClassificationBuilder\n",
    "from image_classification.image_classification_data import ImageClassificationConfig\n",
    "os.chdir('/kaggle/working/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `ImageClassificationBuilder` we write a generator that generates tuples `(image_file, label)` according to the layout specified in `ImageClassificationConfig`. We specify a layout with three fields:\n",
    "- `num_labels` - the number of labels in the dataset\n",
    "- `supported_modes` - a list *(tuple?)** containing one or more of `'train'`, `'validation'`, `'test'`.\n",
    "- `example_generator` - a generator that returns the set of image examples for a given mode\n",
    "\n",
    "### Configuration ###\n",
    "\n",
    "Let's first set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where are we?\n",
    "if os.getenv('PWD') == '/kaggle/working':\n",
    "    HOME_PATH = '/kaggle/'\n",
    "else:\n",
    "    HOME_PATH = '/home/jovyan/work/kaggle/computer-vision/' # your local project directory here\n",
    "\n",
    "TFRECORD_PATH = HOME_PATH + 'working/'\n",
    "ROOT_PATH = HOME_PATH + 'input/stanford-car-dataset-by-classes-folder/car_data/car_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll define the layout configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(HOME_PATH + 'input/stanford-car-dataset-by-classes-folder/names.csv') as csvfile:\n",
    "    LABELS = [r[0] for r in csv.reader(csvfile)]\n",
    "# CLASSES.sort()\n",
    "NUM_LABELS = len(LABELS)\n",
    "\n",
    "class StanfordCarsConfig(ImageClassificationConfig):\n",
    "    def __init__(self, root_path, *args, **kwargs):\n",
    "        super(StanfordCarsConfig, self).__init__(\n",
    "            version=tfds.core.Version('0.1.0'),\n",
    "            supported_versions=[],\n",
    "            **kwargs)\n",
    "        self.root_path = root_path\n",
    "\n",
    "    @property\n",
    "    def supported_modes(self):\n",
    "        return ('train', 'test')\n",
    "\n",
    "    @property\n",
    "    def num_labels(self):\n",
    "        return NUM_LABELS\n",
    "\n",
    "    def example_generator(self, mode):\n",
    "        data_path = self.root_path\n",
    "        mode_path = os.path.join(data_path, mode)\n",
    "\n",
    "        for class_name in os.listdir(mode_path):\n",
    "            class_dir = os.path.join(mode_path, class_name)\n",
    "            for img_path in os.listdir(class_dir):\n",
    "                abs_path = os.path.abspath(os.path.join(class_dir, img_path))\n",
    "                yield {\n",
    "                    'image_fobj': tf.io.gfile.GFile(abs_path, 'rb'),\n",
    "                    'label': class_name,\n",
    "                }\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "config = StanfordCarsConfig(name='stanford-cars-tfrecords',\n",
    "                            description='The Stanford Cars dataset',\n",
    "                            root_path=ROOT_PATH)\n",
    "dataset = ImageClassificationBuilder(data_dir=TFRECORD_PATH,\n",
    "                                     config=config)\n",
    "dataset.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_from_bytes(binary_image):\n",
    "  im = Image.open(io.BytesIO(binary_image)).convert(\"RGB\")\n",
    "  plt.imshow(im)\n",
    "\n",
    "def visualize_tfrecord(tf_record_path):\n",
    "    tf_raw = next(tf.data.TFRecordDataset(tf_record_path).__iter__()).numpy()\n",
    "    tf_example = tf.train.Example()\n",
    "    tf_example.ParseFromString(tf_raw)\n",
    "    print(repr(tf_example)[:1000])\n",
    "    show_image_from_bytes(tf_example.features.feature['image/encoded'].bytes_list.value[0])\n",
    "  \n",
    "tf_record_path = os.path.join(\n",
    "    TFRECORD_PATH,\n",
    "    'image_classification_builder',\n",
    "    'stanford-cars-tfrecords',\n",
    "    '0.1.0',\n",
    "    'image_classification_builder-train.tfrecord-00002-of-00016')\n",
    "visualize_tfrecord(tf_record_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /kaggle/working/downloads/\n",
    "!rm -rf /kaggle/working/tpu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Builder Method ##\n",
    "\n",
    "We need to understand the directory structure that TFDS uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade tensorflow-datasets > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanfordCars(tfds.image.Cars196):\n",
    "    \"\"\"The Stanford Cars Dataset.\"\"\"\n",
    "    VERSION = tfds.core.Version('0.1.0')\n",
    "    def __init__(self, **kwargs):\n",
    "        super(StanfordCars, self).__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ROOT_DIR = '/home/jovyan/work/kaggle/computer-vision/'\n",
    "_DATA_DIR = os.path.join(_ROOT_DIR, 'working/')\n",
    "_INPUT_DIR = os.path.join(_ROOT_DIR, 'input/')\n",
    "_MANUAL_DIR = os.path.join(_INPUT_DIR, 'stanford-cars-dataset/')\n",
    "\n",
    "builder = tfds.builder(name = 'stanford_cars',\n",
    "                       data_dir = _DATA_DIR)\n",
    "download_config = tfds.download.DownloadConfig(extract_dir = _DATA_DIR,\n",
    "                                               manual_dir = _MANUAL_DIR)\n",
    "builder.download_and_prepare(download_config=download_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = builder.as_dataset(split='train')\n",
    "fig = tfds.show_examples(ds_info=builder.info, ds=ds,\n",
    "                         rows=3, cols=3, plot_scale=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in ds.take(3):\n",
    "    print(ex['bbox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models with TFDS Datasets #\n",
    "\n",
    "Previously, we converted the dataset into TFRecords form, ready to be ingested by the TF model. We create a Kaggle dataset from the produced files and reload. Now the data lives in the `../input` directory.\n",
    "\n",
    "## Without Data Augmentation ##\n",
    "### Pipeline ###\n",
    "\n",
    "Let's try training a simple model without accelleration first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade tensorflow-datasets > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanfordCars(tfds.image.Cars196):\n",
    "    \"\"\"The Stanford Cars Dataset.\"\"\"\n",
    "    VERSION = tfds.core.Version('0.1.0')\n",
    "    def __init__(self, **kwargs):\n",
    "        super(StanfordCars, self).__init__(**kwargs)\n",
    "\n",
    "ROOT_DIR = '/kaggle/'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, 'input/stanford-cars-for-learn/')\n",
    "\n",
    "ds, ds_info = tfds.load('stanford_cars', split='train', with_info=True, \n",
    "                        download=False, data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_info=ds_info, ds=ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_validation), ds_info = tfds.load('stanford_cars',\n",
    "                                               download=False,\n",
    "                                               data_dir=DATA_DIR,\n",
    "                                               split=['train', 'test'],\n",
    "                                               as_supervised=True,\n",
    "                                               shuffle_files=True,\n",
    "                                               with_info=True)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "SIZE = 64\n",
    "NUM_EXAMPLES = ds_info.splits['train'].num_examples\n",
    "\n",
    "def preprocessor(image, label):\n",
    "    dim = tf.constant([SIZE, SIZE], dtype=tf.dtypes.int32)\n",
    "    return tf.image.resize(image, dim), label\n",
    "\n",
    "ds_train = (\n",
    "    ds_train.map(preprocessor, AUTOTUNE)\n",
    "    .cache()\n",
    "    .shuffle(NUM_EXAMPLES//4)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_validation = (\n",
    "    ds_validation.map(preprocessor, AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 196\n",
    "EPOCHS = 30\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[SIZE, SIZE, 3]),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(4096, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_LABELS)\n",
    "])\n",
    "model.compile(\n",
    "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=ds_validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Data Augmentation ##\n",
    "\n",
    "Now let's add online data augmentation and use TPU accelleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade tensorflow-datasets > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from kaggle_datasets import KaggleDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StanfordCars(tfds.image.Cars196):\n",
    "    \"\"\"The Stanford Cars Dataset.\"\"\"\n",
    "    VERSION = tfds.core.Version('0.1.0')\n",
    "    def __init__(self, **kwargs):\n",
    "        super(StanfordCars, self).__init__(**kwargs)\n",
    "\n",
    "DATA_DIR = KaggleDatasets().get_gcs_path()\n",
    "ds, ds_info = tfds.load('stanford_cars', split='train', with_info=True, \n",
    "                        download=False, data_dir=DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_info=ds_info, ds=ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Preprocessor and Augmentor ###\n",
    "\n",
    "Random transformations should be done separately from deterministic transformations. Deterministic transformations should be cached. Random transformations should not be cached. Random transformations should also be applied after batching so that they may be vectorized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(size):\n",
    "    def preprocessor(image, label):\n",
    "        # Convert Int to Float and scale from [0, 255] to [0.0, 1.0]\n",
    "        image = tf.image.convert_image_dtype(image,\n",
    "                                             dtype=tf.float32)\n",
    "        # Resize the image to size=[width, height]\n",
    "        image = tf.image.resize(image,\n",
    "                                size=size,\n",
    "                                method=\"bicubic\",\n",
    "                                preserve_aspect_ratio=True)\n",
    "        return image, label\n",
    "    return preprocessor\n",
    "\n",
    "def make_augmentor(# rotation_range=0,\n",
    "                   # width_shift_range=0,\n",
    "                   # height_shift_range=0,\n",
    "                   brightness_delta=None,\n",
    "                   contrast_range=None,\n",
    "                   hue_delta=None,\n",
    "                   saturation_range=None,\n",
    "                   # shear_range=0.0,\n",
    "                   # zoom_range=0.0,\n",
    "                   # channel_shift_range=0.0,\n",
    "                   # fill_mode='nearest',\n",
    "                   horizontal_flip=False,\n",
    "                   vertical_flip=False,\n",
    "                   seed = 31415):\n",
    "    def augmentor(image, label):\n",
    "        if brightness_delta is not None:\n",
    "            image = tf.image.random_brightness(image,\n",
    "                                               max_delta=brightness_delta, seed=seed)\n",
    "        if contrast_range is not None:\n",
    "            image = tf.image.random_contrast(image,\n",
    "                                             lower=contrast_delta[0],\n",
    "                                             upper=contrast_delta[1])\n",
    "        if hue_delta is not None:\n",
    "            image = tf.image.random_hue(image, \n",
    "                                        max_delta=hue_delta, seed=seed)\n",
    "        if saturation_range is not None:\n",
    "            image = tf.image.random_saturation(image,\n",
    "                                               lower=saturation_range[0],\n",
    "                                               upper=saturation_range[1], seed=seed)\n",
    "        if horizontal_flip:\n",
    "            image = tf.image.random_flip_left_right(image, seed=seed)\n",
    "\n",
    "        if vertical_flip:\n",
    "            image = tf.image.random_flip_up_down(image, seed=seed)\n",
    "\n",
    "        return image, label\n",
    "    return augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_preprocessor = make_preprocessor(size=[192, 192])\n",
    "\n",
    "try_augmentor = make_augmentor(hue_delta=0.25,\n",
    "                               saturation_range=[0.1, 3.0],\n",
    "                               horizontal_flip=True)\n",
    "\n",
    "rows = 4; cols = 4\n",
    "ds = tfds.load('stanford_cars', split='train',\n",
    "               download=False, data_dir=DATA_DIR,\n",
    "               as_supervised=True)\n",
    "examples = list(tfds.as_numpy(ds.take(rows * cols)))\n",
    "\n",
    "plt.figure(figsize=(15, int(15 * rows / cols)))\n",
    "for i, (image, label) in enumerate(examples):\n",
    "    image, _ = try_preprocessor(image, label)\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_train, ds_validation), ds_info = tfds.load('stanford_cars',\n",
    "                                               download=False,\n",
    "                                               data_dir=DATA_DIR,\n",
    "                                               split=['train', 'test'],\n",
    "                                               as_supervised=True,\n",
    "                                               shuffle_files=True,\n",
    "                                               with_info=True)\n",
    "\n",
    "NUM_LABELS = 196\n",
    "SHUFFLE_BUFFER = ds_info.splits['train'].num_examples // 4\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "EPOCHS = 10\n",
    "SIZE = 192\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "preprocess = make_preprocessor(size=[SIZE, SIZE])\n",
    "\n",
    "augment = make_augmentor(brightness_delta=0.2,\n",
    "                         horizontal_flip=True)\n",
    "\n",
    "train_batches = (\n",
    "    ds_train\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .cache()\n",
    "    .repeat() # why is this needed?\n",
    "    .shuffle(SHUFFLE_BUFFER)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_batches = (\n",
    "    ds_validation\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.applications.ResNet50(weights='imagenet',\n",
    "                                       include_top=False,\n",
    "                                       input_shape=[SIZE, SIZE, 3])\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(NUM_LABELS, activation='softmax')\n",
    "    ])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_batches,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_batches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_docs as tfdocs\n",
    "\n",
    "plotter = tfdocs.plots.HistoryPlotter()\n",
    "plotter.plot({\"Augmented\": history}, metric = \"accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.ylim([0.0,1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data.Dataset ##\n",
    "\n",
    "- Distributed training strategies (tf.distribute)\n",
    "  - Data parallelism\n",
    "  - Model parallelism\n",
    "\n",
    "Distributed training in Tensorflow occurs via *data parallelism*: the data is split up among identical copies of the model. These pieces are called **shards**. The number of shards should ideally be a multiple of the number of (workers, devices, ?), so that no (worker, device, ?) becomes idle.\n",
    "\n",
    "- TPUs\n",
    "  - 8 cores\n",
    "  - generally, data is arranged in memory either as 8x128 or as 128x128; to minimize the cost of padding the data to these dimenions:\n",
    "    - arrange batch sizes to multiples of 128\n",
    "    - arrange feature dimensions to multiples of either 8 or 128 (spatial dimensions are not padded)\n",
    "\n",
    "- **Rule of Thumb:** 128 (ideal) data items per core (targeting the matrix unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecords and Examples ###\n",
    "\n",
    "#### Examples ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FValue :: tf.train.BytesList | tf.train.FloatList | tf.train.Int64List\n",
    "\n",
    "tf.train.Feature :: feature {key: String,\n",
    "                             value: FValue}\n",
    "\n",
    "tf.train.Example :: {feature: tf.train.Features}\n",
    "\n",
    "TFRecord :: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabular Data as Examples ####\n",
    "\n",
    "| TFRecord  | \"Feature 1\" | \"Feature 2\" | \"Feature 3\" |\n",
    "|           | (BytesList) | (FloatList) | (Int64List) |\n",
    "|-----------|-------------|-------------|-------------|\n",
    "| Example 1 | value       | value       | value       |\n",
    "| Example 2 |             |             |             |\n",
    "| Example 3 |             |             |             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "features {\n",
    "    feature {\n",
    "        \"Feature 1\": value (BytesList)\n",
    "    }\n",
    "    feature {\n",
    "        \"Feature 2\": value (FloatList)\n",
    "    }\n",
    "    feature {\n",
    "        \"Feature 3\": value (Int64List)\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFRecords ####\n",
    "\n",
    "A TFRecord is a file containing a stream of serialized records.\n",
    "\n",
    "`tf.Example` is a way of serializing records (like from the above table).\n",
    "\n",
    "So, a TFRecord file can contain a stream of `tf.Example`s.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Optimal Shard/Batch/Image Size ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Data Pipelines #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=2):\n",
    "    start_time = time.perf_counter()\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.001)\n",
    "    execution_time = time.perf_counter() - start_time\n",
    "    tf.print(\"Execution time:\", execution_time)\n",
    "    tf.print(\"Average time per epoch:\", execution_time/2)\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "ds = tfds.load('stanford_cars',\n",
    "               split='train',\n",
    "               shuffle_files='true',\n",
    "               as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, when `shuffle_files='true'`, TFDS sets `Options.experimental_deterministic=False`\n",
    "\n",
    "* Things to investigate: \n",
    "  - `tf.data.experimental.MapVectorizationOptions`: whether to vectorize map transformations\n",
    "  - `tf.data.Options.experimental_optimization.autotune_buffers`: whether to autotune buffer sizes\n",
    "  - `tfds.ReadConfig`: various data reading options; can be passed to `tfds.load`\n",
    "  \n",
    "## Naive ##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "benchmark(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware Architecture #\n",
    "\n",
    "- Kaggle VM\n",
    "  - Storage\n",
    "  - CPUs\n",
    "- Host VM\n",
    "  - Storage (GCS)\n",
    "  - CPUs\n",
    "  - TPUs\n",
    "    - 8 cores per TPU\n",
    "      - MXU (matrix unit), 128x128, bfloat16/float32 to float32\n",
    "      - VPU (vector unit), ?, float32/int32 to float32/int32\n",
    "\n",
    "# Feature Format #\n",
    "## Images ##\n",
    "- Dimensions\n",
    "  - MNIST\n",
    "    - 28 x 28\n",
    "  - Imagenet Resized\n",
    "    - 8 x 8\n",
    "    - 16 x 16\n",
    "    - 32 x 32\n",
    "    - 64 x 64\n",
    "  - Imagenette\n",
    "    - 160 x 160\n",
    "    - 320 x 320\n",
    "  - TFFlowers\n",
    "    - 192 x 192\n",
    "    - 224 x 224 \n",
    "    - 331 x 331\n",
    "    - 512 x 512\n",
    "\n",
    "# References #\n",
    "\n",
    "## Computer Vision ##\n",
    "\n",
    "- [TensorFlow, Keras, and Deep Learning, without a PhD](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/index.html?index=..%2F..index#0) (Codelabs)\n",
    "- [Feature Visualization](https://distill.pub/2017/feature-visualization/) (Distill)\n",
    "- [Visualizing and Understanding CNNs - Zeiler and Fergus (2017)](https://arxiv.org/abs/1311.2901) (arXiv)\n",
    "\n",
    "### Online Courses ##\n",
    "\n",
    "- [CNNs](https://github.com/udacity/aind2-cnn) (Udacity)\n",
    "- [Deep Learning](https://www.coursera.org/specializations/deep-learning) (Coursera)\n",
    "- [TensorFlow in Practice](https://www.coursera.org/specializations/tensorflow-in-practice) (Coursera)\n",
    "- [Convolutional Neural Nets](http://cs231n.github.io/) (Stanford)\n",
    "- [Practical Deep Learning for Coders](https://course.fast.ai/) (fast.ai)\n",
    "\n",
    "## TPUs and TensorFlow ##\n",
    "\n",
    "### General ###\n",
    "\n",
    "- [Getting Started with 100+ Flowers on TPU](https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu) (Kaggle notebook)\n",
    "- [Keras and modern convnets, on TPUS](https://codelabs.developers.google.com/codelabs/keras-flowers-tpu/) (Codelabs)\n",
    "  - What are TPUs\n",
    "  - Loading Data Fast\n",
    "  - Transfer Learning\n",
    "  - Modern Convnets\n",
    "  - Xception Fine-Tuned\n",
    "- [Cloud TPU Repo](https://github.com/tensorflow/tpu) (GCS GitHub) - \"This repository is a collection of reference models and tools used with Cloud TPUs.\" Much is still TF1, but some is TF2. **Very Useful**\n",
    "  - Benchmarks\n",
    "    - ResNet50 - detailed discussion of how the benchmark was obtained, VM config, batch size, etc.\n",
    "  - Models\n",
    "    - ResNet50\n",
    "    - Keras Applications\n",
    "    - Inception\n",
    "  - Tools\n",
    "    - Image Data Converter\n",
    "    - Data Profiler\n",
    "- [When to Use CPUs vs GPUs vs TPUs in a Kaggle Competition?](https://towardsdatascience.com/when-to-use-cpus-vs-gpus-vs-tpus-in-a-kaggle-competition-9af708a8c3eb) (article)\n",
    "- [Advanced Guide to Inception v3](https://cloud.google.com/tpu/docs/inception-v3-advanced) (Cloud TPU docs)\n",
    "  - TF1, but a good overview of TPU data pipelines with preprocessing on host CPU\n",
    "- [Training ResNet on Cloud TPU](https://cloud.google.com/tpu/docs/tutorials/resnet-2.x) (Cloud TPU docs)\n",
    "  - much less material (no preprocessing), but TF2\n",
    "\n",
    "### TFRecords and Data Preparation ###\n",
    "\n",
    "- [Convert Kaggle Dataset to GCS Bucket of TFRecords](https://www.kaggle.com/paultimothymooney/convert-kaggle-dataset-to-gcs-bucket-of-tfrecords) (Kaggle notebook)\n",
    "- [Flower pictures to TFRecords](https://colab.research.google.com/github/GoogleCloudPlatform/training-data-analyst/blob/master/courses/fast-and-lean-data-science/03_Flower_pictures_to_TFRecords.ipynb) (Colab notebook)\n",
    "\n",
    "### Data Augmentation ###\n",
    "\n",
    "- [Rotation](https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96/notebook) (Kaggle notebook)\n",
    "- [Cutup and Mixup](https://www.kaggle.com/cdeotte/cutmix-and-mixup-on-gpu-tpu) (Kaggle notebook)\n",
    "- [Gridmask](https://www.kaggle.com/xiejialun/gridmask-data-augmentation-with-tensorflow) (Kaggle notebook)\n",
    "- [Faster Data Augmentation](https://www.kaggle.com/yihdarshieh/make-chris-deotte-s-data-augmentation-faster?scriptVersionId=29453906) (Kaggle notebook)\n",
    "- [Perspective Transform](https://www.kaggle.com/yihdarshieh/perspective-transformation?scriptVersionId=29866403) (Kaggle notebook)\n",
    "\n",
    "### Distributed TensorFlow ###\n",
    "\n",
    "- [tf.distribute](https://www.tensorflow.org/api_docs/python/tf/distribute) (TF2 docs)\n",
    "- [Distributed TensorFlow](https://github.com/tensorflow/examples/blob/master/community/en/docs/deploy/distributed.md) (GitHub community docs)\n",
    "\n",
    "### Performance ###\n",
    "\n",
    "- [Custom Training Loop on 100+ Flowers](https://www.kaggle.com/mgornergoogle/custom-training-loop-with-100-flowers-on-tpu/notebook) (Kaggle notebook)\n",
    "- [Cloud TPU Performance Guide](https://cloud.google.com/tpu/docs/performance-guide) (Cloud TPU docs)\n",
    "- [Training Performance (TensorFlow Dev Summit 2018)](https://www.youtube.com/watch?v=SxOsJPaxHME) (YouTube)\n",
    "- [TensorFlow Profiler on TensorBoard](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_profiling_keras.ipynb) (Colab notebook)\n",
    "- [Examining the TensorFlow Graph with TensorBoard](https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/graphs.ipynb) (Colab notebook)\n",
    "- [In-Datacenter Performance Analysis of a TPU](https://arxiv.org/abs/1704.04760) (arXiv)\n",
    "\n",
    "### Hardware ###\n",
    "\n",
    "- [Systolic Architectures](http://www.telesens.co/2018/07/30/systolic-architectures/) (article)\n",
    "- [Why Systolic Architectures?- Kung (1982)](http://www.eecs.harvard.edu/~htk/publication/1982-kung-why-systolic-architecture.pdf) (pdf)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
