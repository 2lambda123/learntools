{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--TITLE:Custom Convnets-->\n",
    "# Introduction #\n",
    "\n",
    "Now that you've seen the layers a convnet uses to extract features, it's time to put them together and build a network of your own!\n",
    "\n",
    "<figure>\n",
    "<!-- <img src=\"./images/2-filter-detect-condense.png\" width=\"400\" alt=\"Extraction as a sequence of blocks.\"> -->\n",
    "<img src=\"https://i.imgur.com/vBatPfn.png\" width=\"400\" alt=\"Extraction as a sequence of blocks.\">\n",
    "</figure>\n",
    "\n",
    "# Convolutional Blocks #\n",
    "\n",
    "Arrange them into blocks.\n",
    "\n",
    "<figure>\n",
    "<!-- <img src=\"./images/2-block-crp.png\" width=\"400\" alt=\"A kind of extraction block: convolution, ReLU, pooling.\"> -->\n",
    "<img src=\"https://i.imgur.com/8D6IhEw.png\" width=\"400\" alt=\"A kind of extraction block: convolution, ReLU, pooling.\">\n",
    "</figure>\n",
    "\n",
    "Modern convolutional networks comprise many of these blocks within their base:\n",
    "\n",
    "<figure>\n",
    "<!-- <img src=\"./images/2-block-seq.png\" width=\"1200\" alt=\"A sequence of extraction blocks.\"> -->\n",
    "<img src=\"https://i.imgur.com/pr8VwCZ.png\" width=\"1200\" alt=\"A sequence of extraction blocks.\">\n",
    "</figure>\n",
    "\n",
    "Each block represents a round of feature extraction, and it is by composing these blocks that the features the network learns become increasingly refined. This deep structure is what enables modern convnets to learn very complex visual features.\n",
    "\n",
    "# Simple to Refined #\n",
    "\n",
    "More extraction makes better features.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://i.imgur.com/VqmC1rm.png\" alt=\"Features extracted from an image of a car, from simple to refined.\" width=1200>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - Design a Convnet #\n",
    "\n",
    "Here is a diagram of the model we want to define:\n",
    "\n",
    "<figure>\n",
    "<!-- <img src=\"./images/2-convmodel-1.png\" width=\"200\" alt=\"Diagram of a convolutional model.\"> -->\n",
    "<img src=\"https://i.imgur.com/dMO4nRb.png\" width=\"200\" alt=\"Diagram of a convolutional model.\">\n",
    "</figure>\n",
    "\n",
    "## Step 1 - Load Data ##\n",
    "\n",
    "The next hidden cell will load our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "# Imports\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import visiontools\n",
    "from visiontools import StanfordCars\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Reproducibility\n",
    "def seed_everything(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "seed = 31415\n",
    "seed_everything(seed)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load training and validation sets\n",
    "DATA_DIR = '/kaggle/input/stanford-cars-for-learn/'\n",
    "(ds_train_, ds_valid_), ds_info = tfds.load(\n",
    "    'stanford_cars/simple',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    "    data_dir=DATA_DIR,\n",
    ")\n",
    "print((\"Loaded {} training examples \" +\n",
    "       \"and {} validation examples \" +\n",
    "       \"with classes {}.\").format(\n",
    "           ds_info.splits['train'].num_examples,\n",
    "           ds_info.splits['test'].num_examples,\n",
    "           ds_info.features['label'].names))\n",
    "\n",
    "# Create data pipeline\n",
    "BATCH_SIZE = 16\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "SIZE = [192, 192]\n",
    "preprocess = visiontools.make_preprocessor(size=SIZE)\n",
    "\n",
    "ds_train = (ds_train_\n",
    "            .map(preprocess)\n",
    "            .cache()\n",
    "            .shuffle(ds_info.splits['train'].num_examples)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(AUTO))\n",
    "\n",
    "ds_valid = (ds_valid_\n",
    "            .map(preprocess)\n",
    "            .cache()\n",
    "            .shuffle(ds_info.splits['test'].num_examples)\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(AUTO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 ##\n",
    "\n",
    "We'll build it as a Keras `Sequential` model and stack a couple of dense layers on top for a classifier just like we did with the model in Lesson 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "\n",
    "    # First Convolutional Block\n",
    "    layers.Conv2D(filters=64,\n",
    "                  kernel_size=5,\n",
    "                  activation=\"relu\",\n",
    "                  padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Second Convolutional Block    \n",
    "    layers.Conv2D(filters=128,\n",
    "                  kernel_size=3,\n",
    "                  activation=\"relu\",\n",
    "                  padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Third Convolutional Block    \n",
    "    layers.Conv2D(filters=256,\n",
    "                  kernel_size=3,\n",
    "                  activation=\"relu\",\n",
    "                  padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Classifier Head #\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=8,\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(units=1,\n",
    "                 activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train ##\n",
    "\n",
    "Training is just the same as before, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(ds_train,\n",
    "                    validation_data=ds_valid,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
