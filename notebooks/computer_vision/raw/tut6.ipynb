{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--TITLE:Data Augmentation-->\n",
    "\n",
    "# Introduction #\n",
    "\n",
    "**TODO**\n",
    "\n",
    "# Understanding Invariance #\n",
    "\n",
    "An idea we touched on when looking at pooling was **invariance**. Broadly, to say that a machine learning model is invariant to some property means that it will treat two examples differing only by that property as being exactly the same. We said that pooling made a network invariant to small shifts in the position of a feature. The network simply ignores that kind of difference.\n",
    "\n",
    "To solve a classification problem means to find a model that is invariant with respect to the class labels: it should assign the same label to all images in the same class.\n",
    "\n",
    "Giving our model translation invariance is helpful because things in the same class tend to have the same features, even if those features are shifted around. If our classifier detects a beak and feathers, our picture is almost certainly of a bird and not a fish or a horse, regardless of where those beak and features happen to be.\n",
    "\n",
    "# Learning Invariance #\n",
    "\n",
    "So one way to improve a model is to build an invariance into the model itself, like we did with pooling. The other way is to *teach* the model the invariance. This is what you are doing when you show the model many different images with the same class label. It learns to treat those images the same.\n",
    "\n",
    "<!--TODO: images of the same class-->\n",
    "<figure>\n",
    "<img src=\"\" width=400 alt=\"Images of the same class.\">\n",
    "</figure>\n",
    "\n",
    "A typical dataset, however, won't have enough examples to fully teach the model all the ways in which images from a class might be different. If you need to improve the accuracy of your model, the best thing is to collect more data. Another (much less expensive) way is to *modify* the data you already have.\n",
    "\n",
    "The idea behind **data augmentation** is that you can teach your model an invariance by transforming your existing data in ways that images of a class in unseen data might vary. For instance, if you are classifying cars, your classifier should know that whether a car is facing left-to-right or right-to-left doesn't affect what class the car is in. If a car is a Honda in one direction, it's also a Honda in any other direction.\n",
    "\n",
    "<!--TODO: cars in different directions -->\n",
    "<figure>\n",
    "<img src=\"\" width=400 alt=\"Same class of car in different directions.\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if you augment your dataset by flipping all of your images, you help your classifier to learn that this is a distinction it should ignore.\n",
    "\n",
    "<!--TODO: data for free-->\n",
    "<figure>\n",
    "<img src=\"\" width=400 alt=\"Augmented cars.\">\n",
    "</figure>\n",
    "\n",
    "# Example - Training with Data Augmentation #\n",
    "\n",
    "Keras lets you augment your data in two ways. The first way is to include it in the data pipeline with a function like [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator). The second way is to include it in the model definition by using Keras's **preprocessing layers**. This is the approach that we'll take. The primary advantage for us is that the image transformations will be computed on the GPU, speeding up training significantly.\n",
    "\n",
    "Let's see how we can use the data augmentations provided by Keras to improve the performance of the classifier from Lesson 1.\n",
    "\n",
    "## Step 1 - Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "from cv_prelude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Define Model ##\n",
    "\n",
    "We'll continue with the VGG16 model we've used throughout this course. For the head, we've increased the number of hidden units in the head from 6 to 8. Since there is now more variation in the data, we can use a little extra capacity to help our model generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "import tensorflow.keras.layers as layers\n",
    "# these are a new feature in TF 2.2\n",
    "import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n",
    "\n",
    "\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    '/kaggle/input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    # Preprocessing\n",
    "    # randomly flip left to right\n",
    "    preprocessing.RandomFlip(mode='horizontal'),\n",
    "    # randomly rotate by as much as 20% either direction\n",
    "    preprocessing.RandomRotation(factor=0.20),\n",
    "    # randomly adjust the contrast by factors between 0.5 and 1.5\n",
    "    preprocessing.RandomContrast(factor=0.5),\n",
    "\n",
    "    # Base\n",
    "    pretrained_base,\n",
    "\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train and Evaluate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n",
    "\n",
    "The `albumentations` library is another source for augmentations; it has been popular with Kagglers in competitions."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
