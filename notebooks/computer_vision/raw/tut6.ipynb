{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--TITLE:Data Augmentation-->\n",
    "\n",
    "# Introduction #\n",
    "\n",
    "Now that you've learned the fundamentals of convolutional classifiers, you're ready to move on to more advanced topics.\n",
    "\n",
    "In this lesson, you'll learn a trick that can give a boost to your image classifiers: it's called **data augmentation**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Usefulness of Fake Data #\n",
    "\n",
    "The best way to improve the performance of a machine learning model is to train it on more data. The more examples the model has to learn from, the better it will be able to recognize which differences in images matter and which do not. More data helps the model to *generalize* better.\n",
    "\n",
    "One easy way of getting more data is to use the data you already have. If we can transform the images in our dataset in ways that preserve the class, we can teach our classifier to ignore those kinds of transformations. For instance, whether a car is facing left or right in a photo doesn't change the fact that it is a *Car* and not a *Truck*. So, if we **augment** our training data with flipped images, our classifier will learn that \"left or right\" is a difference it should ignore.\n",
    "\n",
    "And that's the whole idea behind data augmentation: add in some extra fake data that looks reasonably like the real data and your classifier will improve.\n",
    "\n",
    "# Using Data Augmentation #\n",
    "\n",
    "Typically, many kinds of transformation are used when augmenting a dataset. These might include rotating the image, adjusting the color or contrast, warping the image, or many other things, usually applied in combination. Here is a sample of the different ways a single image might be transformed.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://i.imgur.com/UaOm0ms.png\" width=400, alt=\"Sixteen transformations of a single image of a car.\">\n",
    "</figure>\n",
    "\n",
    "Data augmentation is usually done *online*, meaning, as the images are being fed into the network for training. Recall that training is usually done on mini-batches of data. This is what a batch of 16 images might look like when data augmentation is used.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://i.imgur.com/MFviYoE.png\" width=400, alt=\"A batch of 16 images with various random transformations applied.\">\n",
    "</figure>\n",
    "\n",
    "Each time an image is used during training, a new random transformation is applied. This way, the model is always seeing something a little different than what it's seen before. This extra variance in the training data is what helps the model on new data.\n",
    "\n",
    "It's important to remember though that not every transformation will be useful on a given problem. Most importantly, whatever transformations you use should not mix up the classes. If you were training a [digit recognizer](https://www.kaggle.com/c/digit-recognizer), for instance, rotating images would mix up '9's and '6's. In the end, the best approach for finding good augmentations is the same as with most ML problems: try it and see!\n",
    "\n",
    "# Example - Training with Data Augmentation #\n",
    "\n",
    "Keras lets you augment your data in two ways. The first way is to include it in the data pipeline with a function like [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator). The second way is to include it in the model definition by using Keras's **preprocessing layers**. This is the approach that we'll take. The primary advantage for us is that the image transformations will be computed on the GPU instead of the CPU, potentially speeding up training.\n",
    "\n",
    "In this exercise, we'll learn how to improve the classifier from Lesson 1 through data augmentation. This next hidden cell sets up the data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "from cv_prelude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Define Model ##\n",
    "\n",
    "We'll continue with the VGG16 model we've used throughout this course. For the head, we've increased the number of hidden units from 6 to 8. Since there is now more variation in the data, we can afford a little extra capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "# these are a new feature in TF 2.2\n",
    "import tensorflow.keras.layers.experimental.preprocessing as preprocessing\n",
    "\n",
    "\n",
    "pretrained_base = tf.keras.models.load_model(\n",
    "    '/kaggle/input/cv-course-models/cv-course-models/vgg16-pretrained-base',\n",
    ")\n",
    "pretrained_base.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # Preprocessing\n",
    "    # randomly flip left to right\n",
    "    preprocessing.RandomFlip(mode='horizontal'),\n",
    "    # randomly rotate by as much as 20% either direction\n",
    "    preprocessing.RandomRotation(factor=0.20),\n",
    "    # randomly adjust the contrast by factors between 0.5 and 1.5\n",
    "    preprocessing.RandomContrast(factor=0.5),\n",
    "\n",
    "    # Base\n",
    "    pretrained_base,\n",
    "\n",
    "    # Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train and Evaluate ##\n",
    "\n",
    "And now we'll start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though data augmentation didn't seem to improve the accuracy of the classifier, it's interesting to notice that the loss curves stay much closer together. This might indicate that the augmentation had a *regularizing* effect on the network. The random transformations seem to have prevented the network from simply memorizing the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn #\n",
    "\n",
    "Move on to the [**Exercise**](#$NEXT_NOTEBOOK_URL$) to apply data augmentation to the custom convnet you built in Lesson 5. This will be your best model ever!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
