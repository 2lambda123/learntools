{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In these exercises, you'll explore the effect of the `strides` and `padding` parameters in `Conv2D` and `MaxPool2D` layers, learn about how convnets can capture large-scale visual features through stacking layers, and finally see how convolution can be used on one-dimensional data, a time series.\n",
    "\n",
    "Run the cell below to set everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.computer_vision.ex4 import *\n",
    "\n",
    "from cv_prelude import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Windows #\n",
    "\n",
    "In this exercise, you'll have a chance to experiment with the moving window parameters in `Conv2D` and `MaxPool2D` layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a) Explore Stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.a.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b) Explore Padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.b.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Receptive Field #\n",
    "\n",
    "In all of the examples we've done, we've used $3 \\times 3$ kernels; this is perhaps the most common choice for kernel size in convolutional networks. We might worry, though: if our images have dimension `(192, 192)`, are kernels with dimension `(3, 3)` large enough to capture all of the important features? A $3 \\times 3$ square wouldn't cover the shape of an eye or an ear, for instance. Maybe we should use larger kernels?\n",
    "\n",
    "In fact, this is rarely necessary. Networks occassionally will have an initial `Conv2D` layer with larger kernels, perhaps with `kernel_size=(5, 5)`, but usually not much larger. Instead, convnets can more effectively capture large-scale information from an image by stacking convolution and pooling layers. This stacking increases the number of pixels the output neurons are receiving information from, that is, it increases the size of the neurons' **receptive field**. Let's see how this happens now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) How the Receptive Field Grows\n",
    "\n",
    "This next picture illustrates two stacked convolutional layers both with `(3, 3)` kernels. The bottom layer represents the input. Each of the neurons in the first (middle) layer has a $3 \\times 3$ receptive field. Following the path of connections, we can see that each of the neurons in the second (top) layer has a $5 \\times 5$ receptive field.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://i.imgur.com/HmwQm2S.png\" alt=\"Illustration of the receptive field of two stacked convolutions.\" width=250>\n",
    "</figure>\n",
    "\n",
    "If you added a *third* convolutional layer with a `(3, 3)` kernel, each of its neurons would have a receptive field of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.a.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now say you add a `(2, 2)` maximum pooling layer with `strides=2` after the third convolution. What receptive field do the outputs have now? (This is harder. Try the hint if you need help.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.b.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimensional Convolution #\n",
    "\n",
    "Though we've been using convolutional networks on two-dimensional data, it turns out that they can also be useful on *one*-dimensional data, like time series or natural language texts. In fact, convolutional networks tend to be successful on any kind of data with a strong **local topological structure**, meaning that the information about a point tends to be concentrated in nearby points -- you can most successfully predict the value of a pixel by looking at nearby pixels, you can most successfully predict the weather today by looking at the weather yesterday instead of a month ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Apply a 1D Convolution\n",
    "\n",
    "In this exercise, we'll see how a convolution can be used on a **time series**. The time series we'll use is from [Google Trends](https://trends.google.com/trends/); it measures the popularity of the search term \"machine learning\" for weeks from January 25, 2015 to January 15, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the time series as a Pandas dataframe\n",
    "machinelearning = pd.read_csv(\n",
    "    '/kaggle/input/computer-vision-resources/machinelearning.csv',\n",
    "    parse_dates=['Week'],\n",
    "    index_col='Week',\n",
    ")\n",
    "\n",
    "machinelearning.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our data is one-dimensional, the kernel needs to be one-dimensional as well. Define a one dimensional kernel. Though not required, you'll get better results if the entries sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Define a 1D kernel. \n",
    "kernel = tf.constant([____])\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "kernel = tf.constant([0.1, 0.2, 0.3, 0.4])\n",
    "q_3.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the next cell to apply the kernel with a convolution and see what effect it had on the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat for TensorFlow\n",
    "ts_data = machinelearning.to_numpy()\n",
    "ts_data = tf.expand_dims(ts_data, axis=0)\n",
    "ts_data = tf.cast(ts_data, dtype=tf.float32)\n",
    "kern = tf.reshape(kernel, shape=(*kernel.shape, 1, 1))\n",
    "\n",
    "ts_filter = tf.nn.conv1d(\n",
    "    input=ts_data,\n",
    "    filters=kern,\n",
    "    stride=1,\n",
    "    padding='VALID',\n",
    ")\n",
    "\n",
    "# Format as Pandas Series\n",
    "machinelearning_filtered = pd.Series(tf.squeeze(ts_filter).numpy())\n",
    "\n",
    "machinelearning_filtered.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n",
    "\n",
    "This lesson ends our discussion of feature extraction. Hopefully, having completed these lessons, you've gained some intuition about how the process works and why the usual choices for its implementation are often the best ones.\n",
    "\n",
    "In the next lesson, Lesson 5, you'll learn how to compose the `Conv2D` and `MaxPool2D` layers to build your own convolutional networks from scratch."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
