{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In these exercises, you'll explore the operations a couple of popular convnet architectures use for feature extraction, learn about how convnets can capture large-scale visual features through stacking layers, and finally see how convolution can be used on one-dimensional data, in this case, a time series.\n",
    "\n",
    "Run the cell below to set everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.computer_vision.ex4 import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import visiontools\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Moving Windows #\n",
    "\n",
    "This exercise is meant to give you an opportunity to explore the moving window computations. There aren't any right or wrong answers -- it's just a chance to experiment!\n",
    "\n",
    "We've provided you with some images and kernels you can use. Run this cell to see them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visiontools import edge, blur, bottom_sobel, emboss, sharpen, circle\n",
    "\n",
    "image_dir = '/kaggle/input/computer-vision-resources/'\n",
    "circle_64 = tf.expand_dims(circle([64, 64], val=1.0, r_shrink=4), axis=-1)\n",
    "kaggle_k = visiontools.read_image(image_dir + str('k.jpg'), channels=1)\n",
    "car = visiontools.read_image(image_dir + str('car_illus.jpg'), channels=1)\n",
    "car = tf.image.resize(car, size=[200, 200])\n",
    "images = [(circle_64, \"circle_64\"), (kaggle_k, \"kaggle_k\"), (car, \"car\")]\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "for i, (img, title) in enumerate(images):\n",
    "    plt.subplot(1, len(images), i+1)\n",
    "    plt.imshow(tf.squeeze(img))\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "plt.show();\n",
    "\n",
    "kernels = [(edge, \"edge\"), (blur, \"blur\"), (bottom_sobel, \"bottom_sobel\"),\n",
    "           (emboss, \"emboss\"), (sharpen, \"sharpen\")]\n",
    "plt.figure(figsize=(14, 4))\n",
    "for i, (krn, title) in enumerate(kernels):\n",
    "    plt.subplot(1, len(kernels), i+1)\n",
    "    visiontools.show_kernel(krn, digits=2, text_size=20)\n",
    "    plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose one to experiment with, just enter it's name in the appropriate place below. Then, set the parameters for the window computation. Try out some different combinations and see what they do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: choose an image\n",
    "image = circle_64\n",
    "\n",
    "# YOUR CODE HERE: choose a kernel\n",
    "kernel = bottom_sobel\n",
    "\n",
    "visiontools.show_extraction(\n",
    "    image, kernel,\n",
    "\n",
    "    # YOUR CODE HERE: set parameters\n",
    "    conv_stride=1,\n",
    "    conv_padding='valid',\n",
    "    pool_size=2,\n",
    "    pool_stride=2,\n",
    "    pool_padding='same',\n",
    "    \n",
    "    subplot_shape=(1, 4),\n",
    "    figsize=(14, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you're ready to move on, just run this cell to mark the exercise as complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Receptive Field #\n",
    "\n",
    "In all of the examples we've done, we've used $3 \\times 3$ kernels; this is perhaps the most common choice for kernel size in convolutional networks. We might worry, though: if our images have dimension `(128, 128)`, are kernels with dimension `(3, 3)` large enough to capture all of the important features? A $3 \\times 3$ square wouldn't cover the shape of an eye or an ear, for instance. Maybe we should use larger kernels?\n",
    "\n",
    "In fact, this is rarely necessary. Networks occassionally will have an initial `Conv2D` layer with larger kernels, perhaps with `kernel_size=(5, 5)` or `(7, 7)`, but usually not much larger. Instead, convnets can more effectively capture large-scale information from an image by stacking convolution and pooling layers. This stacking increases the number of pixels the output neurons are receiving information from, that is, it increases the size of the neurons' **receptive field**. Let's see how this happens now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) How the Receptive Field Grows\n",
    "\n",
    "This next picture illustrates two stacked convolutional layers both with `(3, 3)` kernels. The bottom layer represents the input. Each of the neurons in the first (middle) layer has a $3 \\times 3$ receptive field. Following the path of connections, we can see that each of the neurons in the second (top) layer has a $5 \\times 5$ receptive field.\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://i.imgur.com/HmwQm2S.png\" alt=\"Illustration of the receptive field of two stacked convolutions.\" width=250>\n",
    "</figure>\n",
    "\n",
    "If you added a *third* convolutional layer with a `(3, 3)` kernel, each of its neurons would have a receptive field of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.a.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now say you add a `(2, 2)` maximum pooling layer with `strides=2` after the third convolution. What receptive field do the outputs have now? (This is harder. Try the hint if you need help.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.b.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimensional Convolution #\n",
    "\n",
    "Though we've been using convolutional networks on two-dimensional data, it turns out that they can also be useful on *one*-dimensional data, like time series or natural language texts. In fact, convolutional networks tend to be successful on any kind of data with a strong **local topological structure**, meaning that the information about a point tends to be concentrated in nearby points -- you can most successfully predict the value of a pixel by looking at nearby pixels, you can most successfully predict the weather today by looking at the weather yesterday instead of a month ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Apply a 1D Convolution\n",
    "\n",
    "In this exercise, we'll see how a convolution can be used on a **time series**. The time series we'll use is from [Google Trends](https://trends.google.com/trends/); it measures the popularity of the search term \"machine learning\" for weeks from January 25, 2015 to January 15, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the time series as a Pandas dataframe\n",
    "machinelearning = pd.read_csv(\n",
    "    '/kaggle/input/computer-vision-resources/machinelearning.csv',\n",
    "    parse_dates=['Week'],\n",
    "    index_col='Week',\n",
    ")\n",
    "\n",
    "machinelearning.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our data is one-dimensional, the kernel needs to be one-dimensional as well. Define a one dimensional kernel. Though not required, you'll get better results if the entries sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Define a 1D kernel. \n",
    "kernel = tf.constant([____])\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "kernel = tf.constant([0.1, 0.2, 0.3, 0.4])\n",
    "q_3.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the next cell to apply the kernel with a convolution and see what effect it had on the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat for TensorFlow\n",
    "ts_data = machinelearning.to_numpy()\n",
    "ts_data = tf.expand_dims(ts_data, axis=0)\n",
    "ts_data = tf.cast(ts_data, dtype=tf.float32)\n",
    "kern = tf.reshape(kernel, shape=(*kernel.shape, 1, 1))\n",
    "\n",
    "ts_filter = tf.nn.conv1d(\n",
    "    input=ts_data,\n",
    "    filters=kern,\n",
    "    stride=1,\n",
    "    padding='VALID',\n",
    ")\n",
    "\n",
    "# Format as Pandas Series\n",
    "machinelearning_filtered = pd.Series(tf.squeeze(ts_filter).numpy())\n",
    "\n",
    "machinelearning_filtered.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n",
    "\n",
    "This lesson ends our discussion of feature extraction. Hopefully, having completed these lessons, you've gained some intuition about how the process works and why the usual choices for its implementation are often the best ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Going #\n",
    "\n",
    "In the next lesson, [**Lesson 5**](#$NEXT_NOTEBOOK_URL$), you'll learn how to compose the `Conv2D` and `MaxPool2D` layers to build your own convolutional networks from scratch."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
