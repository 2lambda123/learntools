{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Status #\n",
    "\n",
    "- [x] Outline\n",
    "- [x] Introduction\n",
    "- [ ] Exercise 1\n",
    "  - [ ] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 2\n",
    "  - [ ] Code\n",
    "  - [ ] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 3\n",
    "  - [x] Code\n",
    "  - [x] Discussion\n",
    "  - [ ] Checking\n",
    "- [ ] Exercise 4\n",
    "  - [ ] Code\n",
    "  - [x] Discussion\n",
    "  - [ ] Checking\n",
    "- [x] Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In these exercises, you'll explore the effect of the `strides` and `padding` parameters in `Conv2D` and `MaxPool2D` layers, learn about how convnets can capture large-scale visual features through stacking layers, and finally see how convolution can be used on one-dimensional data, a time series.\n",
    "\n",
    "Run the cell below to set everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.computer_vision.ex4 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Windows #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Explore Window Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explore Stride\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Receptive Field #\n",
    "\n",
    "In all of the examples we've done, we've used $3 \\times 3$ kernels; this is perhaps the most common choice for kernel size in convolutional networks. We might worry, though: if our images have dimension `(192, 192)`, are kernels with dimension `(3, 3)` large enough to capture all of the important features? A $3 \\times 3$ square wouldn't cover the shape of an eye or an ear, for instance. Perhaps we should use larger kernels?\n",
    "\n",
    "In fact, this is rarely necessary. Networks occassionally will have an initial `Conv2D` layer with larger kernels, perhaps with `kernel_size=(5, 5)`, but usually not much larger. Instead, convnets can more effectively capture large-scale information from an image by stacking convolution and pooling layers. This stacking increases the number of pixels the output neurons are receiving information from, that is, it increases the size of the neurons' **receptive field**. Let's see how this happens now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) How the Receptive Field Grows\n",
    "\n",
    "This next picture illustrates two stacked convolutional layers with `(3, 3)` kernels. Notice how the total number of neurons connected to the output neuron at top has increased.\n",
    "\n",
    "Look at the dimensions of the square of the connected neurons at bottom. What effect did stacking two `Conv2D` layers with `kernel_size=(3, 3)` have on the effective window size for the neurons in the output layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.a.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.a.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if you added a `(2, 2)` maximum pooling layer with `strides=2` after the convolutions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.b.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.b.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next lesson, you'll learn how to create convolutional networks like this:\n",
    "\n",
    "```\n",
    "model = keras.Sequential([\n",
    "    # Base\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, activation='relu'),\n",
    "    layers.Conv2D(filters=64, kernel_size=3, strides=1, activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    layers.Conv2D(filters=128, kernel_size=3, strides=1, activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    # Head follows\n",
    "    # ...\n",
    "])\n",
    "```\n",
    "\n",
    "What is the receptive field of a neuron following the second `MaxPool2D` layer? (This one's a bit tricky. You can run the `hint` several times to get more hints, if you need.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "q_3.c.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_3.c.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Dimensional Convolution #\n",
    "\n",
    "Though we've been using convolutional networks on two-dimensional data, it turns out that they can also be useful on *one*-dimensional data, like time series or natural language texts. In fact, convolutional networks tend to be successful on any kind of data with a strong **local topological structure**, meaning that the information about a point tends to be concentrated in nearby points -- you can most successfully predict the value of a pixel by looking at nearby pixels, you can most successfully predict the weather today by looking at the weather yesterday instead of a month ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Apply a 1D Convolution\n",
    "\n",
    "In this exercise, we'll see how a convolution can be used on a **time series**. The time series we'll use is from [Google Trends](https://trends.google.com/trends/); it measures the popularity of the search term \"machine learning\" for weeks from January 25, 2015 to January 15, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the time series as a Pandas dataframe\n",
    "machinelearning = pd.read_csv('../data/machinelearning.csv',\n",
    "                              parse_dates=['Week'],\n",
    "                              index_col='Week')\n",
    "\n",
    "machinelearning.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our data is one-dimensional, the kernel needs to be one-dimensional as well. Define a one dimensional kernel. Though not required, you'll get better results if the entries sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Define a 1D kernel.\n",
    "kernel = tf.constant([____])\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "kernel = tf.constant([0.2, 0.6, 0.2])\n",
    "q_4.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the next cell to apply the kernel with a convolution and see what effect it had on the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat for TensorFlow\n",
    "ts_data = machinelearning.to_numpy()[:, 1]\n",
    "ts_data = tf.expand_dims(ts_data, axis=0)\n",
    "\n",
    "ts_filter = tf.nn.conv2d(\n",
    "    input=ts_data,\n",
    "    filters=kernel,\n",
    "    strides=1,\n",
    "    padding='VALID',\n",
    ")\n",
    "\n",
    "# Format as Pandas Series\n",
    "machinelearning_filtered = pd.Series(tf.squeeze(ts_filter).numpy())\n",
    "\n",
    "machinelearning_filtered.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n",
    "\n",
    "This lesson ends our discussion of feature extraction. Hopefully, having completed these lessons, you've gained some intuition about how the process works and why the usual choices for its implementation are often the best ones.\n",
    "\n",
    "In the next lesson, Lesson 5, you'll learn how to compose the `Conv2D` and `MaxPool2D` layers to build your own convolutional networks from scratch."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md,ipynb",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
