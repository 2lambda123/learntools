{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction #\n",
    "\n",
    "In the last lesson, we saw that a convolutional classifier has two parts: a **base** and a **head**. We learned that the job of the base is to extract visual features features from an image, which the head would then use to classify the image.\n",
    "\n",
    "In this lesson, we'll learn how this convolutional base is constructed of **blocks** which perform **three basic operations** common to CNN image classifiers: **filter**, **detect**, **condense**.\n",
    "\n",
    "<img src=\"./images/2-filter-detect-condense.png\" width=\"400\" alt=\"Extraction as a sequence of blocks.\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction #\n",
    "\n",
    "The extraction occurs over these three operations as follows:\n",
    "1. **Filter** an image for a particular feature\n",
    "2. **Detect** that feature within the filtered image\n",
    "3. **Condense** to isolate the feature\n",
    "\n",
    "This is what these operations might look like applied to an image:\n",
    "\n",
    "<img src=\"./images/2-show-extraction.png\" width=\"1000\" alt=\"An example of the feature extraction process.\">\n",
    "\n",
    "Typically, the network will perform several extractions in parallel on a single image. By the time the data reaches the classifier, a network might be producing over 1000 features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Architecture ##\n",
    "\n",
    "You learned in *Introduction to Deep Learning* how a neural network is composed of a sequence of layers each having its own activation function. It is through its layers and activation functions that a convnet carries out these three basic operations. Typically, a single sequence of these operations will be collected together in a **block**:\n",
    "\n",
    "<img src=\"./images/2-block-fdc.png\" width=\"400\" alt=\"The parts of an extraction block: filter, detect, condense.\">\n",
    "\n",
    "Modern convolutional networks comprise many of these blocks within their base:\n",
    "\n",
    "<img src=\"./images/2-block-seq.png\" width=\"1200\" alt=\"A sequence of extraction blocks.\">\n",
    "\n",
    "Each block represents a round of feature extraction, and it is by composing these blocks that the features the network learns become increasingly refined. This deep structure is what enables modern convnets to learn very complex visual features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution, ReLU, Pooling ##\n",
    "\n",
    "Though there are many variations, most often a convolutional network will implement these operations as follows:\n",
    "- one or more **convolutional layers** to **filter**,\n",
    "- a **ReLU activation function** to **detect**,\n",
    "- a single **pooling layer** to condense.\n",
    "\n",
    "<img src=\"./images/2-block-crp.png\" width=\"400\" alt=\"A kind of extraction block: convolution, ReLU, pooling.\">\n",
    "\n",
    "We'll learn the details of how these operations work in future lessons, but for now, let's just see how we can assemble them into feature extraction blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example - Build a Custom Convnet #\n",
    "\n",
    "Let's start with a diagram of the kind of block we want to reproduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: conv_model Pages: 1 -->\n",
       "<svg width=\"180pt\" height=\"55pt\"\n",
       " viewBox=\"0.00 0.00 180.00 55.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 51)\">\n",
       "<title>conv_model</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-51 176,-51 176,4 -4,4\"/>\n",
       "<!-- block1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>block1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-46.5 172,-46.5 172,-0.5 0,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv2D(kernel_size, filters)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-23.5 172,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"86\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">MaxPool2D</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe70c35cc90>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#$HIDE$\n",
    "from graphviz import Digraph\n",
    "\n",
    "def cb(layers):\n",
    "    label = '{'\n",
    "    for k, f in layers:\n",
    "        label += 'Conv2D(kernel_size, filters) |'.format(k, f)\n",
    "    label += 'MaxPool2D}'\n",
    "    return label\n",
    "\n",
    "m = Digraph('conv_model', node_attr={'shape': 'record'})\n",
    "m.node('block1', label=cb([(0, 0)]))\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we chose to do one convolutional layers followed by a single pooling layer. You could do two, three, or even four convolutional layers, if you wanted. State-of-the-art convnet architectures do even more complicated kinds of processing in their blocks.\n",
    "\n",
    "We will define a block as a new kind of layer. For this, Keras provides the `Layer` class. The pooling layer we'll use is a kind called *max pooling* (which we'll learn about in the next lesson). All of these perform their operations on 2-dimensional data; there are also 1D variants for things like time sequences and 3D variants for things like video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPool2D\n",
    "\n",
    "class ConvolutionalBlock(Layer):\n",
    "    \n",
    "    # Instantiate the layers\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional Layer\n",
    "        self.conv = Conv2D(kernel_size=kernel_size, \n",
    "                           filters=filters,\n",
    "                           activation='relu',\n",
    "                           padding='same')\n",
    "        # Pooling Layer\n",
    "        self.pool = MaxPool2D(pool_size=2)\n",
    "    \n",
    "    # Build the layers once the shape of the inputs is known\n",
    "    def call(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we don't need to worry about what the arguments mean -- just notice how we've structured the layers to match the diagram: a convolutional layer followed by a pooling layer.\n",
    "\n",
    "Now let's build a small model using our new convolutional block. Once defined using the Keras `Layer` class, you can use your new block of layers just like you would any other layer.\n",
    "\n",
    "Here is a diagram of the model we want to define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: conv_model Pages: 1 -->\n",
       "<svg width=\"226pt\" height=\"327pt\"\n",
       " viewBox=\"0.00 0.00 226.00 327.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 323)\">\n",
       "<title>conv_model</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-323 222,-323 222,4 -4,4\"/>\n",
       "<!-- block1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>block1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"4.5,-272.5 4.5,-318.5 213.5,-318.5 213.5,-272.5 4.5,-272.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-303.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv2D(kernel_size=3, filters=64)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"4.5,-295.5 213.5,-295.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-280.3\" font-family=\"Times,serif\" font-size=\"14.00\">MaxPool2D</text>\n",
       "</g>\n",
       "<!-- block2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>block2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1.5,-189.5 1.5,-235.5 216.5,-235.5 216.5,-189.5 1.5,-189.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-220.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv2D(kernel_size=3, filters=128)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1.5,-212.5 216.5,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\">MaxPool2D</text>\n",
       "</g>\n",
       "<!-- block1&#45;&gt;block2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>block1&#45;&gt;block2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-272.37C109,-264.15 109,-254.66 109,-245.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-245.61 109,-235.61 105.5,-245.61 112.5,-245.61\"/>\n",
       "</g>\n",
       "<!-- block3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>block3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1.5,-106.5 1.5,-152.5 216.5,-152.5 216.5,-106.5 1.5,-106.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-137.3\" font-family=\"Times,serif\" font-size=\"14.00\">Conv2D(kernel_size=3, filters=256)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1.5,-129.5 216.5,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\">MaxPool2D</text>\n",
       "</g>\n",
       "<!-- block2&#45;&gt;block3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>block2&#45;&gt;block3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-189.37C109,-181.15 109,-171.66 109,-162.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-162.61 109,-152.61 105.5,-162.61 112.5,-162.61\"/>\n",
       "</g>\n",
       "<!-- head -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>head</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-69.5 218,-69.5 218,-0.5 0,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-54.3\" font-family=\"Times,serif\" font-size=\"14.00\">Flatten()</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-46.5 218,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense(units=8, activation=&#39;relu&#39;)</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-23.5 218,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"109\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\">Dense(units=1, activation=&#39;sigmoid&#39;)</text>\n",
       "</g>\n",
       "<!-- block3&#45;&gt;head -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>block3&#45;&gt;head</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M109,-106.11C109,-98.18 109,-88.97 109,-79.88\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"112.5,-79.75 109,-69.75 105.5,-79.75 112.5,-79.75\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe71933ef10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#$HIDE$\n",
    "from graphviz import Digraph\n",
    "\n",
    "def cb(layers):\n",
    "    label = '{'\n",
    "    for k, f in layers:\n",
    "        label += 'Conv2D(kernel_size={}, filters={}) |'.format(k, f)\n",
    "    label += 'MaxPool2D}'\n",
    "    return label\n",
    "\n",
    "m = Digraph('conv_model', node_attr={'shape': 'record'})\n",
    "m.node('block1', label=cb([(3, 64)]))\n",
    "m.node('block2', label=cb([(3, 128)]))\n",
    "m.node('block3', label=cb([(3, 256)]))\n",
    "m.node('head', label=\"{Flatten() | Dense(units=8, activation='relu') | Dense(units=1, activation='sigmoid')}\")\n",
    "m.edges([('block1', 'block2'), ('block2', 'block3'), ('block3', 'head')])\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build it as a Keras `Sequential` model. We'll stack a couple of dense layers on top for a classifier just like we did with the model in the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "model = Sequential([\n",
    "    ConvolutionalBlock(kernel_size=3, filters=64),\n",
    "    ConvolutionalBlock(kernel_size=3, filters=128),\n",
    "    ConvolutionalBlock(kernel_size=3, filters=256),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we've built our own custom convnet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion #\n",
    "\n",
    "To be efficient, a neural network needs a structure that reflects the problem it is trying to solve. Modern neural networks have been designed to solve complex problems, and their architectures have become complex as a result. Designing a network around modular components like we have in this lesson makes managing this complexity much easier. (It is a kind of object-oriented design for neural networks!)\n",
    "\n",
    "Nonetheless, a deep stack of convolutional blocks like we defined above was state-of-the-art only a few years ago, and a relatively simple model can still be the right choice with smaller datasets, when a larger model might be in danger of overfitting. Having composable blocks makes it easier to design a network to suit your need."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
