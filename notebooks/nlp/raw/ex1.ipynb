{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Processing with Spacy\n",
    "\n",
    "In this exercise, you'll use SpaCy to generate some basic statistics from Yelp reviews. You'll be looking at reviews for specific dishes from an Italian deli, [DelFalco's in Scottsdale, Arizona](https://defalcosdeli.com/index.html). For example, they have meatball subs!\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/0a/Meatballs_sandwich10000000041678_000334_%2815638892980%29.jpg\" alt=\"meatball sub\">\n",
    "    \n",
    "You're a consultant for the restaurant looking to get insight into the quality of their food. You have an idea to use customer ratings from Yelp reviews to measure the quality of specific dishes. Assuming that a customer's rating and the menu items mentioned in the review are correlated, items that consistently appear in reviews with low ratings are likely subpar. Using this analysis, you can provide feedback to the owner.\n",
    "\n",
    "The goal then is to extract menu items from the review text and find basic statistics on the ratings. For example, you can count how many times specific dishes appear in the reviews.\n",
    "\n",
    "First you'll load in Pandas and SpaCy, then load the data from a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.nlp.ex1 import *\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data from JSON file\n",
    "data = pd.read_json('../input/restaurant.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've provided a list with the menu items and common alternate spellings. This could be improved, but it will be good for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n",
    "         \"Prosciutto\", \"Salami\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Find items in one review\n",
    "\n",
    "First up, you'll use SpaCy to find menu items in a single review. For this you can use `PhraseMatcher` which matches based on phrase patterns. Comparatively `Matcher` matches on tokens, individual words. However, some of the menu items are phrases, so you can't match on individual tokens only. Note that while the menu items are in title case, review authors will often write the food items in a variety of cases. You'll need to tell the `PhraseMatcher` to perform case-insensitive matching with the `attr` keyword argument.\n",
    "\n",
    "Using the `nlp` model, create a list of phrase docs from the `menu` list. Add the patterns to `PhraseMatcher` with the key `\"MENU\"`. Then use the `PhraseMatcher` to find matches in `doc`, an example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Create the doc object\n",
    "review_doc = nlp(data.iloc[4].text)\n",
    "\n",
    "# Create the PhraseMatcher object, be sure to match on lowercase text\n",
    "matcher = ____\n",
    "\n",
    "# Create a list of docs for each item in the menu\n",
    "patterns = ____\n",
    "\n",
    "# Add the item patterns to the matcher\n",
    "____\n",
    "\n",
    "# Find matches in the review_doc\n",
    "matches = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "# q_1.hint()\n",
    "# q_1.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After implementing the above cell, uncomment and run this to print \n",
    "# out the matches. Otherwise you'll get an error.\n",
    "\n",
    "# for match in matches:\n",
    "#     print(f\"At position {match[1]}: {review_doc[match[1]:match[2]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "review_doc = nlp(data.iloc[4].text)\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "patterns = [nlp(item) for item in menu]\n",
    "matcher.add(\"MENU\", None, *patterns)\n",
    "matches = matcher(review_doc)\n",
    "\n",
    "for match in matches:\n",
    "    print(f\"At position {match[1]}: {review_doc[match[1]:match[2]]}\")\n",
    "    \n",
    "# Uncomment when checking code is complete\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Matching on the whole dataset\n",
    "\n",
    "Now run this matcher over the whole dataset and collect ratings for each menu item. Each review has a rating, `review.stars`. For each item that appears in the review text (`review.text`), append the review's rating to a list of ratings for that item. The lists are kept in a dictionary `item_ratings`.\n",
    "\n",
    "To get the matched phrases, you can reference the PhraseMatcher documentation for the structure of each match object:\n",
    "\n",
    ">A list of `(match_id, start, end)` tuples, describing the matches. A match tuple describes a span `doc[start:end]`. The `match_id` is the ID of the added match pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# item_ratings is a dictionary of lists. If a key doesn't exist in item_ratings,\n",
    "# the key is added with an empty list as the value.\n",
    "item_ratings = defaultdict(list)\n",
    "\n",
    "for idx, review in data.iterrows():\n",
    "    doc = ____\n",
    "    # Using the matcher from the previous exercise\n",
    "    matches = ____\n",
    "    \n",
    "    # Create a set of the items found in the review text\n",
    "    found_items = ____\n",
    "    \n",
    "    # Update item_ratings with rating for each item in found_items\n",
    "    # Transform the item strings to lowercase to make it case insensitive\n",
    "    ____\n",
    "\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "#q_2.hint()\n",
    "#q_2.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "item_ratings = defaultdict(list)\n",
    "\n",
    "for idx, review in data.iterrows():\n",
    "    doc = nlp(review.text)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    found_items = set([doc[match[1]:match[2]] for match in matches])\n",
    "    \n",
    "    for item in found_items:\n",
    "        item_ratings[str(item).lower()].append(review.stars)\n",
    "        \n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Similar Items\n",
    "\n",
    "You have some items like Steak and Cheese, Cheesesteak, and Cheese Steak that all refer to the same item, but are counted separately. Because language is messy. Before doing analysis, you should combine these items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_items = [('cheesesteak', 'cheese steak'),\n",
    "                 ('cheesesteak', 'steak and cheese'),\n",
    "                 ('chicken parmigiana', 'chicken parm'),\n",
    "                 ('chicken parmigiana', 'chicken parmesan'),\n",
    "                 ('mac and cheese', 'macaroni'),\n",
    "                 ('calzone', 'calzones')]\n",
    "\n",
    "for (destination, source) in similar_items:\n",
    "    item_ratings[destination].extend(item_ratings.pop(source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Which items are the best reviewed?\n",
    "\n",
    "Using these item ratings, find the mean ratings for each item. Then sort the ratings to find the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean ratings for each menu item as a dictionary\n",
    "mean_ratings = ____\n",
    "\n",
    "# Sort the ratings in descending order, should be a list\n",
    "best_items = ____\n",
    "\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "# q_3.hint()\n",
    "# q_3.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After implementing the above cell, uncomment and run this to print \n",
    "# out the best items. Otherwise you'll get an error.\n",
    "\n",
    "# for item in best_items:\n",
    "#     print(f\"{item:>25}{mean_ratings[item]:>10.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "\n",
    "mean_ratings = {item: sum(ratings)/len(ratings) for item, ratings in item_ratings.items()}\n",
    "best_items = sorted(mean_ratings, key=mean_ratings.get, reverse=True)\n",
    "\n",
    "for item in best_items:\n",
    "    print(f\"{item:>25}{mean_ratings[item]:>10.3f}\")\n",
    "    \n",
    "q_3.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which items are the most popular?\n",
    "\n",
    "Similar to the mean ratings, you can calculate the number of reviews for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {item: len(ratings) for item, ratings in item_ratings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = sorted(counts, key=counts.get, reverse=True)\n",
    "for item in item_counts:\n",
    "    print(f\"{item:>25}{counts[item]:>5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thought Question: Are counts important here?\n",
    "\n",
    "Finally, print out the 10 best and 10 worst items. Print the item name, the average rating, and the count. It's important to consider the number of ratings for a specific item when using the mean to make decisions or suggestions. Why is this?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_4.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best rated menu items:\")\n",
    "for item in best_items[:10]:\n",
    "    print(f\"{item:20} Average rating: {mean_ratings[item]:.3f} \\tcount: {counts[item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Worst rated menu items:\")\n",
    "for item in best_items[:-10:-1]:\n",
    "    print(f\"{item:20} Average rating: {mean_ratings[item]:.3f} \\tcount: {counts[item]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Up!\n",
    "\n",
    "In the next tutorial you'll learn how to create a text classification model with SpaCy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
