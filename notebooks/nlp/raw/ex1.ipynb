{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Classification\n",
    "\n",
    "In the first exercise, you will train a model that classifies Yelp reviews into \"good\" or \"bad\" sentiments. You'll use ScaPy to train a text classifier, then use the model to predict the sentiment of text examples.\n",
    "\n",
    "The data consists of the text body of each review along with the star rating. The star ratings have been grouped into sentiments. Ratings with 1-2 stars are \"negative\", ratings with 4-5 stars are \"positive\", while 3 star ratings are \"neutral\" and have been dropped from the data.\n",
    "\n",
    "<img src=\"https://i.imgur.com/7l6vwIr.png\" width=400px>\n",
    "\n",
    "The goal then is to use the text and sentiments of each review to train a classification model for predicting the sentiment of new text. To do this, you'll use ScaPy's TextCategorizer component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.nlp.ex1 import *\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total bill for this horrible service? Over $8G...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Went in for a lunch. Steak sandwich was delici...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today was my second out of three sessions I ha...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  sentiment\n",
       "0  Total bill for this horrible service? Over $8G...    1.0          0\n",
       "1  I *adore* Travis at the Hard Rock's new Kelly ...    5.0          1\n",
       "2  I have to say that this office really has it t...    5.0          1\n",
       "3  Went in for a lunch. Steak sandwich was delici...    5.0          1\n",
       "4  Today was my second out of three sessions I ha...    1.0          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('../input/yelp_ratings.csv', index_col=0)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Exercise: Create the model\n",
    "\n",
    "For the first exercise, create the text classifier model and add the labels `\"NEGATIVE\"` and `\"POSITIVE\"`. For the model, use the `\"bow\"` (bag of words) architecture. The other architectures will likely result in better performance, but train much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Create an empty model\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Create the TextCategorizer with exclusive classes and \"bow\" architecture\n",
    "textcat = nlp.create_pipe(\n",
    "            \"textcat\",\n",
    "            config={\n",
    "                \"exclusive_classes\": True,\n",
    "                \"architecture\": \"bow\"})\n",
    "nlp.add_pipe(textcat)\n",
    "\n",
    "# Add NEGATIVE and POSITIVE labels to text classifier\n",
    "textcat.add_label(\"NEGATIVE\")\n",
    "textcat.add_label(\"POSITIVE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "Here I've included a function to load the data and split it into training and validation slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file, split=0.8):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Shuffle data\n",
    "    train_data = data.sample(frac=1, random_state=7)\n",
    "    \n",
    "    texts = train_data.text.values\n",
    "    labels = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)}\n",
    "              for y in train_data.sentiment.values]\n",
    "    split = int(len(train_data) * split)\n",
    "    \n",
    "    return texts[:split], labels[:split], texts[split:], labels[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels, val_texts, val_labels = load_data('../input/yelp_ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Exercise: Train Function\n",
    "\n",
    "Implement a function `train` that updates a model with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.util import minibatch\n",
    "import random\n",
    "\n",
    "def train(model, train_data, optimizer, batch_size=8):\n",
    "    losses = {}\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=batch_size)\n",
    "    for batch in batches:\n",
    "        # Need to get separate iterables for texts and labels\n",
    "        texts, labels = zip(*batch)\n",
    "        model.update(texts, labels, sgd=optimizer, drop=0.2, losses=losses)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.471749642463003\n"
     ]
    }
   ],
   "source": [
    "optimizer = nlp.begin_training()\n",
    "\n",
    "train_data = list(zip(train_texts, [{\"cats\": labels} for labels in train_labels]))\n",
    "\n",
    "losses = train(nlp, train_data, optimizer)\n",
    "print(losses['textcat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try this slightly trained model on some example text and look at the probabilities assigned to each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NEGATIVE': 0.8552083373069763, 'POSITIVE': 0.1447916030883789}\n"
     ]
    }
   ],
   "source": [
    "text = \"This tea cup was full of holes. Do not recommend.\"\n",
    "doc = nlp(text)\n",
    "print(doc.cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These probabilities look reasonable. Now you should turn them into an actual prediction.\n",
    "\n",
    "## 3) Exercise: Making Predictions\n",
    "\n",
    "Implement a function `predict` that uses a model to predict the sentiment of text examples. The function takes a SpaCy model (with a TextCategorizer) and a list of texts. First, tokenize the texts using `model.tokenizer`. Then, pass those docs to the TextCategorizer which you can get from `model.get_pipe`. Use the `textcat.predict` method to get scores for each document, then choose the class with the highest score (probability) as the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, texts): \n",
    "    # Use the tokenizer to tokenize each input text example\n",
    "    docs = [model.tokenizer(text) for text in texts]\n",
    "    \n",
    "    # Use textcat to get the scores for each doc\n",
    "    textcat = model.get_pipe('textcat')\n",
    "    scores, _ = textcat.predict(docs)\n",
    "    \n",
    "    # From the scores, find the class with the highest score/probability\n",
    "    predicted_class = scores.argmax(axis=1)\n",
    "    \n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSITIVE: Some of the best sushi I've ever had. Reasonable prices. Excellent service and drinks. \n",
      "\n",
      "NEGATIVE: I would be remiss if I said nothing was good, because the egg rolls were good and the white rice, because it's white rice and that was pretty good. But everything else was kind of sub par. Maybe it's what I ordered. The quality of the chicken on the general tso's was really bad. You hope for crispy chicken with a spicy sauce, but this is soggy and the breading is gross. The lo mien hardly has any vegetables, and is also pretty bleh. Stay far away from the crab rangoons. \n",
      "\n",
      "I wanted to like this place, I had gone to the one in Vermilion and was even more disappointed. Seeing these reviews, and knowing it was under different management  I thought it would be better. The people in the restaurant love it, but it's gross. \n",
      "\n",
      "POSITIVE: One of my favorite Asian restaurants. The food is not typical and seemingly more authentic. There are items on the menu I would have to be a bit more adventurous to try. Often there's a wait for s table but the staff is very accommodating and the owner very friendly \n",
      "\n",
      "NEGATIVE: First time there, only one waitress for the whole restaurant, her attitude wasn't nice to our table, but she smiled to all the other customers...., then when we got the bill and paid for it, she came back and told us that the bill hasn't included tips...  we had already left 10% on the tray, what was that about???  Asking for more tips???   Her attitude made us didn't want to leave any at all, but we did anyways! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(nlp, val_texts[23:27])\n",
    "texts = val_texts[23:27]\n",
    "\n",
    "for p, t in zip(predictions, texts):\n",
    "    print(f\"{textcat.labels[p]}: {t} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By eye it looks like your model is working well after going through the data just once. However you need to calculate some metric for the model's performance on the hold-out validation data.\n",
    "\n",
    "## 4) Exercise: Evaluating a Trained Model\n",
    "\n",
    "Implement a function that evaluates a `TextCategorizer` model. This function `evaluate` takes a model along with texts and labels. It returns the accuracy of the model, the number of correct predictions divided by all predictions.\n",
    "\n",
    "First, use the `predict` method you wrote earlier to get the predicted class for each text in `texts`. Then, find where the predicted labels match the true \"gold-standard\" labels and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, texts, labels):\n",
    "    \"\"\" Returns the accuracy of a TextCategorizer model. \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        model: ScaPy model with a TextCategorizer\n",
    "        texts: Text samples, from load_data function\n",
    "        labels: True labels, from load_data function\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get predictions from textcat model\n",
    "    predicted_class = predict(model, texts)\n",
    "    \n",
    "    # From labels, get the true class as a list of integers (POSITIVE -> 1, NEGATIVE -> 0)\n",
    "    true_class = [int(each['POSITIVE']) for each in labels]\n",
    "    \n",
    "    # A boolean or int array indicating correct predictions\n",
    "    correct_predictions = predicted_class == true_class\n",
    "    \n",
    "    # The accuracy, number of correct predictions divided by all predictions\n",
    "    accuracy = correct_predictions.mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9432\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluate(nlp, val_texts, val_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the functions implemented, you can train and evaluate in loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.479 \t Accuracy: 0.946\n",
      "Loss: 5.242 \t Accuracy: 0.946\n",
      "Loss: 4.799 \t Accuracy: 0.950\n",
      "Loss: 4.446 \t Accuracy: 0.949\n",
      "Loss: 4.168 \t Accuracy: 0.948\n"
     ]
    }
   ],
   "source": [
    "n_iters = 5\n",
    "train_data = list(zip(train_texts, [{\"cats\": labels} for labels in train_labels]))\n",
    "for i in range(n_iters):\n",
    "    losses = train(nlp, train_data, optimizer)\n",
    "    accuracy = evaluate(nlp, val_texts, val_labels)\n",
    "    print(f\"Loss: {losses['textcat']:.3f} \\t Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) What would you do to find the best model?\n",
    "\n",
    "In this exercise, you only build the necessary components to train a text classifier with SpaCy. What could you do further to optimize the model and get the best accuracy on the hold-out data?\n",
    "\n",
    "Answer: There are various hyperparameters to work with here. The biggest one is the TextCategorizer architecture. You used the simplest model which trains faster but likely has worse performance than the CNN and ensemble models. You can adjust the dropout parameter to reduce overfitting. Also, you can save the model after each training pass through the data and use the model with the best validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Up!\n",
    "\n",
    "In the next lesson, you'll learn how to use SpaCy to represent tokens as vectors, then use these vectors to train machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
