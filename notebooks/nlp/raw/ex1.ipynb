{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Processing with Spacy\n",
    "\n",
    "In this exercise, you'll use SpaCy to generate some basic statistics from Yelp reviews.\n",
    "\n",
    "You're a consultant for a restaurant looking to get insight into the quality of their food. You have an idea to use Yelp reviews to use customer ratings to measure the quality of specific dishes. Your hypothesis is that a customer's rating and the menu items mentioned in the review will be correlated. Items that consistently appear in reviews with low ratings are likely subpar. Using this analysis, you can provide feedback to the owner and head cook.\n",
    "\n",
    "The goal then is to extract menu items from the review text and find basic statistics on the ratings. For example, you can count how many times specific dishes appear in the reviews.\n",
    "\n",
    "First you'll load in Pandas and SpaCy, then load the data from a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lDJIaF4eYRF4F7g6Zb9euw</td>\n",
       "      <td>lb0QUR5bc4O-Am4hNq9ZGg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I used to work food service and my manager at ...</td>\n",
       "      <td>2013-01-27 17:54:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>vvIzf3pr8lTqE_AOsxmgaA</td>\n",
       "      <td>MAmijW4ooUzujkufYYLMeQ</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We have been trying Eggplant sandwiches all ov...</td>\n",
       "      <td>2015-04-15 04:50:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>UF-JqzMczZ8vvp_4tPK3bQ</td>\n",
       "      <td>slfi6gf_qEYTXy90Sw93sg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Steak and Cheese... Better than any Ph...</td>\n",
       "      <td>2011-03-20 00:57:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>geUJGrKhXynxDC2uvERsLw</td>\n",
       "      <td>N_-UepOzAsuDQwOUtfRFGw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Although I have been going to DeFalco's for ye...</td>\n",
       "      <td>2018-07-17 01:48:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>aPctXPeZW3kDq36TRm-CqA</td>\n",
       "      <td>139hD7gkZVzSvSzDPwhNNw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highs: Ambience, value, pizza and deserts. Thi...</td>\n",
       "      <td>2018-01-21 10:52:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "109   lDJIaF4eYRF4F7g6Zb9euw  lb0QUR5bc4O-Am4hNq9ZGg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1013  vvIzf3pr8lTqE_AOsxmgaA  MAmijW4ooUzujkufYYLMeQ  r5PLDU-4mSbde5XekTXSCA   \n",
       "1204  UF-JqzMczZ8vvp_4tPK3bQ  slfi6gf_qEYTXy90Sw93sg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1251  geUJGrKhXynxDC2uvERsLw  N_-UepOzAsuDQwOUtfRFGw  r5PLDU-4mSbde5XekTXSCA   \n",
       "1354  aPctXPeZW3kDq36TRm-CqA  139hD7gkZVzSvSzDPwhNNw  r5PLDU-4mSbde5XekTXSCA   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "109       4       2      0     0   \n",
       "1013      4       0      0     0   \n",
       "1204      5       1      0     0   \n",
       "1251      1       0      0     0   \n",
       "1354      2       0      0     0   \n",
       "\n",
       "                                                   text                date  \n",
       "109   I used to work food service and my manager at ... 2013-01-27 17:54:54  \n",
       "1013  We have been trying Eggplant sandwiches all ov... 2015-04-15 04:50:56  \n",
       "1204  Amazing Steak and Cheese... Better than any Ph... 2011-03-20 00:57:45  \n",
       "1251  Although I have been going to DeFalco's for ye... 2018-07-17 01:48:23  \n",
       "1354  Highs: Ambience, value, pizza and deserts. Thi... 2018-01-21 10:52:58  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the data from JSON file\n",
    "data = pd.read_json('../input/restaurant.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've provided a list with the menu items and common misspellings for a few of the items. This could be improved, but it will be good for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Calzone\", \n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\", \"Calzones\", \"Corned Beef\", \"Garlic Bread\", \"Spaghetti\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n",
    "        \"Pastrami\", \"Roast Beef\", \"Prosciutto\", \"Salami\", \"Gnocchi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Match One Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At position 6: pizza\n",
      "At position 51: Pizza\n",
      "At position 70: Cannoli\n",
      "At position 98: Pasta\n",
      "\n",
      "\n",
      "Highs: Ambience, value, pizza and deserts. This is a genuine Italian grocery and I might shop here during the day when the crowds are smaller. The restaurant meals are cheap for what you get and word is out among the ASU students and young families. Pizza crust was chewy, crispy with just the right amount of char, like a good bread. Cannoli was outstanding, obviously had been freshly filled, as shell was perfectly crunchy and the sweet ricotta center had a nice clean flavor. Lows: Pasta and disorganization.  It was a packed Saturday night and they weren't prepared. The wine glasses and forks ran out. They had a weird ordering system where there were two cash registers, one halfway through the line. When one of the staff would become available they would open the halfway register, which meant that someone who was lucky enough to be there at that moment would get to order early, in effect cutting in front of the rest of us who had been waiting longer. Our ravioli and filled shells came out lukewarm. As Yogi Berra once said, \"Nobody goes there anymore. It's too crowded.\"\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "doc = nlp(data.iloc[4].text)\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "patterns = [nlp(item) for item in menu]\n",
    "matcher.add(\"MENU\", None, *patterns)\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match in matches:\n",
    "    print(f\"At position {match[1]}: {doc[match[1]:match[2]]}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Matching on the whole dataset\n",
    "\n",
    "Now run this matcher over the whole dataset and collect ratings for each menu item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "patterns = [nlp(item) for item in menu]\n",
    "matcher.add(\"MENU\", None, *patterns)\n",
    "\n",
    "item_ratings = defaultdict(list)\n",
    "for idx, row in data.iterrows():\n",
    "    doc = nlp(row.text)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    found_items = set([doc[match[1]:match[2]] for match in matches])\n",
    "    \n",
    "    for item in found_items:\n",
    "        item_ratings[str(item).lower()].append(row.stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Similar Items\n",
    "\n",
    "You have some items like Steak and Cheese, Cheesesteak, and Cheese Steak that all refer to the same item, but are counted separately. Because language is messy. Before doing analysis, you should combine these items and otherwise clean up the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_items = [('cheesesteak', 'cheese steak'),\n",
    "                 ('cheesesteak', 'steak and cheese'),\n",
    "                 ('chicken parmigiana', 'chicken parm'),\n",
    "                 ('chicken parmigiana', 'chicken parmesan'),\n",
    "                 ('mac and cheese', 'macaroni'),\n",
    "                 ('calzone', 'calzones')]\n",
    "\n",
    "\n",
    "for (destination, source) in similar_items:\n",
    "    item_ratings[destination].extend(item_ratings.pop(source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Which items are the most popular?\n",
    "\n",
    "Look at the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {item: len(ratings) for item, ratings in item_ratings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = sorted(counts, key=mean_ratings.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artichoke salad',\n",
       " 'fettuccini alfredo',\n",
       " 'turkey breast',\n",
       " 'corned beef',\n",
       " 'reuben',\n",
       " 'pastrami',\n",
       " 'chicken salad',\n",
       " 'purista',\n",
       " 'prosciutto',\n",
       " 'chicken pesto',\n",
       " 'chicken spinach salad',\n",
       " 'grilled veggie',\n",
       " 'gnocchi',\n",
       " 'lasagna',\n",
       " 'cheesesteak',\n",
       " 'pizzas',\n",
       " 'pasta',\n",
       " 'mac and cheese',\n",
       " 'calzone',\n",
       " 'cannoli',\n",
       " 'pizza',\n",
       " 'tiramisu',\n",
       " 'ziti',\n",
       " 'chicken parmigiana',\n",
       " 'salami',\n",
       " 'italian sausage',\n",
       " 'roast beef',\n",
       " 'portobello',\n",
       " 'meatball',\n",
       " 'garlic bread',\n",
       " 'italian beef',\n",
       " 'tuna salad',\n",
       " 'eggplant',\n",
       " 'italian combo',\n",
       " 'spaghetti',\n",
       " 'turkey sandwich',\n",
       " 'chicken cutlet']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Which items are the best reviewed?\n",
    "\n",
    "Look at the means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ratings = {item: sum(ratings)/len(ratings) for item, ratings in item_ratings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_items = sorted(mean_ratings, key=mean_ratings.get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thought Question: Are counts important here?\n",
    "\n",
    "Finally, print out the 10 best and 10 worst items. Print the item name, the average rating, and the count. It's important to consider the number of ratings for a specific item when using the mean to make decisions. Why is this?\n",
    "\n",
    "Answer: The less data we have for any specific item, the less we can trust that the average rating is the \"real\" sentiment of the customers. This is fairly common sense. If more people tell you the same thing, you're more likely to believe it. It's also mathematically sound. As the number of data points increases, the error on the mean decreases as $1 / \\sqrt{n}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artichoke salad      Average rating: 5.000 \tcount: 5\n",
      "fettuccini alfredo   Average rating: 5.000 \tcount: 6\n",
      "turkey breast        Average rating: 5.000 \tcount: 1\n",
      "corned beef          Average rating: 5.000 \tcount: 2\n",
      "reuben               Average rating: 4.800 \tcount: 5\n",
      "pastrami             Average rating: 4.688 \tcount: 16\n",
      "chicken salad        Average rating: 4.667 \tcount: 6\n",
      "purista              Average rating: 4.642 \tcount: 67\n",
      "prosciutto           Average rating: 4.619 \tcount: 63\n",
      "chicken pesto        Average rating: 4.567 \tcount: 30\n"
     ]
    }
   ],
   "source": [
    "for item in best_items[:10]:\n",
    "    print(f\"{item:20} Average rating: {mean_ratings[item]:.3f} \\tcount: {counts[item]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicken cutlet       Average rating: 3.545 \tcount: 11\n",
      "turkey sandwich      Average rating: 3.800 \tcount: 5\n",
      "spaghetti            Average rating: 3.854 \tcount: 41\n",
      "italian combo        Average rating: 3.909 \tcount: 22\n",
      "eggplant             Average rating: 3.968 \tcount: 95\n",
      "tuna salad           Average rating: 4.000 \tcount: 5\n",
      "italian beef         Average rating: 4.000 \tcount: 29\n",
      "garlic bread         Average rating: 4.022 \tcount: 46\n",
      "meatball             Average rating: 4.080 \tcount: 163\n"
     ]
    }
   ],
   "source": [
    "for item in best_items[:-10:-1]:\n",
    "    print(f\"{item:20} Average rating: {mean_ratings[item]:.3f} \\tcount: {counts[item]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Up!\n",
    "\n",
    "In the next tutorial you'll learn how to create a text classification model with SpaCy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
