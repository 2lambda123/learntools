{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing Text Data\n",
    "\n",
    "In this exercise, you'll pre-process the data to hopefully improve the model. Text data can contain words \n",
    "\n",
    "As pre-processing steps in this exercise, you'll use the SpaCy package for tokenizing, stemming, and lemmatizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data and take a small sample so we don't wait around forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2970342</th>\n",
       "      <td>Plano Gun Cse: I have an FN AR with a scope th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811203</th>\n",
       "      <td>Avoid...: As a long time Byrdmaniac own virtua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395023</th>\n",
       "      <td>Great Story, Defective Copy: Ender's Shadow is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115925</th>\n",
       "      <td>Typical Comic Book Come-On Cover: As you would...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876317</th>\n",
       "      <td>perfect: This product is even better than it a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  rating\n",
       "2970342  Plano Gun Cse: I have an FN AR with a scope th...       1\n",
       "2811203  Avoid...: As a long time Byrdmaniac own virtua...       0\n",
       "2395023  Great Story, Defective Copy: Ender's Shadow is...       0\n",
       "3115925  Typical Comic Book Come-On Cover: As you would...       0\n",
       "1876317  perfect: This product is even better than it a...       1"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('../input/amazon/train.csv')\n",
    "data = all_data.sample(100_000, random_state=7)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use SpaCy for a bit of preprocessing\n",
    "\n",
    "Here we're going to get lemmas and drop stop words. This actually leads to the model performing worse. But it's part of the hyperparameter iterations. So maybe it helps other models, but hurts naive bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "docs = nlp.pipe(data.text)\n",
    "\n",
    "# Get lemmas of each token and drop stop words\n",
    "tokenized = ([token.lemma_ for token in doc if not token.is_drop] for doc in docs)\n",
    "\n",
    "# Convert tokens back into strings for CountVectorizer\n",
    "processed = [' '.join(tokens) for tokens in tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit NB model with processed text..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84352\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(processed)\n",
    "\n",
    "y = data.rating\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_train_counts, y, random_state=1)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_X, train_y)\n",
    "\n",
    "accuracy = nb_model.score(val_X, val_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams and Trigrams\n",
    "\n",
    "Have CountVectorizer give us bigrams and trigrams for the model. This improves it quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89172\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1, 3))\n",
    "X_train_counts = count_vect.fit_transform(processed)\n",
    "\n",
    "y = data.rating\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X_train_counts, y, random_state=1)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_X, train_y)\n",
    "\n",
    "accuracy = nb_model.score(val_X, val_y)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
