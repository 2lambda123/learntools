{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing Language\n",
    "\n",
    "In this exercise you'll use SpaCy to convert the review text into word vectors, then train a Scikit-learn model with the vectors. You'll also find the most similar review inthe data set given some example text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.nlp.ex3 import *\n",
    "print(\"\\nSetup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = pd.read_csv('../input/nlp-course/yelp_ratings.csv')\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Need to load the large model to get the vectors\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Get document vectors\n",
    "\n",
    "To start, use SpaCy to get document vectors from the review text. \n",
    "\n",
    "Returning all 44,500 document vectors takes about 20 minutes, so here you'll need to get only the first 100. For the rest of this exercise, I've provided a file with all of the document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = review_data[:100]\n",
    "# We just want the vectors so we can turn off other models in the pipeline\n",
    "with nlp.disable_pipes():\n",
    "    # vectors should be a Numpy array with shape (100, 300)\n",
    "    vectors = ____\n",
    "    \n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "# q_1.hint()\n",
    "# q_1.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "reviews = review_data[:100]\n",
    "# We just want the vectors so we can turn off other models in the pipeline\n",
    "with nlp.disable_pipes():\n",
    "    vectors = np.array([nlp(review.text).vector for idx, review in reviews.iterrows()])\n",
    "    \n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to load in the rest of the document vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all document vectors from file\n",
    "vectors = np.load('../input/nlp-course/review_vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Train a Scikit-learn model\n",
    "\n",
    "Next up, train a `LinearSVM` model using the document vectors. Set the regularization parameter to 10, this gives better results than the default. Also set the random state to 1 and `dual=False` (speeds up training without loss in accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, review_data.sentiment, \n",
    "                                                    test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the LinearSVC model\n",
    "model = ____\n",
    "# Fit the model\n",
    "____\n",
    "\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "# q_2.hint()\n",
    "# q_2.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "model = LinearSVC(C=10, random_state=1, dual=False)\n",
    "model.fit(X_train, y_train)\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see the model accuracy\n",
    "print(f'Model test accuracy: {model.score(X_test, y_test)*100:.3f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get an accuracy of 93.9%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Make a prediction\n",
    "\n",
    "With the model trained, you can use it to predict the sentiment of other reviews. The below review is for a tea house in San Franciso. Use your model to predict if the sentiment of the review is positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review=\"\"\"I absolutely love this place. The 360 degree glass windows with the Yerba buena garden view, tea pots all around and the smell of fresh tea everywhere transports you to what feels like a different zen zone within the city. I know the price is slightly more compared to the normal American size, however the food is very wholesome, the tea selection is incredible and I know service can be hit or miss often but it was on point during our most recent visit. Definitely recommend!\n",
    "\n",
    "I would recommend the butternut squash gyoza and ideally the tea sets as I feel like it is better value!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = ____\n",
    "sentiment = ____\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "# q_3.hint()\n",
    "# q_3.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "vector = nlp(review).vector.reshape((1, -1))\n",
    "sentiment = model.predict(vector)[0]\n",
    "q_3.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sentiment = {'Positive' if sentiment else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Similarity\n",
    "\n",
    "For the same tea house review, find the most similar review in the dataset using the cosine similarity.\n",
    "\n",
    "## Exercise: Centering the Vectors\n",
    "\n",
    "Sometimes you'll get better results when measuring similarities if you center the document vectors. This means you subtract the mean of the vectors from each vectors, so the new mean is 0. Why do you think this could help with similarity metrics?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_4.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Find the most similar review\n",
    "\n",
    "Given the review above, find the most similar document within the Yelp dataset using the cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b)/np.sqrt(a.dot(a)*b.dot(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vec = nlp(review).vector\n",
    "\n",
    "## Center the document vectors\n",
    "# Calculate the mean for the document vectors, should have shape (300,)\n",
    "vec_mean = ____\n",
    "# Subtract the mean from the vectors\n",
    "centered = ____\n",
    "\n",
    "# Calculate similarities for each document in the dataset\n",
    "# Make sure to subtract the mean from the review vector\n",
    "sims = ____\n",
    "\n",
    "# Get the index for the most similar document\n",
    "most_similar = ____\n",
    "q_5.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "# q_5.hint()\n",
    "# q_5.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "review_vec = nlp(review).vector\n",
    "\n",
    "## Center the document vectors\n",
    "# Calculate the mean for the document vectors\n",
    "vec_mean = vectors.mean(axis=0)\n",
    "# Subtract the mean from the vectors\n",
    "centered = vectors - vec_mean\n",
    "\n",
    "# Calculate similarities for each document in the dataset\n",
    "# Make sure to subtract the mean from the review vector\n",
    "sims = np.array([cosine_similarity(review_vec - vec_mean, vec) for vec in centered])\n",
    "\n",
    "# Get the index for the most similar document\n",
    "most_similar = sims.argmax()\n",
    "q_5.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_data.iloc[most_similar].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there are many different sorts of businesses in our Yelp dataset, you should have found another tea shop. \n",
    "\n",
    "## Exercise: Other similar reviews\n",
    "\n",
    "If you look at other similar reviews, you'll see many coffee shops. Why do you think reviews for coffee are similar to the example review which mentions only tea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q_6.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on finishing this course! At this point you know how to get embeddings for each word in the documents, but you're only using the averaged document vectors with these models. Using the word vectors themselves might result in even better performing models. To do this you'll want to use a recurrent neural network (RNN for short). We won't cover RNNs in this course, but look them up if you want to learn about state-of-the-art NLP models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
