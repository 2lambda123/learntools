{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "You have seen how to define a random agent.  In this exercise, you'll make a few improvements.\n",
    "\n",
    "To get started, run the code cell below to set up our feedback system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.rl.ex1 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) A smarter agent\n",
    "\n",
    "We can improve our performance without devising a complicated strategy, simply by selecting a winning move, if one is available.\n",
    "\n",
    "Define an agent that:\n",
    "- selects the winning move, if it is available.  (_If there is more than one move that lets the agent win the game, the agent can select any of them._)\n",
    "- Otherwise, it should select a random move.\n",
    "\n",
    "To help you with this exercise, we have provided an agent with a very useful helper function:\n",
    "- the `check_winning_move` method takes two required arguments: `state` (corresponding to the current game state) and `col` (any valid move).  The method returns `True` if dropping a piece in the provided column wins the game for the agent, and otherwise returns `False`.  (There's a third, optional argument that we'll discuss in the next exercise.)\n",
    "\n",
    "**To complete this exercise, you need to finish the `act()` method.  To do this, you'll need to use the `check_winning_move` function.**  \n",
    "\n",
    "Many of the other methods (like `drop_piece`, `check_window`, and `count_windows`) are called in the `check_winning_move` function.  Feel free to examine the details below, but you won't need to use these to solve the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random agent that selects winning move, if it is available\n",
    "# Define opponent\n",
    "class BetterRandom_Player:\n",
    "    def __init__(self, num_rows=6, num_cols=7, in_a_row=4):\n",
    "        self.num_rows = num_rows\n",
    "        self.num_cols = num_cols\n",
    "        self.in_a_row = in_a_row\n",
    "        \n",
    "    def get_valid_moves(self, state):\n",
    "        is_valid_by_idx = [state[0][i]==0 for i in range(self.num_cols)]\n",
    "        return np.where(is_valid_by_idx)[0]\n",
    "    \n",
    "    def drop_piece(self, state, col):\n",
    "        next_state = state.copy()\n",
    "        for row in range(self.num_rows-1, -1, -1):\n",
    "            if next_state[row][col] == 0:\n",
    "                break\n",
    "        next_state[row][col] = 1\n",
    "        return next_state\n",
    "    \n",
    "    def act(self, state):\n",
    "        state = state.reshape(self.num_rows, self.num_cols)\n",
    "        valid_moves = self.get_valid_moves(state)\n",
    "        # Currently, the agent selects a random move.  Change this!\n",
    "        col = random.choice(valid_moves)\n",
    "        return col\n",
    "    \n",
    "    def check_winning_move(self, state, col, agent=True):\n",
    "        next_state = self.drop_piece(state, col)\n",
    "        if agent==True:\n",
    "            num_fours = self.count_windows(next_state, 4, 1)\n",
    "        else:\n",
    "            num_fours = self.count_windows(next_state, 4, -1)\n",
    "        is_winning_move = (num_fours > 0)\n",
    "        return is_winning_move\n",
    "    \n",
    "    def check_window(self, window, num_discs, piece):\n",
    "        return (window.count(piece) == num_discs and window.count(0) == self.in_a_row-num_discs)\n",
    "    \n",
    "    def count_windows(self, state, num_discs=4, piece=1):\n",
    "        num_windows = 0\n",
    "        # horizontal\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols-(self.in_a_row-1)):\n",
    "                window = list(state[row,col:col+self.in_a_row])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        # vertical\n",
    "        for row in range(self.num_rows-(self.in_a_row-1)):\n",
    "            for col in range(self.num_cols):\n",
    "                window = list(state[row:row+self.in_a_row,col])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        # positive diagonal\n",
    "        for row in range(self.num_rows-(self.in_a_row-1)):\n",
    "            for col in range(self.num_cols-(self.in_a_row-1)):\n",
    "                window = list(state[range(row, row+self.in_a_row), range(col, col+self.in_a_row)])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        # negative diagonal\n",
    "        for row in range(self.in_a_row-1, self.num_rows):\n",
    "            for col in range(self.num_cols-(self.in_a_row-1)):\n",
    "                window = list(state[range(row, row-self.in_a_row, -1), range(col, col+self.in_a_row)])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        return num_windows\n",
    "\n",
    "# Check your answer\n",
    "q_1.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "\n",
    "q_1.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) An even smarter agent\n",
    "\n",
    "In the previous question, you created an agent that selects winning moves.  In this problem, you'll amend the code to create an agent that can also block its opponent from winning.  In particular, your agent should:\n",
    "- Select a winning move, if one is available.\n",
    "- Otherwise, it selects a move to block the opponent from winning, if the opponent has a winning move. \n",
    "- If neither the agent nor the opponent can win in the next move, the agent selects a random move.\n",
    "\n",
    "To help you with this exercise, you are encouraged to start with the agent from the previous exercise.  \n",
    "\n",
    "**To check if the opponent has a winning move, you can use the `check_winning_move` function, but need to set `agent` (the third argument) to `False`.**  The default provided value for this function is `True`, and in this case, we check if the agent has a winning move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here: ...\n",
    "\n",
    "# Check your answer\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines below will give you a hint or solution code\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.hint()\n",
    "#_COMMENT_IF(PROD)_\n",
    "q_2.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Looking ahead\n",
    "\n",
    "So far, you have encoded an agent that always selects the winning move, if it's available.  And, it can also block the opponent from winning.\n",
    "\n",
    "Will this produce an agent that always either wins or draws the game?  If not, where (specifically) does the agent have room for improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "q_3.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Submit to the competition!\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep going\n",
    "\n",
    "Learn how to **[use heuristics](#$NEXT_NOTEBOOK_URL$)** to improve your agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
