{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Even if you're new to Connect Four, you've likely developed several strategies for playing the game.  In this tutorial, you'll learn how to use a **heuristic** to share your knowledge with the agent.  \n",
    "\n",
    "# Game trees\n",
    "\n",
    "As a human player, how do you think about how to play the game?  How do you weigh alternative moves?\n",
    "\n",
    "You likely do a bit of forecasting.  For each potential move, you predict what your opponent is likely to do in response, along with how you'd then respond, and what the opponent is likely to do then, and so on.  Then, you choose the move where you think you're most likely to win.\n",
    "\n",
    "We can formalize this idea and represent all possible outcomes in a **(complete) game tree**.  \n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/EZKHxyy.png\"><br/>\n",
    "</center>\n",
    "\n",
    "The game tree represents each possible move (by player and opponent), starting with an empty board.  Then, the first row shows all possible moves the red player can make.  Next, we record each move the yellow player can make in response, and so on, until each branch reaches the end of the game.  (_The game tree for Connect Four is quite large, so we show only a small preview in the image above_.)\n",
    "\n",
    "Once we can see every way the game can possibly end, it can help us to pick the move where we are most likely to win.\n",
    "\n",
    "# Heuristics\n",
    "\n",
    "The complete game tree for Connect Four has over [4 trillion](https://oeis.org/A212693) different boards!  So in practice, our agent can only work with a small subset when planning a move. \n",
    "\n",
    "To make sure the incomplete tree is still useful to the agent, we will use a **heuristic** (or **heuristic function**).  The heuristic assigns scores to different game boards, where we estimate that boards with higher scores are more likely to result in the agent winning the game.  You will design the heuristic based on your knowledge of the game.\n",
    "\n",
    "For instance, one heuristic that might work reasonably well for Connect Four looks at each grid position of four spots in a (horizontal, vertical, or diagonal) line and assigns:\n",
    "- **100 points** if the agent has four discs in a row (the agent won), \n",
    "- **1 point** if the agent filled three spots, and the remaining spot is empty (the agent wins if it fills in the empty spot), \n",
    "- **-10 points** if the opponent filled three spots, and the remaining spot is empty (the opponent wins by filling in the empty spot), and\n",
    "- **-100 points** if the opponent has four discs in a row (the opponent won).\n",
    "\n",
    "This is also represented in the image below.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/UlUYhgr.png\" width=50%><br/>\n",
    "</center>\n",
    "\n",
    "So, how exactly will the agent use the heuristic?  Consider it's the agent's turn, and it's trying to plan a move for the game board shown at the top of the figure below.  There are seven possible moves (one for each column).\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/lGfMNBK.png\" width=100%><br/>\n",
    "</center>\n",
    "\n",
    "The heuristic assigns the first board (where the agent plays in column 0) a score of 20.  The second board is assigned a score of 10, and so on.  The first board receives the highest score, and so the agent will select this move.  It's also the best outcome for the agent, since it has a guaranteed win in just one more move.  \n",
    "\n",
    "The heuristic works really well for this specific example, since it matches the best move with the highest score!  In general, if you're not sure how to design your heuristic (i.e., how to score different game states, or which scores to assign to different conditions), often the best thing to do is to simply take an initial guess at the heuristic and then play against your agent.  This will let you identify specific cases when your agent makes bad moves, which you can then fix by modifying the heuristic.\n",
    "\n",
    "# Code\n",
    "\n",
    "Our **one-step lookahead** agent will:\n",
    "- use the heuristic to assign a score to each possible valid move, and\n",
    "- select the move that gets the highest score.  (_If multiple moves get the high score, we select one at random._)\n",
    "\n",
    "\"One-step lookahead\" refers to the fact that the agent looks only one step (or move) into the future, instead of deeper into the game tree.  This is implemented in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep_Player:\n",
    "    def __init__(self, num_rows=6, num_cols=7, in_a_row=4):\n",
    "        self.num_rows = num_rows\n",
    "        self.num_cols = num_cols\n",
    "        self.in_a_row = in_a_row\n",
    "        \n",
    "    def get_valid_moves(self, state):\n",
    "        is_valid_by_idx = [state[0][i]==0 for i in range(self.num_cols)]\n",
    "        return np.where(is_valid_by_idx)[0]\n",
    "    \n",
    "    def drop_piece(self, state, col):\n",
    "        next_state = state.copy()\n",
    "        for row in range(self.num_rows-1, -1, -1):\n",
    "            if next_state[row][col] == 0:\n",
    "                break\n",
    "        next_state[row][col] = 1\n",
    "        return next_state\n",
    "    \n",
    "    def act(self, state):\n",
    "        state = state.reshape(self.num_rows, self.num_cols)\n",
    "        valid_moves = self.get_valid_moves(state)\n",
    "        scores = dict(zip(valid_moves, [self.score_valid_move(state, col) for col in valid_moves]))\n",
    "        max_val = max(scores.values())\n",
    "        max_keys = [key for key in scores.keys() if scores[key] == max_val]\n",
    "        col = random.choice(max_keys)\n",
    "        return col\n",
    "    \n",
    "    def score_valid_move(self, state, col):\n",
    "        next_state = self.drop_piece(state, col)\n",
    "        num_threes = self.count_windows(next_state, 3, 1)\n",
    "        num_fours = self.count_windows(next_state, 4, 1)\n",
    "        num_threes_opp = self.count_windows(next_state, 3, -1)\n",
    "        score = num_threes - 1e3*num_threes_opp + 1e6*num_fours\n",
    "        return score\n",
    "    \n",
    "    def check_window(self, window, num_discs, piece):\n",
    "        return (window.count(piece) == num_discs and window.count(0) == self.in_a_row-num_discs)\n",
    "    \n",
    "    def count_windows(self, state, num_discs=3, piece=1):\n",
    "        num_windows = 0\n",
    "        # horizontal\n",
    "        for row in range(self.num_rows):\n",
    "            for col in range(self.num_cols-(self.in_a_row-1)):\n",
    "                window = list(state[row,col:col+self.in_a_row])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        # vertical\n",
    "        for row in range(self.num_rows-(self.in_a_row-1)):\n",
    "            for col in range(self.num_cols):\n",
    "                window = list(state[row:row+self.in_a_row,col])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        # positive diagonal\n",
    "        for row in range(self.num_rows-(self.in_a_row-1)):\n",
    "            for col in range(self.num_cols-(self.in_a_row-1)):\n",
    "                window = list(state[range(row, row+self.in_a_row), range(col, col+self.in_a_row)])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        # negative diagonal\n",
    "        for row in range(self.in_a_row-1, self.num_rows):\n",
    "            for col in range(self.num_cols-(self.in_a_row-1)):\n",
    "                window = list(state[range(row, row-self.in_a_row, -1), range(col, col+self.in_a_row)])\n",
    "                if self.check_window(window, num_discs, piece):\n",
    "                    num_windows += 1\n",
    "        return num_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remember that the `act()` method is most important. gets set of valid moves, scores each of them, and then selects at random from the moves that maximize the score.\n",
    "\n",
    "then they play against the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn\n",
    "\n",
    "Continue to **[...link...](#$NEXT_NOTEBOOK_URL$)** ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
