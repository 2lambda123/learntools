{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the previous tutorial, you learned how to build an agent with one-step lookahead.  This agent performs reasonably well, but definitely still has room for improvement!  For instance, consider the potential moves in the figure below.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/fazMfqQ.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "With one-step lookahead, the red player picks one of column 5 or 6, each with 50% probability.  But, column 5 is clearly a bad move, as it lets the opponent win the game in only one more turn.  Unfortunately, the agent doesn't know this, because it can only look one move into the future.  \n",
    "\n",
    "In this tutorial, you'll use the **minimax algorithm** to help the agent look farther into the future and make better-informed decisions.\n",
    "\n",
    "# Minimax\n",
    "\n",
    "We'd like to leverage information from deeper in the game tree.  For now, assume we work with a depth of 3.  This way, when deciding its move, the agent considers all possible game boards that can result from  \n",
    "1. the agent's move, \n",
    "2. the opponent's move, and \n",
    "3. the agent's next move.  \n",
    "\n",
    "We'll work with a visual example.  For simplicity, we assume that at each turn, both the agent and opponent have only two possible moves.  Each of the blue rectangles in the figure below corresponds to a different game board.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/R92TZxL.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "We have labeled each of the \"leaves\" at the bottom of the tree with the score from the heuristic.  As before, the current game state is at the top of the figure, and the agent's goal is to end up with a score that's as high as possible. \n",
    "\n",
    "But notice that the agent no longer has complete control over its score -- after the agent makes its move, the opponent selects its own move.  And, the opponent's selection can prove disastrous for the agent!  In particular, \n",
    "- If the agent chooses the left branch, the opponent can force a score of -1.  \n",
    "- If the agent chooses the right branch, the opponent can force a score of +10.  \n",
    "\n",
    "This is depicted in the figure below, where the agent's selection and the opponent's response are marked as (1) and (2), respectively.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/KbM2UQ4.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "With this in mind, you might argue that the right branch is the better choice for the agent, since it is the less risky option.  Sure, it gives up the possibility of getting the large score (+40) that can only be accessed on the left branch, but it also guarantees that the agent gets at least +10 points.\n",
    "\n",
    "This is the main idea behind the **minimax algorithm**: when assessing potential moves, the agent assumes that its opponent will always choose a move in response that is most damaging for the agent.  That is, the agent assumes its opponent has access to the same game tree and heuristic scores that are available to the agent, and that the opponent always chooses its moves so that the agent's score is as low as possible.\n",
    "\n",
    "Then, given that the opponent uses this strategy, the agent can then plan its best moves.  For instance, in the example above, the minimax agent will not pick the left branch, since it assumes that the opponent will certainly in that case select a move in response to force the agent to a score of -1.  Instead, it picks the right branch.\n",
    "\n",
    "# In practice\n",
    "\n",
    "We've discussed how minimax works at a high level, but how does it work in practice?\n",
    "\n",
    "Well, as was the case with the one-step lookahead agent, the minimax agent assigns a score to each possible move.  The difference is that the minimax agent will generally use information from deeper in the game tree to assign these scores.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/R92TZxL.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "Then, we work up the tree and assume that:\n",
    "- when the agent is given a choice, it should choose the **max**imizing move, and \n",
    "- when the opponent is given a choice, it will choose the **min**imum.  \n",
    "\n",
    "This is illustrated in the figure below.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/1vXGeEq.png\" width=50%><br/>\n",
    "</center>\n",
    "\n",
    "In the example, minimax assigns the move on the left a score of -1, and the move on the right is assigned a score of +10.  So, the agent will select the move on the right. \n",
    "\n",
    "# Code\n",
    "\n",
    "We'll use the same heuristic and several functions from the previous tutorial.  These are defined in the hidden code cell below.  (_Click on the \"Code\" button below if you'd like to view them._)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Gets board at next step if agent drops piece in selected column\n",
    "def drop_piece(grid, col, mark, config):\n",
    "    next_grid = grid.copy()\n",
    "    for row in range(config.rows-1, -1, -1):\n",
    "        if next_grid[row][col] == 0:\n",
    "            break\n",
    "    next_grid[row][col] = mark\n",
    "    return next_grid\n",
    "\n",
    "# Helper function for minimax: calculates value of heuristic for grid\n",
    "def get_heuristic(grid, mark, config):\n",
    "    num_threes = count_windows(grid, 3, mark, config)\n",
    "    num_fours = count_windows(grid, 4, mark, config)\n",
    "    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n",
    "    num_fours_opp = count_windows(grid, 4, mark%2+1, config)\n",
    "    score = num_threes - 1e2*num_threes_opp - 1e4*num_fours_opp + 1e6*num_fours\n",
    "    return score\n",
    "\n",
    "# Helper function for get_heuristic: checks if window satisfies heuristic conditions\n",
    "def check_window(window, num_discs, piece, config):\n",
    "    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n",
    "    \n",
    "# Helper function for get_heuristic: counts number of windows satisfying specified heuristic conditions\n",
    "def count_windows(grid, num_discs, piece, config):\n",
    "    num_windows = 0\n",
    "    # horizontal\n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    return num_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, we define the minimax agent.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses minimax to calculate value of dropping piece in selected column\n",
    "def score_move(grid, col, mark, config, nsteps):\n",
    "    next_grid = drop_piece(grid, col, mark, config)\n",
    "    score = minimax(next_grid, nsteps-1, False, mark, config)\n",
    "    return score\n",
    "\n",
    "# Helper function for minimax: checks if agent or opponent has four in a row in the window\n",
    "def is_terminal_window(window, config):\n",
    "    return window.count(1) == config.inarow or window.count(2) == config.inarow\n",
    "\n",
    "# Helper function for minimax: checks if game has ended\n",
    "def is_terminal_node(grid, config):\n",
    "    # Check for draw \n",
    "    if list(grid[0, :]).count(0) == 0:\n",
    "        return True\n",
    "    # Check for win: horizontal, vertical, or diagonal\n",
    "    # horizontal \n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Minimax implementation\n",
    "def minimax(node, depth, maximizingPlayer, mark, config):\n",
    "    is_terminal = is_terminal_node(node, config)\n",
    "    valid_moves = [c for c in range(config.columns) if node[0][c] == 0]\n",
    "    if depth == 0 or is_terminal:\n",
    "        return get_heuristic(node, mark, config)\n",
    "    if maximizingPlayer:\n",
    "        value = -np.Inf\n",
    "        for col in valid_moves:\n",
    "            child = drop_piece(node, col, mark, config)\n",
    "            value = max(value, minimax(child, depth-1, False, mark, config))\n",
    "        return value\n",
    "    else:\n",
    "        value = np.Inf\n",
    "        for col in valid_moves:\n",
    "            child = drop_piece(node, col, mark%2+1, config)\n",
    "            value = min(value, minimax(child, depth-1, True, mark, config))\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of the `minimax()` function above closely resembles the pseudocode [on Wikipedia](https://en.wikipedia.org/wiki/Minimax#Pseudocode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How deep to make the game tree: higher values take longer to run!\n",
    "N_STEPS = 3\n",
    "\n",
    "def agent(obs, config):\n",
    "    # Get list of valid moves\n",
    "    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n",
    "    # Convert the board to a 2D grid\n",
    "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "    # Use the heuristic to assign a score to each possible board in the next step\n",
    "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, config, N_STEPS) for col in valid_moves]))\n",
    "    # Get a list of columns (moves) that maximize the heuristic\n",
    "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
    "    # Select at random from the maximizing columns\n",
    "    return random.choice(max_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell, we see the outcome of one game round against a random agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_simulations as ks\n",
    "\n",
    "# Create the game environment\n",
    "env = ks.make(\"connectx\")\n",
    "\n",
    "# Two random agents play one game round\n",
    "env.run([agent, \"random\"])\n",
    "\n",
    "# Show the game\n",
    "env.render(mode=\"ipython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn\n",
    "\n",
    "Continue to **[improve the agent's performance](#$NEXT_NOTEBOOK_URL$)** with alpha-beta pruning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
