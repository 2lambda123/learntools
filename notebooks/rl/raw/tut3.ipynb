{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the previous tutorial, you learned how to build an agent with one-step lookahead.  This agent performs reasonably well, but definitely still has room for improvement!  For instance, consider the potential moves in the figure below.\n",
    "\n",
    "NEED TO FIX FIGURE\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/Zi77Qf5.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "With one-step lookahead, the red player picks one of column 4 or 5, each with 50% probability.  But, column 5 is the better move, as it puts the player in a position to certainly win the game in only one more turn.  (_So, ideally, the agent only selects column 5 from this board._)  Unfortunately, the agent doesn't know this, because it can only look one move into the future.  \n",
    "\n",
    "In this tutorial, you'll use the **minimax algorithm** to help the agent look farther into the future and make better-informed decisions.\n",
    "\n",
    "# Minimax\n",
    "\n",
    "We'd like to leverage information from deeper in the game tree.  For now, assume we work with a depth of 3.  This way, when deciding its move, the agent considers all possible game boards that can result from  \n",
    "1. the agent's move, \n",
    "2. the opponent's move, and \n",
    "3. the agent's next move.  \n",
    "\n",
    "We'll work with a visual example.  For simplicity, we assume that at each turn, both the agent and opponent have only two possible moves.  Each of the blue rectangles in the figure below corresponds to a different game board.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/Vgf1OwI.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "As before, the current game state is at the top of the figure, and we've recorded the number of points assigned to each board at the bottom of the tree.  The agent's goal is to end up with a score that's as high as possible. \n",
    "\n",
    "But notice that the agent no longer has complete control over its score -- after the agent makes its move, the opponent selects its own move.  And, the opponent's selection can prove disastrous for the agent!  In particular, the opponent can ensure the agent never receives a score of +10.  \n",
    "- If the agent chooses the left branch, the opponent can force a score of -10.  \n",
    "- If the agent chooses the right branch, the opponent can force a score of 0.  \n",
    "\n",
    "This is depicted in the figure below, where the agent's selection and the opponent's response are marked as (1) and (2), respectively.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://i.imgur.com/x6AGOQf.png\" width=80%><br/>\n",
    "</center>\n",
    "\n",
    "With this in mind, you might argue that the right branch is the better choice for the agent, since it is the less risky option.  Sure, it gives up the possibility of getting the large score (100) that can only be accessed on the left branch, but it also completely avoids the worst case scenario of the very small score (-100).\n",
    "\n",
    "This is the main idea behind the **minimax algorithm**: when assessing potential moves, the agent assumes that its opponent will always choose a move in response that is most damaging for the agent.  That is, the agent assumes its opponent has access to the same game tree and heuristic scores that are available to the agent, and that the opponent always chooses its moves so that the agent gets the lowest possible score.  \n",
    "\n",
    "Then, given that the opponent uses this strategy, the agent can then plan its best moves.  For instance, in the example above, the minimax agent will not pick the left branch, since it assumes that the opponent will certainly in that case select a move in response to force the agent to a score of -100.  Instead, it picks the right branch: in practice, ...\n",
    "\n",
    "# Code\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "# Helper function for score_move: checks if window satisfies heuristic conditions\n",
    "def check_window(window, num_discs, piece, config):\n",
    "    return (window.count(piece) == num_discs and window.count(0) == config.inarow-num_discs)\n",
    "    \n",
    "# Helper function for score_move: counts number of windows satisfying specified heuristic conditions\n",
    "def count_windows(grid, num_discs, piece, config):\n",
    "    num_windows = 0\n",
    "    # horizontal\n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if check_window(window, num_discs, piece, config):\n",
    "                num_windows += 1\n",
    "    return num_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses minimax to calculate value of dropping piece in selected column\n",
    "def score_move(grid, col, mark, config, nsteps):\n",
    "    next_grid = drop_piece(grid, col, mark, config)\n",
    "    score = minimax(next_grid, nsteps-1, False)\n",
    "    return score\n",
    "\n",
    "# Calculates value of heuristic for selected grid\n",
    "def get_heuristic(grid, mark, config):\n",
    "    num_threes = count_windows(grid, 3, mark, config)\n",
    "    num_fours = count_windows(grid, 4, mark, config)\n",
    "    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n",
    "    num_fours_opp = count_windows(grid, 4, mark%2+1, config)\n",
    "    score = num_threes - 1e2*num_threes_opp - 1e4*num_fours_opp + 1e6*num_fours \n",
    "    return score\n",
    "\n",
    "# Gets board at next step if drop piece in selected column\n",
    "def drop_piece(grid, piece, config):\n",
    "    next_grid = grid.copy()\n",
    "    for row in range(config.rows-1, -1, -1):\n",
    "        if next_grid[row][col] == 0:\n",
    "            break\n",
    "    next_grid[row][col] = piece\n",
    "    return next_grid\n",
    "\n",
    "# Helper function for minimax: checks if agent or opponent has four in a row in the window\n",
    "def is_terminal_window(window, config):\n",
    "    return window.count(1) == config.inarow or window.count(2) == config.inarow\n",
    "\n",
    "# Helper function for minimax: checks if game has ended\n",
    "def is_terminal_node(grid, config):\n",
    "    # horizontal \n",
    "    for row in range(config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[row, col:col+config.inarow])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    # vertical\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns):\n",
    "            window = list(grid[row:row+config.inarow, col])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    # positive diagonal\n",
    "    for row in range(config.rows-(config.inarow-1)):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row+config.inarow), range(col, col+config.inarow)])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    # negative diagonal\n",
    "    for row in range(config.inarow-1, config.rows):\n",
    "        for col in range(config.columns-(config.inarow-1)):\n",
    "            window = list(grid[range(row, row-config.inarow, -1), range(col, col+config.inarow)])\n",
    "            if is_terminal_window(window, config):\n",
    "                return True\n",
    "    # TODO: Check for draw\n",
    "    return False\n",
    "\n",
    "# Returns list of valid moves\n",
    "def get_valid_moves(grid, config):\n",
    "    return [c for c in range(config.columns) if grid[0][c] == 0]\n",
    "\n",
    "# Minimax implementation\n",
    "def minimax(node, depth, maximizingPlayer, mark, config):\n",
    "    is_terminal = is_terminal_node(node, config)\n",
    "    valid_moves = get_valid_moves(node, config)\n",
    "    if depth == 0 or is_terminal:\n",
    "        return get_heuristic(node, mark, config)\n",
    "    if maximizingPlayer:\n",
    "        value = -np.Inf\n",
    "        for col in valid_moves:\n",
    "            child = drop_piece(node, mark, config)\n",
    "            value = max(value, minimax(child, depth-1, False, mark, config))\n",
    "        return value\n",
    "    else:\n",
    "        value = np.Inf\n",
    "        for col in valid_moves:\n",
    "            child = drop_piece(node, mark%2+1, config)\n",
    "            value = min(value, minimax(child, depth-1, True, mark, config))\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimax agent is implemented in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 3\n",
    "\n",
    "# Minimax agent\n",
    "def agent1(obs, config):\n",
    "    # Get list of valid moves\n",
    "    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n",
    "    # Convert the board to a 2D grid\n",
    "    grid = np.asarray(obs.board).reshape(config.rows, config.columns)\n",
    "    # Use the heuristic to assign a score to each possible board in the next step\n",
    "    scores = dict(zip(valid_moves, [score_move(grid, col, obs.mark, config, N_STEPS) for col in valid_moves]))\n",
    "    # Get a list of columns (moves) that maximize the heuristic\n",
    "    max_cols = [key for key in scores.keys() if scores[key] == max(scores.values())]\n",
    "    # Select at random from the maximizing columns\n",
    "    return random.choice(max_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then they play against the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn\n",
    "\n",
    "Continue to **[...link...](#$NEXT_NOTEBOOK_URL$)** ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
