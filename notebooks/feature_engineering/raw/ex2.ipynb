{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this exercise you'll apply more advanced encodings to encode the categorical variables ito improve your classifier model. The encodings you will implement are:\n",
    "\n",
    "- Count Encoding\n",
    "- Target Encoding\n",
    "- Leave-one-out Encoding\n",
    "- CatBoost Encoding\n",
    "- Feature embedding with SVD \n",
    "\n",
    "You'll refit the classifier after each encoding to check its performance on hold-out data. First, run the next cell to repeat the work you did in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mat/miniconda3/envs/kaggle/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/Users/mat/miniconda3/envs/kaggle/lib/python3.6/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/Users/mat/miniconda3/envs/kaggle/lib/python3.6/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/Users/mat/miniconda3/envs/kaggle/lib/python3.6/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up code checking\n",
    "# This can take a few seconds, thanks for your patience\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.feature_engineering.ex2 import *\n",
    "\n",
    "clicks = pd.read_parquet('../input/feature-engineering-data/baseline_data.pqt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll define a couple functions to help test the new encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(dataframe, valid_fraction=0.1):\n",
    "    \"\"\" Splits a dataframe into train, validation, and test sets. First, orders by \n",
    "        the column 'click_time'. Set the size of the validation and test sets with\n",
    "        the valid_fraction keyword argument.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe = dataframe.sort_values('click_time')\n",
    "    valid_rows = int(len(dataframe) * valid_fraction)\n",
    "    train = dataframe[:-valid_rows * 2]\n",
    "    # valid size == test size, last two sections of the data\n",
    "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
    "    test = dataframe[-valid_rows:]\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def train_model(train, valid, test=None, feature_cols=None):\n",
    "    if feature_cols is None:\n",
    "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
    "                                           'is_attributed'])\n",
    "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "    \n",
    "    param = {'num_leaves': 64, 'objective': 'binary', \n",
    "             'metric': 'auc', 'seed': 7}\n",
    "    num_round = 1000\n",
    "    print(\"Training model!\")\n",
    "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
    "                    early_stopping_rounds=20, verbose_eval=False)\n",
    "    \n",
    "    valid_pred = bst.predict(valid[feature_cols])\n",
    "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
    "    print(f\"Validation AUC score: {valid_score}\")\n",
    "    \n",
    "    if test is not None: \n",
    "        test_pred = bst.predict(test[feature_cols])\n",
    "        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
    "        return bst, valid_score, test_score\n",
    "    else:\n",
    "        return bst, valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to get a baseline score. If your encodings do better than this, you can keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model\n",
      "Training model!\n",
      "Validation AUC score: 0.9622743228943659\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline model\")\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Categorical encodings and leakage\n",
    "\n",
    "These encodings are all based on statistics calculated from the dataset like counts and means. Considering this, what data should you be using to calculate the encodings?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_1.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Count encodings\n",
    "\n",
    "Here, encode the categorical features `['ip', 'app', 'device', 'os', 'channel']` using the count of each value in the data set. Using `CountEncoder` from the `category_encoders` library, fit the encoding using the categorical feature columns defined in `cat_features`. Then apply the encodings to the train and validation sets, adding them as new columns with names suffixed `\"_count\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 4, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 262, \"questionId\": \"2_CountEncodings\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#ccaa33\">Check:</span> When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `train_encoded`, `valid_encoded`"
      ],
      "text/plain": [
       "Check: When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `train_encoded`, `valid_encoded`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the count encoder\n",
    "count_enc = ____\n",
    "\n",
    "# Learn encoding from the training set\n",
    "____\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "# Make sure to add `_count` as a suffix to the new columns\n",
    "train_encoded = ____\n",
    "valid_encoded = ____\n",
    "\n",
    "q_2.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you need some guidance\n",
    "#q_2.hint()\n",
    "#q_2.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 262, \"questionId\": \"2_CountEncodings\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the count encoder\n",
    "count_enc = ce.CountEncoder(cols=cat_features)\n",
    "\n",
    "# Learn encoding from the training set\n",
    "count_enc.fit(train[cat_features])\n",
    "\n",
    "# Apply encoding to the train and validation sets\n",
    "train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\n",
    "valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))\n",
    "\n",
    "q_2.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.9653051135205329\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the encoded datasets\n",
    "# This can take around 30 seconds to complete\n",
    "_ = train_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count encoding improved our model's score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Why is count encoding effective?\n",
    "At first glance, it could be surprising that Count Encoding helps make accurate models. \n",
    "Why do you think is count encoding is a good idea, or how does it improve the model score?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_3.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Target encoding\n",
    "\n",
    "Here you'll try some supervised encodings that use the labels (the targets) to transform categorical features. The first one is target encoding. Create the target encoder from the `category_encoders` library. Then, learn the encodings from the training dataset, apply the encodings to all the datasets and retrain the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 4, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 262, \"questionId\": \"4_TargetEncodings\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#ccaa33\">Check:</span> When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `train_encoded`, `valid_encoded`"
      ],
      "text/plain": [
       "Check: When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `train_encoded`, `valid_encoded`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the target encoder. You can find this easily by using tab completion.\n",
    "# Start typing ce. the press Tab to bring up a list of classes and functions.\n",
    "target_enc = ____\n",
    "\n",
    "# Learn encoding from the training set. Use the 'is_attributed' column as the target.\n",
    "____\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "# Make sure to add `_target` as a suffix to the new columns\n",
    "train_encoded = ____\n",
    "valid_encoded = ____\n",
    "\n",
    "q_4.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these if you need some guidance\n",
    "#q_4.hint()\n",
    "#q_4.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 262, \"questionId\": \"4_TargetEncodings\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "target_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))\n",
    "\n",
    "q_4.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.9540530347873288\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(train_encoded, valid_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Remove IP encoding\n",
    "\n",
    "Try leaving `ip` out of the encoded features and retrain the model with target encoding again. You should find that the score increases and is above the baseline score! Why do you think the score is below baseline when we encode the IP address but above baseline when we don't?\n",
    "\n",
    "Uncomment the following line after you've decided your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_5.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) CatBoost Encoding\n",
    "\n",
    "The CatBoost encoder is supposed to working well with the LightGBM model. Encode the categorical features with `CatBoostEncoder` and train the model on the encoded data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 4, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 262, \"questionId\": \"6_CatBoostEncodings\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#ccaa33\">Check:</span> When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `train_encoded`, `valid_encoded`"
      ],
      "text/plain": [
       "Check: When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `train_encoded`, `valid_encoded`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the CatBoost encoder\n",
    "cb_enc = ____\n",
    "\n",
    "# Learn encoding from the training set\n",
    "____\n",
    "\n",
    "# Apply encoding to the train and validation sets as new columns\n",
    "# Make sure to add `_cb` as a suffix to the new columns\n",
    "train_encoded = ____\n",
    "valid_encoded = ____\n",
    "q_6.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these if you need some guidance\n",
    "#q_6.hint()\n",
    "#q_6.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 1, \"learnTutorialId\": 262, \"questionId\": \"6_CatBoostEncodings\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "train, valid, _ = get_data_splits(clicks)\n",
    "\n",
    "cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n",
    "\n",
    "# Learn encodings on the train set\n",
    "cb_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# Apply encodings to each set\n",
    "train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
    "valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))\n",
    "\n",
    "q_6.assert_check_passed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.9622743228943659\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CatBoost encodings work the best, so we'll keep those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = cb_enc.transform(clicks[cat_features])\n",
    "for col in encoded:\n",
    "    clicks.insert(len(clicks.columns), col + '_cb', encoded[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical feature embeddings with SVD\n",
    "\n",
    "Now you'll create embeddings from pairs of columns using SVD to learn from a count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Learn SVD components as embeddings.\n",
    "\n",
    "Here you'll use SVD to learn embeddings for the categorical features from a matrix of counts. First, create the SVD transformer with `TruncatedSVD`. Then for each pair of features, create a count matrix and learn the SVD components. Remember you should be learning the embeddings from the train dataset to avoid leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 2, \"failureMessage\": \"Something wrong with app_device\", \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 262, \"questionId\": \"7_LearnSVDEmbeddings\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#cc3333\">Incorrect:</span> Something wrong with app_device"
      ],
      "text/plain": [
       "Incorrect: Something wrong with app_device"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, valid, test = get_data_splits(clicks)\n",
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "\n",
    "# Create the SVD transformer\n",
    "svd = TruncatedSVD(n_components=5, random_state=7)\n",
    "\n",
    "# Learn SVD feature vectors and store in svd_components as DataFrames\n",
    "# Make sure you're only using the train set!\n",
    "svd_components = {}\n",
    "for col1, col2 in itertools.permutations(cat_features, 2):\n",
    "    # Create the count matrix\n",
    "    ____\n",
    "    \n",
    "    # Fit the SVD and transform to get the components\n",
    "    pair_components = ____\n",
    "    \n",
    "    # Store the components in the dictionary. \n",
    "    svd_components['_'.join([col1, col2])] = pair_components\n",
    "\n",
    "q_7.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these if you need some guidance\n",
    "#q_7.hint()\n",
    "#q_7.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.2, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 262, \"questionId\": \"7_LearnSVDEmbeddings\", \"learnToolsVersion\": \"0.3.1\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#33cc33\">Correct</span>"
      ],
      "text/plain": [
       "Correct"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Learn SVD feature vectors\n",
    "cat_features = ['app', 'device', 'os', 'channel']\n",
    "svd_components = {}\n",
    "svd = TruncatedSVD(n_components=5, random_state=7)\n",
    "# Loop through each pair of categorical features\n",
    "for col1, col2 in itertools.permutations(cat_features, 2):\n",
    "    # For a pair, create a sparse matrix with cooccurence counts\n",
    "    pair_counts = train.groupby([col1, col2])['is_attributed'].count()\n",
    "    pair_matrix = pair_counts.unstack(fill_value=0)\n",
    "    \n",
    "    pair_components = pd.DataFrame(svd.fit_transform(pair_matrix))\n",
    "    \n",
    "    # Fit the SVD and store the components\n",
    "    svd_components['_'.join([col1, col2])] = pair_components\n",
    "\n",
    "q_7.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Encode categorical features with SVD components\n",
    "\n",
    "With the components learned from the train dataset, encode the categorical features and create a dataframe `svd_encodings`. The columns need to be named with the feature pair, `svd`, and the component index, such as `\"os_device_svd_0\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 4, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 262, \"questionId\": \"8_ApplySVDEncoding\", \"learnToolsVersion\": \"0.3.1\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style=\"color:#ccaa33\">Check:</span> When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `svd_components`, `svd_encodings`"
      ],
      "text/plain": [
       "Check: When you've updated the starter code, `check()` will tell you whether your code is correct. You need to update the code that creates variables `svd_components`, `svd_encodings`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svd_encodings = pd.DataFrame(index=clicks.index)\n",
    "\n",
    "for feature in svd_components:\n",
    "    # Get the feature column the SVD components are encoding\n",
    "    col = feature.split('_')[0]\n",
    "\n",
    "    ## Use SVD components to encode the categorical features\n",
    "    feature_components = svd_components[feature]\n",
    "    comp_cols = ____\n",
    "    \n",
    "    # Doing this so we know what these features are\n",
    "    svd_cols = ____\n",
    "    svd_encodings = ____\n",
    "\n",
    "# Fill null values with the mean\n",
    "# svd_encodings = svd_encodings.fillna(svd_encodings.mean())\n",
    "q_8.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment these if you need some guidance\n",
    "#q_8.hint()\n",
    "#q_8.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "svd_encodings = pd.DataFrame(index=clicks.index)\n",
    "for feature in svd_components:\n",
    "    # Get the feature column the SVD components are encoding\n",
    "    col = feature.split('_')[0]\n",
    "\n",
    "    ## Use SVD components to encode the categorical features\n",
    "    feature_components = svd_components[feature]\n",
    "    comp_cols = feature_components.reindex(clicks[col]).set_index(clicks.index)\n",
    "    \n",
    "    # Doing this so we know what these features are\n",
    "    comp_cols = comp_cols.add_prefix(feature + '_svd_')\n",
    "    \n",
    "    svd_encodings = svd_encodings.join(comp_cols)\n",
    "\n",
    "# Fill null values with the mean\n",
    "svd_encodings = svd_encodings.fillna(svd_encodings.mean())\n",
    "\n",
    "q_8.assert_check_passed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = get_data_splits(clicks.join(svd_encodings))\n",
    "_ = train_model(train, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Going\n",
    "\n",
    "Now you are ready to **[generating completely new features](#$NEXT_NOTEBOOK_URL$)** from the data itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
