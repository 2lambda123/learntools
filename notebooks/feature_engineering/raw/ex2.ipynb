{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Categorical Encodings\n",
    "\n",
    "In this exercise you'll be applying more advanced encodings to the categorical variables. The goal is to encode the categorical variables in a way that provides more information for the classifier model. The encodings you will implement are:\n",
    "\n",
    "- Count Encoding\n",
    "- Target Encoding\n",
    "- Leave-on-out Encoding\n",
    "- CatBoost Encoding\n",
    "- Feature embedding with SVD \n",
    "\n",
    "After each encoding, you'll refit the classifier and check it's performance on hold-out data. First, run the next cell to repeat the work you did in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Ignoring repeated attempt to bind to globals\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.machine_learning.ex2 import *\n",
    "\n",
    "# Create features from timestamps\n",
    "click_data = pd.read_csv('../input/train_sample.csv', parse_dates=['click_time'])\n",
    "click_times = click_data['click_time']\n",
    "clicks = click_data.assign(day=click_times.dt.day.astype('uint8'),\n",
    "                           hour=click_times.dt.hour.astype('uint8'),\n",
    "                           minute=click_times.dt.minute.astype('uint8'),\n",
    "                           second=click_times.dt.second.astype('uint8'))\n",
    "\n",
    "# Label encoding for categorical features\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "for feature in cat_features:\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    clicks[feature] = label_encoder.fit_transform(clicks[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll define a couple functions to help test the new encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(dataframe, valid_fraction=0.1):\n",
    "    \"\"\" Splits a dataframe into train, validation, and test sets. First, orders by \n",
    "        the column 'click_time'. Set the size of the validation and test sets with\n",
    "        the valid_fraction keyword argument.\n",
    "    \"\"\"\n",
    "\n",
    "    dataframe = dataframe.sort_values('click_time')\n",
    "    valid_rows = int(len(dataframe) * valid_fraction)\n",
    "    train = dataframe[:-valid_rows * 2]\n",
    "    # valid size == test size, last two sections of the data\n",
    "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
    "    test = dataframe[-valid_rows:]\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def train_model(train, valid, test):\n",
    "    \"\"\" Trains a logistic classifier with LightGBM on the train and valid datasets.\n",
    "        Uses the test set to measure the AUC score on hold-out data.\n",
    "    \"\"\"\n",
    "    feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
    "                                       'is_attributed'])\n",
    "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "    dtest = lgb.Dataset(test[feature_cols], label=test['is_attributed'])\n",
    "    \n",
    "    param = {'num_leaves': 64, 'objective': 'binary', 'metric': 'auc'}\n",
    "    num_round = 1000\n",
    "    print(\"Training model!\")\n",
    "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
    "                    early_stopping_rounds=20, verbose_eval=False)\n",
    "    \n",
    "    ypred = bst.predict(test[feature_cols])\n",
    "    score = metrics.roc_auc_score(test['is_attributed'], ypred)\n",
    "    print(f\"Model AUC score: {score}\")\n",
    "    \n",
    "    return bst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to get a baseline score. If your encodings do better than this, you can keep them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model\n",
      "Training model!\n",
      "Model AUC score: 0.9727603360058794\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline model\")\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "_ = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Count encodings\n",
    "\n",
    "Here, encode the categorical features `['ip', 'app', 'device', 'os', 'channel']` using the count of each value in the data set. Then, retrain the model to measure the score with the new encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountEncoder:\n",
    "    def __init__(self):\n",
    "        self.mapping = {}\n",
    "        \n",
    "    def fit(self, df):\n",
    "        for col in df.columns:\n",
    "            self.mapping[col] = df.groupby(col).count().iloc[:, 0]\n",
    "        \n",
    "    def transform(self, df):\n",
    "        out_df = df.copy()\n",
    "        for col, encoding in self.mapping.items():\n",
    "            out_df[col] = df[col].map(self.mapping[col]).fillna(0)\n",
    "        \n",
    "        return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Model AUC score: 0.9742349038475913\n"
     ]
    }
   ],
   "source": [
    "count_enc = CountEncoder()\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "# Learn encoding from the training set\n",
    "count_enc.fit(train[cat_features])\n",
    "\n",
    "# Apply encoding to each set and train a new model\n",
    "for each in (train, valid, test):\n",
    "    encoded = count_enc.transform(each[cat_features])\n",
    "    for col in encoded:\n",
    "        each.insert(0, col + '_count', encoded[col])\n",
    "\n",
    "bst = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, count encoding improved our model's score. Add it to the whole dataset and try more encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_enc = CountEncoder()\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "# Learn encoding from the training set\n",
    "count_enc.fit(train[cat_features])\n",
    "encoded = count_enc.transform(clicks[cat_features])\n",
    "for col in encoded:\n",
    "    clicks.insert(len(clicks.columns), col + '_count', encoded[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Target encoding\n",
    "\n",
    "Now, try target encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Model AUC score: 0.9654157052540729\n"
     ]
    }
   ],
   "source": [
    "tenc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "tenc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "for each in (train, valid, test):\n",
    "    encoded = tenc.transform(each[cat_features])\n",
    "    for col in encoded:\n",
    "        each.insert(0, col + '_target', encoded[col])\n",
    "\n",
    "bst = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X) Leave-One-Out Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Model AUC score: 0.9626649445257338\n"
     ]
    }
   ],
   "source": [
    "loo_enc = ce.LeaveOneOutEncoder(cols=cat_features, sigma=1)\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "loo_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "for each in (train, valid, test):\n",
    "    encoded = loo_enc.transform(each[cat_features])\n",
    "    for col in encoded:\n",
    "        each.insert(0, col + '_loo', encoded[col])\n",
    "\n",
    "bst = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X) CatBoost Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Model AUC score: 0.9652455582007964\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "cb_enc = ce.CatBoostEncoder(cols=cat_features, sigma=0.6)\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "# Learn encodings on the train set\n",
    "cb_enc.fit(train[cat_features], train['is_attributed'])\n",
    "\n",
    "# Apply encodings to each set\n",
    "for each in [train, valid, test]:\n",
    "    encoded = cb_enc.transform(each[cat_features])\n",
    "    for col in encoded:\n",
    "        each.insert(0, col + '_cb', encoded[col])\n",
    "\n",
    "bst = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X) Supervised encoding performance\n",
    "\n",
    "Why do you think these encodings result in lower scores?\n",
    "\n",
    "**Answer:** Most likely it's because these encodings are using information about the target to create the encodings. This means the encodings are too specific to the training set and don't generalize to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical feature embeddings with SVD\n",
    "\n",
    "Now you'll create embeddings from pairs of columns using SVD to learn from a count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note to self/Dan\n",
    "Here I'm creating the count matrix as a dense array in a DataFrame. It's possible to use CountVectorizer from sklearn to create a sparse array. But, CountVectorizer expects the input data to be strings while our data here is all integers. It would be fairly confusing to use CountVectorizer for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X) Learn SVD components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, be sure to learn encodings only from the training set!\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Learn SVD feature vectors\n",
    "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
    "svd_components = {}\n",
    "svd = TruncatedSVD(n_components=5)\n",
    "# Loop through each pair of categorical features\n",
    "for col1, col2 in itertools.permutations(cat_features, 2):\n",
    "    # For a pair, create a sparse matrix with cooccurence counts\n",
    "    pair_counts = train.groupby([col1, col2])['is_attributed'].count()\n",
    "    pair_matrix = pair_counts.unstack(fill_value=0)\n",
    "    \n",
    "    # Fit the SVD and store the components\n",
    "    # Note: these components represent column 2\n",
    "    svd.fit(pair_matrix)\n",
    "    svd_components['_'.join([col2, col1])] = pd.DataFrame(svd.components_.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X) Encode categorical features with SVD components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Apply encodings to each set\n",
    "for each in [train, valid, test]:\n",
    "    for feature in svd_components:\n",
    "        # Get the feature column the SVD components are encoding\n",
    "        col = feature.split('_')[0]\n",
    "        \n",
    "        # Use SVD components to encode the categorical features\n",
    "        comp_cols = svd_components[feature].reindex(each[col]).set_index(each.index)\n",
    "\n",
    "        # Add encoded features to the DataFrame\n",
    "        for component, values in comp_cols.T.iterrows():\n",
    "            each.insert(len(each.columns), feature + \"_svd_\" + str(component), values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Model AUC score: 0.9746475189597654\n"
     ]
    }
   ],
   "source": [
    "bst = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a slight boost in the AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X) Which encodings work?\n",
    "\n",
    "Which encodings should we use?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
