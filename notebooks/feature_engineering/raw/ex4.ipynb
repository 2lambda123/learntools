{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "In this exercise you'll use some feature selection algorithms to improve your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mat/miniconda3/envs/py36/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/Users/mat/miniconda3/envs/py36/lib/python3.6/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/Users/mat/miniconda3/envs/py36/lib/python3.6/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/Users/mat/miniconda3/envs/py36/lib/python3.6/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.machine_learning.ex2 import *\n",
    "\n",
    "import os\n",
    "\n",
    "clicks = pd.read_parquet('../input/baseline_data.pqt')\n",
    "data_files = ['count_encodings.pqt',\n",
    "              'catboost_encodings.pqt',\n",
    "              'interactions.pqt',\n",
    "              'past_6hr_events.pqt',\n",
    "              'downloads.pqt',\n",
    "              'time_deltas.pqt',\n",
    "              'svd_encodings.pqt']\n",
    "for file in data_files:\n",
    "    features = pd.read_parquet(os.path.join('../input', file))\n",
    "    clicks = clicks.join(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(dataframe, valid_fraction=0.1):\n",
    "\n",
    "    dataframe = dataframe.sort_values('click_time')\n",
    "    valid_rows = int(len(dataframe) * valid_fraction)\n",
    "    train = dataframe[:-valid_rows * 2]\n",
    "    # valid size == test size, last two sections of the data\n",
    "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
    "    test = dataframe[-valid_rows:]\n",
    "    \n",
    "    return train, valid, test\n",
    "\n",
    "def train_model(train, valid, test, feature_cols=None):\n",
    "    if feature_cols is None:\n",
    "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
    "                                           'is_attributed'])\n",
    "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
    "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
    "    dtest = lgb.Dataset(test[feature_cols], label=test['is_attributed'])\n",
    "    \n",
    "    param = {'num_leaves': 64, 'objective': 'binary', \n",
    "             'metric': 'auc', 'seed': 7}\n",
    "    num_round = 1000\n",
    "    print(\"Training model!\")\n",
    "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
    "                    early_stopping_rounds=20, verbose_eval=False)\n",
    "    \n",
    "    valid_pred = bst.predict(valid[feature_cols])\n",
    "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
    "    \n",
    "    test_pred = bst.predict(test[feature_cols])\n",
    "    test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
    "    print(f\"Validation AUC score: {valid_score}\")\n",
    "    \n",
    "    return bst, valid_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Score\n",
    "\n",
    "Let's look at the baseline score for all the features we've made so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.9659200109124912\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = get_data_splits(clicks)\n",
    "_, baseline_score, _ = train_model(train, valid, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Which data to use for feature selection?\n",
    "\n",
    "Since many feature selection methods require calculating statistics from the dataset, should you use all the data for feature selection?\n",
    "\n",
    "**Answer:** Including validation and test data within the feature selection is a source of leakage. You'll want to perform feature selection on the train set only, then use the results there to remove features from the validation and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 131 features we're using for predictions. With all these features, there is a good chance the model is overfitting the data. We might be able to reduce the overfitting by removing some features. Of course, the model's performance might decrease. But at least we'd be making the model smaller and faster without losing much performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Univariate Feature Selection\n",
    "\n",
    "Below, use `SelectKBest` to choose 40 features from the 131 features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = clicks.columns.drop(['click_time', 'attributed_time', 'is_attributed'])\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the selector, keeping 40 features\n",
    "selector = ____\n",
    "\n",
    "# Use the selector to retrieve the best features\n",
    "X_new = ____ \n",
    "\n",
    "# Get back the kept features as a DataFrame with dropped columns as all 0s\n",
    "selected_features = ____\n",
    "\n",
    "# Find the columns that were dropped\n",
    "dropped_columns = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "feature_cols = clicks.columns.drop(['click_time', 'attributed_time', 'is_attributed'])\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Do feature extraction on the training data only!\n",
    "selector = SelectKBest(f_classif, k=40)\n",
    "X_new = selector.fit_transform(train[feature_cols], train['is_attributed'])\n",
    "\n",
    "# Get back the features we've kept, zero out all other features\n",
    "selected_features = pd.DataFrame(selector.inverse_transform(X_new), \n",
    "                                 index=train.index, \n",
    "                                 columns=feature_cols)\n",
    "\n",
    "# Dropped columns have values of all 0s, so var is 0, drop them\n",
    "dropped_columns = selected_features.columns[selected_features.var() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model!\n",
      "Validation AUC score: 0.962405543877231\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(train.drop(dropped_columns, axis=1), \n",
    "                valid.drop(dropped_columns, axis=1),\n",
    "                test.drop(dropped_columns, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) The best value of K\n",
    "\n",
    "With this method we can choose the best K features, but we still have to choose K ourselves. How would you find the \"best\" value of K? That is, you want it to be small so you're keeping the best features, but not so small that it's degrading the model's performance.\n",
    "\n",
    "**Answer:** To find the best value of K, you can fit multiple models with increasing values of K, then choose the smallest K with validation score above some threshold or some other criteria. A good way to do this is loop over values of K and record the validation scores for each iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Use L1 regularization for feature selection\n",
    "\n",
    "Now try a more powerful approach using L1 regularization. Use a `LinearSVC` classifier model with an L1 penalty to select the features. First fit the model, then use `SelectFromModel` to return a model with the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = clicks.columns.drop(['click_time', 'attributed_time', 'is_attributed'])\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Create the LinearSVC model with l1 penalty and penalty parameter = 0.01\n",
    "lsvc = ____\n",
    "\n",
    "# Train the LinearSVC model\n",
    "____\n",
    "\n",
    "# Use SelectFromModel to retrieve the best features from the trained SVC model\n",
    "model = ____ \n",
    "\n",
    "# With the new model, get the selected features\n",
    "X_new = ____\n",
    "\n",
    "# Get back the kept features as a DataFrame with dropped columns as all 0s\n",
    "selected_features = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "\n",
    "feature_cols = clicks.columns.drop(['click_time', 'attributed_time', 'is_attributed'])\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "X, y = train[feature_cols], train['is_attributed']\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "\n",
    "X_new = model.transform(X)\n",
    "\n",
    "# Get back the kept features as a DataFrame with dropped columns as all 0s\n",
    "selected_features = pd.DataFrame(model.inverse_transform(X_new), \n",
    "                                 index=train.index, \n",
    "                                 columns=feature_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped columns have values of all 0s, so var is 0, drop them\n",
    "dropped_columns = selected_features.columns[selected_features.var() == 0]\n",
    "_ = train_model(train.drop(dropped_columns, axis=1), \n",
    "                valid.drop(dropped_columns, axis=1),\n",
    "                test.drop(dropped_columns, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Feature Selection with Trees\n",
    "\n",
    "Since we're using a tree-based model, using another tree-based model for feature selection might produce better results. What would you do different to select the features using a trees classifier?\n",
    "\n",
    "**Answer:** You could use something like `RandomForestClassifier` or `ExtraTreesClassifier` to find feature importances. `SelectFromModel` can use the feature importances to find the best features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Principle Component Analysis\n",
    "\n",
    "There are 103 numerical features, the SVD encodings plus the three numerical features we created. Use PCA to reduce these to down to 20 features and refit the model. In this first step here, create the PCA transformer and fit it to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "# Select the feature columns you'll use to train the PCA transformer\n",
    "feature_cols = ____\n",
    "\n",
    "# Create the PCA transformer with 20 components\n",
    "pca = ____\n",
    "\n",
    "# Fit PCA to the feature columns\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "feature_cols = train.columns[-103:]\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pca.fit(train[feature_cols], train['is_attributed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Applying PCA encodings\n",
    "\n",
    "Implement a function `encode_pcs` that encodes the feature columns of a dataframe using a trained PCA transformer. As input, this function will take a dataframe, a trained PCA transformer, and a list of feature columns to encode. Then it should return a dataframe with the same index, but encoded features. Note that the feature columns here should be the same as what was used to train the PCA transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_pcs(df, pca, feature_cols):\n",
    "    \"\"\" Returns a new dataframe with the feature columns of a dataframe (defined with the\n",
    "        feature_cols argument) encoded using a trained PCA transformer\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        df: DataFrame\n",
    "        pca: Trained PCA transformer\n",
    "        feature_cols: the feature columns of df that will be encoded\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DataFrame with PCA encoded features\n",
    "    \"\"\"\n",
    "    ____\n",
    "    return ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "def encode_pcs(df, pca, feature_cols):\n",
    "    encodings = pd.DataFrame(pca.transform(df[feature_cols]),\n",
    "                             index=df.index).add_prefix('pca_')\n",
    "    encoded_df = df.drop(feature_cols, axis=1).join(encodings)\n",
    "    return encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_model(encode_pcs(train, pca, feature_cols),\n",
    "                encode_pcs(valid, pca, feature_cols), \n",
    "                encode_pcs(test, pca, feature_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Feature Selection with Boruta\n",
    "\n",
    "Finally, you'll use Boruta. Define a function `fit_boruta` that fits the Boruta feature selection to a dataset and returns the rejected features. This function will take a dataframe with the data, a list of feature columns, and the target column (as a string).\n",
    "\n",
    "Boruta takes a while to run so to provide more immediate feedback I'll only be testing it on a small sample from the data. Typically, you'd let it run on the entire dataset and just wait. I'll provide a file with the results on the full dataset so you can see the final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_boruta(df, feature_cols, target):\n",
    "    ____\n",
    "    return ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "def fit_boruta(df, feature_cols, target):\n",
    "    \n",
    "    X = df[feature_columns].values\n",
    "    y = df[target].values\n",
    "    \n",
    "    # define random forest classifier, with utilising all cores and\n",
    "    # sampling in proportion to y labels\n",
    "    rf = RandomForestClassifier(class_weight='balanced', max_depth=5, n_jobs=-1)\n",
    "\n",
    "    # define Boruta feature selection method\n",
    "    feat_selector = BorutaPy(rf, n_estimators='auto', random_state=1)\n",
    "\n",
    "    # Fit the Boruta selector\n",
    "    feat_selector.fit(X, y)\n",
    "\n",
    "    # Get the rejected columns\n",
    "    rejected_columns = feature_columns[~feat_selector.support_]\n",
    "    return rejected_columns\n",
    "\n",
    "feature_cols = clicks.columns.drop(['click_time', 'attributed_time', 'is_attributed'])\n",
    "train, valid, test = get_data_splits(clicks)\n",
    "\n",
    "rejected_columns = fit_boruta(train[:5000], feature_cols, 'is_attributed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Still need to fit boruta on the entire dataset and save the results.\n",
    "## I'll load in the smaller dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_model(train.drop(rejected_columns, axis=1),\n",
    "                valid.drop(rejected_columns, axis=1),\n",
    "                test.drop(rejected_columns, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
